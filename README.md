# Awesome colab notebooks collection for ML experiments
## Research
| name | description | author | links | colaboratory | update |
|------|-------------|--------|:-----:|:------------:|:------:|
| Big GAN | Large Scale GAN Training for High Fidelity Natural Image Synthesis | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1809.11096) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb) | 09.12.2020 |
| WikiArt (stylegan2-ada) | Generation of paintings of different styles and genres | Doron Adler | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2006.06676) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_ADA_Example_Generation.ipynb) | 08.12.2020 |
| DeOldify (video) | Colorize your own videos! | Robert Bell | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1805.08318), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.08500) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb) | 13.11.2020 |
| DeOldify (photo) | Colorize your own photos! | <ul><li>Matt Robinson</li> <li>María Benavente</li></ul> | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1805.08318), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.08500) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb) | 13.11.2020 |
| Fine-tuning a BERT | In this example, we will work through fine-tuning a BERT model using the tensorflow-models PIP package | <ul><li>Chen Chen</li> <li>Claire Yao</li></ul> | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://tensorflow.org/hub)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.04805)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb) | 23.10.2020 |
| First Order Motion Model for Image Animation | Transferring facial movements from video to image | Aliaksandr Siarohin | <ul><li>[neurips](https://papers.nips.cc/paper/2019/hash/31c0b36aef265d9221af80872ceb62f9-Abstract.html)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/AliaksandrSiarohin/first-order-model)</li><li>[project](https://aliaksandrsiarohin.github.io/first-order-model-website/)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=u-0cQ-grXBQ)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb) | 01.10.2020 |
| Instance-aware Image Colorization | Novel deep learning framework to achieve instance-aware colorization | Jheng-Wei Su | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2005.10825)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/ericsujw/InstColorization)</li><li>[project](https://ericsujw.github.io/InstColorization/)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=Zj1N4uE1ehk)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericsujw/InstColorization/blob/master/InstColorization.ipynb) | 30.08.2020 |
| DFL-Colab | This project provides you IPython Notebook to use DeepFaceLab with Google Colaboratory | chervonij | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2005.05535)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/channel/UCTKBl8kB6DJ_qLnk1NGDGbQ)</li><li>[guide](https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/iperov/DeepFaceLab)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chervonij/DFL-Colab/blob/master/DFL_Colab.ipynb) | 04.08.2020 |
| Customizing a Transformer Encoder | In this Colab notebook, we will learn how to customize the encoder to employ new network architectures | Chen Chen | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.03762)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/tensorflow/models/tree/master/official/nlp/modeling), [<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/tensorflow/models/blob/master/official/nlp/modeling/networks/encoder_scaffold.py)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/nlp/customize_encoder.ipynb) | 03.08.2020 |
| GrooVAE | This notebook demonstrates some applications of machine learning for generating and manipulating beats and drum performances | <ul><li>Jon Gillick</li> <li>Adam Roberts</li> <li>Jesse Engel</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1905.06118)</li><li>[blog post](https://g.co/magenta/groovae)</li><li>[data](https://g.co/magenta/groove-datasets)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=x2YLmXzovDo)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](http://goo.gl/magenta/musicvae-py)</li><li>[web app](https://groove-drums.glitch.me/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/magenta-demos/blob/master/colab-notebooks/GrooVAE.ipynb) | 09.07.2020 |
| PIFu | Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization | Ryota Natsume | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/pdf/1905.05172.pdf)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/shunsukesaito/PIFu)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=S1FpjwKqtPs)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1GFSsqP2BWz4gtq0e-nki00ZHSirXwFyY) | 18.06.2020 |
| 3D Ken Burns | This is a reference implementation of 3D Ken Burns Effect from a Single Image using PyTorch. Given a single input image, it animates this still image with a virtual camera scan and zoom subject to motion parallax. | Manuel Romero | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1909.05483)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=WrajxHHfRBA)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/sniklaus/3d-ken-burns)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/3D_Ken_Burns.ipynb) | 13.06.2020 |
| Multitrack MusicVAE | The models in this notebook are capable of encoding and decoding single measures of up to 8 tracks, optionally conditioned on an underlying chord | <ul><li>Ian Simon</li> <li>Adam Roberts</li> <li>Colin Raffel</li> <li>Jesse Engel</li> <li>Curtis Hawthorne</li> <li>Douglas Eck</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1806.00195)</li><li>[blog post](http://g.co/magenta/multitrack)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) | 02.06.2020 |
| MusicVAE | A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music | <ul><li>Adam Roberts</li> <li>Jesse Engel</li> <li>Colin Raffel</li> <li>Curtis Hawthorne</li> <li>Douglas Eck</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1803.05428)</li><li>[blog post](https://g.co/magenta/music-vae)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr)</li><li>[project](https://magenta.tensorflow.org/music-vae)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb) | 02.06.2020 |
| Background Matting | The notebook is split into three parts: required setup, running the algorithm on photos, and running it on videos | Andrey Ryabtsev | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2004.00626)</li><li>[blog post](https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/senguptaumd/Background-Matting)</li><li>[data](https://drive.google.com/open?id=1j3BMrRFhFpfzJAe6P2WDtfanoeSCLPiq)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/andreyryabtsev/243aa3eefa6e06891dda7b1583d1d08f/backmatting.ipynb) | 18.05.2020 |
| 3D Photo Inpainting | Method for converting a single RGB-D input image into a 3D photo, i.e., a multi-layer representation for novel view synthesis that contains hallucinated color and depth structures in regions occluded in the original view | Meng-Li Shih | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2004.04727)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/vt-vl-lab/3d-photo-inpainting)</li><li>[project](https://shihmengli.github.io/3D-Photo-Inpainting/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1706ToQrkIZshRSJSHvZ1RuCiM__YX3Bz) | 04.05.2020 |
| textgenrnn | Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity | Max Woolf | <ul><li>[blog post](http://minimaxir.com/2018/05/text-neural-networks/)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=RW7mP6BfZuY)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/minimaxir/textgenrnn)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK) | 28.04.2020 |
| CartoonGAN | This notebook contains the implementation of the cartoon GAN model with PyTorch | Tobias Sunderdiek | <ul><li>[cvpr](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf)</li><li>[project](https://tobiassunderdiek.github.io/cartoon-gan/)</li><li>[<img src="https://www.vectorlogo.zone/logos/kaggle/kaggle-icon.svg" alt="kaggle" height=20/>](https://www.kaggle.com/alamson/safebooru)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TobiasSunderdiek/cartoon-gan/blob/master/CartoonGAN.ipynb) | 13.04.2020 |
| Onsets and Frames | Onsets and Frames is an automatic music transcription framework with piano and drums models | <ul><li>Curtis Hawthorne</li> <li>Erich Elsen</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1710.11153), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.12247), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2004.00188)</li><li>[blog post](http://g.co/magenta/onsets-frames)</li><li>[data1](https://g.co/magenta/maestro-wave2midi2wave)</li><li>[data2](https://magenta.tensorflow.org/datasets/e-gmd)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://goo.gl/magenta/onsets-frames-code)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb) | 02.04.2020 |
| Classification of chest vs. adominal X-rays | The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays | tmoneyx01 | <ul><li>[annotator](https://public.md.ai/annotator/project/PVq9raBJ)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/mdai/mdai-client-py)</li><li>[docs](https://docs.md.ai/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson1-xray-images-classification.ipynb) | 07.03.2020 |
| Lung X-Rays Semantic Segmentation | This lesson applies a U-Net for Semantic Segmentation of the lung fields on chest x-rays | tmoneyx01 | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1505.04597)</li><li>[annotator](https://public.md.ai/annotator/project/aGq4k6NW)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/mdai/mdai-client-py)</li><li>[data](https://ceb.nlm.nih.gov/repositories/tuberculosis-chest-x-ray-image-data-sets/)</li><li>[docs](https://docs.md.ai/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson2-lung-xrays-segmentation.ipynb) | 07.03.2020 |
| WikiArt (stylegan2) | Generation of paintings of different styles and genres | Doron Adler | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1912.04958) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb) | 27.01.2020 |
| Earth Engine Python API and Folium Interactive Mapping | This notebook demonstrates how to setup the Earth Engine Python API in the Google Colaboratory platform and provides several examples for visualizing Earth Engine processed data interactively using the folium library | Qiusheng Wu | <ul><li>[api](https://developers.google.com/earth-engine/python_install)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/python-visualization/folium)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giswqs/qgis-earthengine-examples/blob/master/Folium/ee-api-folium-setup.ipynb) | 20.01.2020 |
| Traffic counting | Making Road Traffic Counting App based on Computer Vision and OpenCV | Andrey Nikishaev | <ul><li>[<img src="https://upload.vectorlogo.zone/logos/medium/images/43c41ba8-9de2-453d-92dc-500dab4e316a.svg" alt="medium" height=20/>](https://medium.com/machine-learning-world/tutorial-making-road-traffic-counting-app-based-on-computer-vision-and-opencv-166937911660)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=_o5iLbRHKao)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/creotiv/object_detection_projects/tree/master/opencv_traffic_counting)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12N4m_RYKqrpozRzh9qe7nQE_sIqQH9U8) | 10.01.2020 |
| GPT-2 | Retrain an advanced text generating neural network on any text dataset using gpt-2-simple! | Max Woolf | <ul><li>[blog post](https://minimaxir.com/2019/09/howto-gpt2/)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/minimaxir/gpt-2-simple)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) | 21.12.2019 |
| Learning to Paint | Learning to Paint With Model-based Deep Reinforcement Learning | Manuel Romero | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1903.04411)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=YmOgKZ5oipk)</li><li>[reddit](https://www.reddit.com/r/reinforcementlearning/comments/b5lpfl/learning_to_paint_with_modelbased_deep/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/custom_learningtopaint.ipynb) | 17.12.2019 |
| StyleGAN 2 | Generation of faces, cars, etc. | Mikael Christensen | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1912.04958) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ShgW6wohEFQtqs_znMna3dzrcVoABKIH) | 15.12.2019 |
| Imaging-AMARETTO | An imaging genomics software tool to systematically interrogate multi-omics networks for relevance to radiography and histopathology imaging biomarkers of clinical outcomes with application to studies of brain tumors | <ul><li>Nathalie Pochet</li> <li>Olivier Gevaert</li></ul> | <ul><li>[project](http://portals.broadinstitute.org/pochetlab/amaretto.html)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/broadinstitute/ImagingAMARETTO)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14u1KZJ3Gf-9qjDycyBKzBiN5VzzOa2xU) | 29.11.2019 |
| SVG VAE | A colab demo for the SVG VAE model | Raphael Gontijo Lopes | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1904.02632)</li><li>[blog post](https://magenta.tensorflow.org/svg-vae)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/vae_svg_decoding.ipynb) | 30.09.2019 |
| Generating Piano Music with Transformer | This Colab notebook lets you play with pretrained Transformer models for piano music generation, based on the Music Transformer model introduced by Huang et al. in 2018. | <ul><li>Ian Simon</li> <li>Anna Huang</li> <li>Jesse Engel</li> <li>Curtis "Fjord" Hawthorne</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.03762), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1809.04281)</li><li>[blog post](http://g.co/magenta/music-transformer)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb) | 16.09.2019 |
| Waifu2x | This is the Google Colab implementation of tsurumeso's chainer implementation of waifu2x, for people that do not have access to NVIDIA GPUs | Margesh Phirke | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/mphirke/Google-Colab-waifu2x-chainer)</li><li>[demo](http://waifu2x.udp.jp/)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](http://arxiv.org/abs/1501.00092)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mphirke/waifu2x-chainer/blob/master/Waifu2x_Colab_Implementation.ipynb) | 23.08.2019 |
| AMARETTO | Multiscale and multimodal inference of regulatory networks to identify cell circuits and their drivers shared and distinct within and across biological systems of human disease | <ul><li>Nathalie Pochet</li> <li>Olivier Gevaert</li></ul> | <ul><li>[project](http://portals.broadinstitute.org/pochetlab/amaretto.html)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/gevaertlab/AMARETTO)</li><li>[bioconductor](https://bioconductor.org/packages/release/bioc/html/AMARETTO.html)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JfnRoNgTVX_7VEGAAmjGjwP_yX2tdDxs) | 25.07.2019 |
| Breast Cancer detection | A Neural Network for detecting breast cancer in cell scans! | Peter Teoh | [blog post](http://www.laurencemoroney.com/easily-build-a-neural-net-for-breast-cancer-detection/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12DKmhi5z5Qx84iJQ8FTq5hHsG5UUHUcG) | 28.04.2019 |
| MusicXML Documentation | The goal of this notebook is to explore one of the magenta libraries for music | <ul><li>Prakruti Joshi</li> <li>Falak Shah</li> <li>Twisha Naik</li></ul> | <ul><li>[musicXML](https://www.musicxml.com/for-developers/)</li><li>[magenta](https://magenta.tensorflow.org/)</li><li>[music theory](http://musictheoryblog.blogspot.com/2008/02/learn-music-theory.html)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicXML_Document_Structure_Documentation.ipynb) | 05.04.2019 |
| BERT with TPU | Using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models and run predictions on tuned model | Google | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.04805)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/hub)</li><li>[TPU quickstart](https://cloud.google.com/tpu/docs/quickstart)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb) | 29.03.2019 |
| GANSynth | This notebook is a demo GANSynth, which generates audio with Generative Adversarial Networks | Jesse Engel | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1809.11096)</li><li>[project](https://storage.googleapis.com/magentadata/papers/gansynth/index.html)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](http://goo.gl/magenta/gansynth-code)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/magenta/gansynth/gansynth_demo.ipynb) | 25.02.2019 |
| Edge Detection | Edge detection in OpenCV and skimage | Yuhuang Hu | [<img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Wikipedia_logo_%28svg%29.svg" alt="wiki" height=20/>](https://en.wikipedia.org/wiki/Edge_detection) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10ZIvyVgDjGlWd09LJZzwboQs-4RPlCut) | 15.02.2019 |
| BERT on TF Hub | Predicting Movie Review Sentiment with BERT on TF Hub | Dale Markowitz | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.04805)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/google-research/bert)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb) | 12.02.2019 |
| Faceswap-GAN | This colab notebook is a minimum demo for faceswap-GAN v2.2 | shaoanlu | [<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/shaoanlu/faceswap-GAN) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shaoanlu/faceswap-GAN/blob/master/colab_demo/faceswap-GAN_colab_demo.ipynb) | 08.11.2018 |
| RSNA Pneumonia Detection Challenge (Kaggel API) | This notebook covers the basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation | tmoneyx01 | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1703.06870)</li><li>[<img src="https://www.vectorlogo.zone/logos/kaggle/kaggle-icon.svg" alt="kaggle" height=20/>](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)</li><li>[annotator](https://public.md.ai/annotator/project/LxR6zdR2/workspace)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/mdai/mdai-client-py)</li><li>[docs](https://docs.md.ai/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-kaggle.ipynb) | 03.09.2018 |
| HoF | This notebook will walk you step by step through the process of using a pre-trained model to detect faces in an image | Lucas Persona | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/the-house-of-black-and-white/hall-of-faces)</li><li>[data](http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/)</li><li>[yolo](https://pjreddie.com/darknet/yolo/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lJWquGmKoMm68qNuwjSnfMjjIi-UTzI1) | 23.04.2018 |
| Latent Constraints | Conditional Generation from Unconditional Generative Models | <ul><li>Jesse Engel</li> <li>Matthew Hoffman</li> <li>Adam Roberts</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1711.05772)</li><li>[data](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/latent_constraints/latentconstraints.ipynb) | 27.11.2017 |
| Performance RNN | This notebook shows you how to generate new performed compositions from a trained model | <ul><li>Ian Simon</li> <li>Sageev Oore</li> <li>Curtis Hawthorne</li></ul> | <ul><li>[blog post](https://magenta.tensorflow.org/performance-rnn)</li><li>[data](http://www.piano-e-competition.com/)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/magenta/magenta/tree/master/magenta/models/performance_rnn)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/magenta/performance_rnn/performance_rnn.ipynb) | 11.07.2017 |
| NSynth | This colab notebook has everything you need to upload your own sounds and use NSynth models to reconstruct and interpolate between them | <ul><li>Jesse Engel</li> <li>Cinjon Resnick</li> <li>Adam Roberts</li> <li>Sander Dieleman</li> <li>Karen Simonyan</li> <li>Mohammad Norouzi</li> <li>Doug Eck</li></ul> | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1704.01279)</li><li>[blog post](https://magenta.tensorflow.org/nsynth)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth)</li><li>[data](https://magenta.tensorflow.org/datasets/nsynth)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=AaALLWQmCdI), [<img src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg" alt="youtube" height=20/>](https://www.youtube.com/watch?v=BOoSy-Pg8is)</li><li>[tutorial](https://magenta.tensorflow.org/nsynth-fastgen)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/magenta/nsynth/nsynth.ipynb) | 06.04.2017 |
## Tutorials
| name | description | author | links | colaboratory | update |
|------|-------------|--------|:-----:|:------------:|:------:|
| Data augmentation | This tutorial demonstrates data augmentation: a technique to increase the diversity of your training set by applying random transformations such as image rotation | Google | [<img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Wikipedia_logo_%28svg%29.svg" alt="wiki" height=20/>](https://en.wikipedia.org/wiki/Data_augmentation) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb) | 21.12.2020 |
| CNN | This tutorial demonstrates training a simple Convolutional Neural Network to classify CIFAR images | Google | <ul><li>[link](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network)</li><li>[cifar](https://www.cs.toronto.edu/~kriz/cifar.html)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb) | 17.12.2020 |
| Integrated gradients | This tutorial demonstrates how to implement Integrated Gradients, an Explainable AI technique | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1703.01365) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb) | 17.12.2020 |
| Classify text with BERT | This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.04805) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/classify_text_with_bert.ipynb) | 14.12.2020 |
| GLUE using BERT on TPU | This tutorial contains complete end-to-end code to train models on a TPU | Google | <ul><li>[GLUE](https://gluebenchmark.com/)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1810.04805)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/guide/tpu)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/solve_glue_tasks_using_bert_on_tpu.ipynb) | 14.12.2020 |
| Building Your Own Federated Learning Algorithm | In this tutorial, we discuss how to implement federated learning algorithms without deferring to the tff.learning API | Zachary Charles | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model)</li><li>[blog post](https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1907.08610)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb) | 17.11.2020 |
| Text classification with RNN | This text classification tutorial trains a recurrent neural network on the IMDB large movie review dataset for sentiment analysis | Google | <ul><li>[link](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network)</li><li>[data](http://ai.stanford.edu/~amaas/data/sentiment/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb) | 09.11.2020 |
| Word embeddings | This tutorial contains an introduction to word embeddings | Google | [projector](http://projector.tensorflow.org/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word_embeddings.ipynb) | 03.11.2020 |
| Federated Learning for Image Classification | In this tutorial, we use the classic MNIST training example to introduce the Federated Learning (FL) API layer of TFF, tff.learning - a set of higher-level interfaces that can be used to perform common types of federated learning tasks, such as federated training, against user-supplied models implemented in TensorFlow | Krzysztof Ostrowski | <ul><li>[data](https://www.nist.gov/srd/nist-special-database-19)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1602.05629)</li><li>[<img src="https://upload.vectorlogo.zone/logos/medium/images/43c41ba8-9de2-453d-92dc-500dab4e316a.svg" alt="medium" height=20/>](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb) | 02.11.2020 |
| Transformer | This tutorial trains a Transformer model to translate Portuguese to English | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.03762) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb) | 01.11.2020 |
| Word2Vec | Word2Vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets | Google | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/pdf/1301.3781.pdf)</li><li>[neurips](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb) | 30.10.2020 |
| Image classification | This tutorial shows how to classify images of flowers | Google | [link](https://paperswithcode.com/task/image-classification) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb) | 22.10.2020 |
| Neural style transfer | This tutorial uses deep learning to compose one image in the style of another image | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1508.06576) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/style_transfer.ipynb) | 22.10.2020 |
| Custom Federated Algorithms, Part 1: Introduction to the Federated Core | This tutorial is the first part of a two-part series that demonstrates how to implement custom types of federated algorithms in TensorFlow Federated using the Federated Core - a set of lower-level interfaces that serve as a foundation upon which we have implemented the Federated Learning layer | Krzysztof Ostrowski | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/federated_core), [<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/federated_learning)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1602.05629)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_1.ipynb) | 21.10.2020 |
| Federated Learning for Text Generation | For this tutorial, we start with a RNN that generates ASCII characters, and refine it via federated learning | Krzysztof Ostrowski | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/hub)</li><li>[data1](http://www.ibiblio.org/pub/docs/books/gutenberg/9/98/98.txt)</li><li>[data2](http://www.ibiblio.org/pub/docs/books/gutenberg/4/46/46.txt)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1812.01097), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1602.05629)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb) | 17.10.2020 |
| Simple audio recognition | This tutorial will show you how to build a basic speech recognition network that recognizes ten different words | Google | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/datasets/catalog/speech_commands)</li><li>[coursera](https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb) | 16.10.2020 |
| Text generation with RNN | This tutorial demonstrates how to generate text using a character-based RNN | Google | [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb) | 13.10.2020 |
| Autoencoders | This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection. | Google | [book](https://www.deeplearningbook.org/contents/autoencoders.html) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/autoencoder.ipynb) | 05.10.2020 |
| Custom Federated Algorithms, Part 2: Implementing Federated Averaging | his tutorial is the second part of a two-part series that demonstrates how to implement custom types of federated algorithms in TFF using the Federated Core, which serves as a foundation for the Federated Learning layer | Krzysztof Ostrowski | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/federated_core), [<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/federated_learning)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/learning/federated_averaging.py)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_2.ipynb) | 05.10.2020 |
| DeepDream | This tutorial contains a minimal implementation of DeepDream: an experiment that visualizes the patterns learned by a neural network | Google | [blog post](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb) | 04.10.2020 |
| TFF for Federated Learning Research: Model and Update Compression | In this tutorial, we use the EMNIST dataset to demonstrate how to enable lossy compression algorithms to reduce communication cost in the Federated Averaging algorithm | Weikang Song | <ul><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist), [<img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="tf" height=20/>](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process)</li><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1602.05629)</li><li>[tensor encoding](http://jakubkonecny.com/files/tensor_encoding.pdf)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/tff_for_federated_learning_research_compression.ipynb) | 30.09.2020 |
| CycleGAN | This notebook demonstrates unpaired image to image translation using conditional GAN's | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1703.10593) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb) | 29.09.2020 |
| Image captioning | Given an image our goal is to generate a caption | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1502.03044) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb) | 24.09.2020 |
| Transfer learning and fine-tuning | In this tutorial, you will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network | François Chollet | [<img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Wikipedia_logo_%28svg%29.svg" alt="wiki" height=20/>](https://en.wikipedia.org/wiki/Transfer_learning) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb) | 16.09.2020 |
| Image segmentation | This tutorial focuses on the task of image segmentation, using a modified U-Net | Google | [u-net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb) | 10.09.2020 |
| High-performance Simulation with Kubernetes | This tutorial will describe how to set up high-performance simulation using a TFF runtime running on Kubernetes | Jason Roselander | <ul><li>[GKE](https://cloud.google.com/kubernetes-engine/)</li><li>[shell](https://cloud.google.com/shell/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb) | 09.09.2020 |
| Adversarial FGSM | This tutorial creates an adversarial example using the Fast Gradient Signed Method attack. This was one of the first and most popular attacks to fool a neural network. | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1412.6572) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb) | 09.09.2020 |
| CVAE | This notebook demonstrates how train a Variational Autoencoder on the MNIST dataset | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1312.6114), [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1401.4082) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb) | 09.09.2020 |
| DCGAN | This tutorial demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/pdf/1511.06434.pdf) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb) | 09.09.2020 |
| Pix2Pix | This notebook demonstrates image to image translation using conditional GAN's | Google | [<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1611.07004) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb) | 09.09.2020 |
| Actor-Critic | This tutorial demonstrates how to implement the Actor-Critic method using TensorFlow to train an agent on the Open AI Gym CartPole-V0 environment | Google | <ul><li>[neurips1](https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf)</li><li>[gym](https://gym.openai.com/)</li><li>[neurips2](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Wikipedia_logo_%28svg%29.svg" alt="wiki" height=20/>](https://en.wikipedia.org/wiki/Temporal_difference_learning)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb) | 09.09.2020 |
| NMT with attention | This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation | Google | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/pdf/1409.0473.pdf)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Wikipedia_logo_%28svg%29.svg" alt="wiki" height=20/>](https://en.wikipedia.org/wiki/Neural_machine_translation)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb) | 09.09.2020 |
| High-performance simulations with TFF | This tutorial will describe how to setup high-performance simulations with TFF in a variety of common scenarios | Krzysztof Ostrowski |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/simulations.ipynb) | 28.07.2020 |
| RSNA Pneumonia Detection Challenge (MD.ai API) | This notebook covers the basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation | tmoneyx01 | <ul><li>[<img src="https://web.science.mq.edu.au/~cpurcell/public/images/arxiv_logo.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1703.06870)</li><li>[<img src="https://www.vectorlogo.zone/logos/kaggle/kaggle-icon.svg" alt="kaggle" height=20/>](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)</li><li>[annotator](https://public.md.ai/annotator/project/LxR6zdR2/workspace)</li><li>[<img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="git" height=20/>](https://github.com/mdai/mdai-client-py)</li><li>[docs](https://docs.md.ai/)</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-mdai-client-lib.ipynb) | 29.08.2018 |
(generated by [generate_markdown.py](./generate_markdown.py) based on [research.json](research.json) and [tutorials.json](tutorials.json))
