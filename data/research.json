[
    {
        "name": "3D Ken Burns",
        "description": "A reference implementation of 3D Ken Burns Effect from a Single Image using PyTorch - given a single input image, it animates this still image with a virtual camera scan and zoom subject to motion parallax",
        "author": [
            [
                "Manuel Romero",
                "https://mrm8488.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1909.05483"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=WrajxHHfRBA"
            ],
            [
                "git",
                "https://github.com/sniklaus/3d-ken-burns"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/3D_Ken_Burns.ipynb",
        "update": 1592062693.0
    },
    {
        "name": "Learning to Paint",
        "description": "Learning to Paint With Model-based Deep Reinforcement Learning",
        "author": [
            [
                "Manuel Romero",
                "https://mrm8488.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1903.04411"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=YmOgKZ5oipk"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/reinforcementlearning/comments/b5lpfl/learning_to_paint_with_modelbased_deep/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/custom_learningtopaint.ipynb",
        "update": 1576600536.0
    },
    {
        "name": "WikiArt (stylegan2)",
        "description": "Generation of paintings of different styles and genres",
        "author": [
            [
                "Doron Adler",
                "https://linktr.ee/Norod78"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb",
        "update": 1580100143.0
    },
    {
        "name": "WikiArt (stylegan2-ada)",
        "description": "Generation of paintings of different styles and genres",
        "author": [
            [
                "Doron Adler",
                "https://linktr.ee/Norod78"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2006.06676"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_ADA_Example_Generation.ipynb",
        "update": 1607407403.0
    },
    {
        "name": "GPT-2",
        "description": "Retrain an advanced text generating neural network on any text dataset using gpt-2-simple!",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://minimaxir.com/2019/09/howto-gpt2/"
            ],
            [
                "git",
                "https://github.com/minimaxir/gpt-2-simple"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce",
        "update": 1634524182.04
    },
    {
        "name": "textgenrnn",
        "description": "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "http://minimaxir.com/2018/05/text-neural-networks/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=RW7mP6BfZuY"
            ],
            [
                "git",
                "https://github.com/minimaxir/textgenrnn"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK",
        "update": 1626144610.804
    },
    {
        "name": "Train a GPT-2 Model on Tweets",
        "description": "Train the model on your downloaded tweets, and generate massive amounts of Tweets from it",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/download-tweets-ai-text-gen"
            ],
            [
                "GPT-2",
                "https://openai.com/blog/better-language-models/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1qxcQ2A1nNjFudAGN_mcMOnvV9sF_PkEb",
        "update": 1579148034.702
    },
    {
        "name": "automl-gs on a TPU",
        "description": "Give an input CSV file and a target field you want to predict to automl-gs, and get a trained high-performing machine learning or deep learning model plus native Python code pipelines allowing you to integrate that model into any prediction workflow",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/automl-gs"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1sbF8cqnOsdzN9Bdt74eER5s_xXcdvatV",
        "update": 1553580859.738
    },
    {
        "name": "Imaging-AMARETTO",
        "description": "An imaging genomics software tool to systematically interrogate multi-omics networks for relevance to radiography and histopathology imaging biomarkers of clinical outcomes with application to studies of brain tumors",
        "author": [
            [
                "Nathalie Pochet",
                "http://portals.broadinstitute.org/pochetlab/"
            ],
            [
                "Olivier Gevaert",
                "https://profiles.stanford.edu/olivier-gevaert"
            ],
            [
                "Mohsen Nabian",
                "https://github.com/monabiyan"
            ],
            [
                "Celine Everaert",
                "http://www.crig.ugent.be/en/node/510"
            ],
            [
                "Jayendra Shinde",
                "https://jayendrashinde91.github.io/"
            ],
            [
                "Artur Manukyan",
                "https://artur-man.github.io/"
            ],
            [
                "Thorin Tabor",
                "http://thorin.tabcreations.com/"
            ],
            [
                "Mikel Hernaez",
                "http://mikelhernaez.github.io/"
            ],
            [
                "Jill Mesirov",
                "https://en.wikipedia.org/wiki/Jill_P._Mesirov"
            ]
        ],
        "links": [
            [
                "project",
                "http://portals.broadinstitute.org/pochetlab/amaretto.html"
            ],
            [
                "git",
                "https://github.com/broadinstitute/ImagingAMARETTO"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/14u1KZJ3Gf-9qjDycyBKzBiN5VzzOa2xU",
        "update": 1575041033.629
    },
    {
        "name": "AMARETTO",
        "description": "Multiscale and multimodal inference of regulatory networks to identify cell circuits and their drivers shared and distinct within and across biological systems of human disease",
        "author": [
            [
                "Nathalie Pochet",
                "http://portals.broadinstitute.org/pochetlab/"
            ],
            [
                "Olivier Gevaert",
                "https://profiles.stanford.edu/olivier-gevaert"
            ],
            [
                "Mohsen Nabian",
                "https://github.com/monabiyan"
            ],
            [
                "Jayendra Shinde",
                "https://jayendrashinde91.github.io/"
            ],
            [
                "Celine Everaert",
                "http://www.crig.ugent.be/en/node/510"
            ],
            [
                "Thorin Tabor",
                "http://thorin.tabcreations.com/"
            ]
        ],
        "links": [
            [
                "project",
                "http://portals.broadinstitute.org/pochetlab/amaretto.html"
            ],
            [
                "git",
                "https://github.com/gevaertlab/AMARETTO"
            ],
            [
                "bioconductor",
                "https://bioconductor.org/packages/release/bioc/html/AMARETTO.html"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JfnRoNgTVX_7VEGAAmjGjwP_yX2tdDxs",
        "update": 1564051448.504
    },
    {
        "name": "Customizing a Transformer Encoder",
        "description": "We will learn how to customize the encoder to employ new network architectures",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "git",
                "https://github.com/tensorflow/models/tree/master/official/nlp/modeling"
            ],
            [
                "git",
                "https://github.com/tensorflow/models/blob/master/official/nlp/modeling/networks/encoder_scaffold.py"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/nlp/customize_encoder.ipynb",
        "update": 1650633017.0
    },
    {
        "name": "Fine-tuning a BERT",
        "description": "We will work through fine-tuning a BERT model using the tensorflow-models PIP package",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ],
            [
                "Claire Yao",
                "https://github.com/claireyao-fen"
            ]
        ],
        "links": [
            [
                "tf",
                "https://tensorflow.org/hub"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb",
        "update": 1621888437.0
    },
    {
        "name": "First Order Motion Model for Image Animation",
        "description": "Transferring facial movements from video to image",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/2019/hash/31c0b36aef265d9221af80872ceb62f9-Abstract.html"
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/first-order-model"
            ],
            [
                "project",
                "https://aliaksandrsiarohin.github.io/first-order-model-website/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=u-0cQ-grXBQ"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb",
        "update": 1625073459.0
    },
    {
        "name": "Motion Supervised co-part Segmentation",
        "description": "A self-supervised deep learning method for co-part segmentation",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ],
            [
                "Subhankar Roy",
                "https://github.com/roysubhankar"
            ]
        ],
        "links": [
            [
                "arxiv",
                "http://arxiv.org/abs/2004.03234"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=RJ4Nj1wV5iA"
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/motion-cosegmentation"
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/video-preprocessing"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AliaksandrSiarohin/motion-cosegmentation/blob/master/part_swap.ipynb",
        "update": 1586274932.0
    },
    {
        "name": "Motion Representations for Articulated Animation",
        "description": "Novel motion representations for animating articulated objects consisting of distinct parts",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ],
            [
                "Oliver Woodford",
                "https://ojwoodford.github.io/"
            ],
            [
                "Jian Ren",
                "https://alanspike.github.io/"
            ],
            [
                "Menglei Chai",
                "https://mlchai.com/"
            ],
            [
                "Sergey Tulyakov",
                "http://www.stulyakov.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://snap-research.github.io/articulated-animation/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.11280"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=gpBYN8t8_yY"
            ],
            [
                "git",
                "https://github.com/snap-research/articulated-animation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AliaksandrSiarohin/articulated-animation/blob/master/demo.ipynb",
        "update": 1619709660.0
    },
    {
        "name": "DeOldify (video)",
        "description": "Colorize your own videos!",
        "author": [
            [
                "Jason Antic",
                "https://github.com/jantic"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08500"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/Nickelodeons/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/silentmoviegifs/"
            ],
            [
                "youtube",
                "http://www.youtube.com/watch?v=l3UXXid04Ys"
            ],
            [
                "youtube",
                "http://www.youtube.com/watch?v=EXn-n2iqEjI"
            ],
            [
                "model",
                "https://data.deepai.org/deoldify/ColorizeVideo_gen.pth"
            ],
            [
                "medium",
                "https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb",
        "update": 1605241178.0
    },
    {
        "name": "DeOldify (photo)",
        "description": "Colorize your own photos!",
        "author": [
            [
                "Jason Antic",
                "https://github.com/jantic"
            ],
            [
                "Matt Robinson",
                "https://github.com/mc-robinson"
            ],
            [
                "María Benavente",
                "https://github.com/mariabg"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08500"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/TheWayWeWere/"
            ],
            [
                "model",
                "https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb",
        "update": 1605241178.0
    },
    {
        "name": "StyleGAN 2",
        "description": "Generation of faces, cars, etc.",
        "author": [
            [
                "Mikael Christensen",
                "https://github.com/Syntopia"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1ShgW6wohEFQtqs_znMna3dzrcVoABKIH",
        "update": 1636142903.17
    },
    {
        "name": "Edge Detection",
        "description": "Edge detection in OpenCV and skimage",
        "author": [
            [
                "Yuhuang Hu",
                "https://dgyblog.com/"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Edge_detection"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/10ZIvyVgDjGlWd09LJZzwboQs-4RPlCut",
        "update": 1550255216.592
    },
    {
        "name": "Faceswap-GAN",
        "description": "A minimum demo for faceswap-GAN v2.2",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/faceswap-GAN"
            ]
        ],
        "colab": "https://colab.research.google.com/github/shaoanlu/faceswap-GAN/blob/master/colab_demo/faceswap-GAN_colab_demo.ipynb",
        "update": 1599880270.0
    },
    {
        "name": "GazeML",
        "description": "Eye region landmarks detection",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/GazeML-keras"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=cLUHKYfZN5s"
            ]
        ],
        "colab": "https://colab.research.google.com/github/shaoanlu/GazeML-keras/blob/master/demo_colab.ipynb",
        "update": 1554272200.0
    },
    {
        "name": "Few-shot face translation",
        "description": "A GAN based approach for one model to swap them all: model is capable of producing faces that has its gaze direction, glasses, and hiar occlusions being consistent with given source face",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/fewshot-face-translation-GAN"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1903.07291"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.01723"
            ],
            [
                "link",
                "https://drum.lib.umd.edu/handle/1903/21337"
            ]
        ],
        "colab": "https://colab.research.google.com/github/shaoanlu/fewshot-face-translation-GAN/blob/master/colab_demo.ipynb",
        "update": 1567380828.0
    },
    {
        "name": "Face toolbox",
        "description": "A collection of deep learning frameworks ported to Keras for face detection, face segmentation, face parsing, iris detection, and face verification",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/face_toolbox_keras"
            ]
        ],
        "colab": "https://colab.research.google.com/github/shaoanlu/face-toolbox-keras/blob/master/demo.ipynb",
        "update": 1570083478.0
    },
    {
        "name": "Group Normalization",
        "description": "A simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization.",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/GroupNormalization-keras"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1803.08494"
            ],
            [
                "blog post",
                "https://shaoanlu.wordpress.com/2018/03/26/experiment-with-group-normalization/"
            ],
            [
                "git",
                "https://github.com/zalandoresearch/fashion-mnist"
            ]
        ],
        "colab": "https://colab.research.google.com/github/shaoanlu/GroupNormalization-keras/blob/master/group_norm_experiments.ipynb",
        "update": 1522041641.0
    },
    {
        "name": "Traffic counting",
        "description": "Making Road Traffic Counting App based on Computer Vision and OpenCV",
        "author": [
            [
                "Andrey Nikishaev",
                "https://github.com/creotiv"
            ]
        ],
        "links": [
            [
                "medium",
                "https://medium.com/machine-learning-world/tutorial-making-road-traffic-counting-app-based-on-computer-vision-and-opencv-166937911660"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_o5iLbRHKao"
            ],
            [
                "git",
                "https://github.com/creotiv/object_detection_projects/tree/master/opencv_traffic_counting"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12N4m_RYKqrpozRzh9qe7nQE_sIqQH9U8",
        "update": 1578663579.317
    },
    {
        "name": "DFL-Colab",
        "description": "This project provides you IPython Notebook to use DeepFaceLab",
        "author": [
            [
                "chervonij",
                "https://github.com/chervonij"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05535"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCTKBl8kB6DJ_qLnk1NGDGbQ"
            ],
            [
                "guide",
                "https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial"
            ],
            [
                "git",
                "https://github.com/iperov/DeepFaceLab"
            ]
        ],
        "colab": "https://colab.research.google.com/github/chervonij/DFL-Colab/blob/master/DFL_Colab.ipynb",
        "update": 1642708247.0
    },
    {
        "name": "Breast Cancer detection",
        "description": "A Neural Network for detecting breast cancer in cell scans!",
        "author": [
            [
                "Peter Teoh",
                "https://github.com/tthtlc"
            ]
        ],
        "links": [
            [
                "blog post",
                "http://www.laurencemoroney.com/easily-build-a-neural-net-for-breast-cancer-detection/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12DKmhi5z5Qx84iJQ8FTq5hHsG5UUHUcG",
        "update": 1556419846.973
    },
    {
        "name": "Waifu2x",
        "description": "This is the Google Colab implementation of tsurumeso's chainer implementation of waifu2x",
        "author": [
            [
                "Margesh Phirke",
                "https://github.com/mphirke"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mphirke/Google-Colab-waifu2x-chainer"
            ],
            [
                "demo",
                "http://waifu2x.udp.jp/"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1501.00092"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mphirke/waifu2x-chainer/blob/master/Waifu2x_Colab_Implementation.ipynb",
        "update": 1566575812.0
    },
    {
        "name": "BERT on TF Hub",
        "description": "Predicting Movie Review Sentiment with BERT on TF Hub",
        "author": [
            [
                "Dale Markowitz",
                "https://daleonai.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "git",
                "https://github.com/google-research/bert"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb",
        "update": 1550001623.0
    },
    {
        "name": "Analyzing Tennis Serve",
        "description": "We'll use the Video Intelligence API to analyze a tennis serve, including the angle of the arms and legs during the serve",
        "author": [
            [
                "Dale Markowitz",
                "https://daleonai.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://daleonai.com/machine-learning-for-sports"
            ],
            [
                "git",
                "https://github.com/google/making_with_ml/tree/master/sports_ai"
            ],
            [
                "medium",
                "https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=yLrOy2Xedgk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/making_with_ml/blob/master/sports_ai/Sports_AI_Analysis.ipynb",
        "update": 1594745619.0
    },
    {
        "name": "PIFu",
        "description": "Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization",
        "author": [
            [
                "Ryota Natsume",
                "https://github.com/nanopoteto"
            ],
            [
                "Shunsuke Saito",
                "https://github.com/shunsukesaito"
            ],
            [
                "Zeng Huang",
                "https://zeng.science/"
            ],
            [
                "Angjoo Kanazawa",
                "https://people.eecs.berkeley.edu/~kanazawa/"
            ],
            [
                "Hao Li",
                "http://hao.li"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1905.05172"
            ],
            [
                "git",
                "https://github.com/shunsukesaito/PIFu"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=S1FpjwKqtPs"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1GFSsqP2BWz4gtq0e-nki00ZHSirXwFyY",
        "update": 1592428040.528
    },
    {
        "name": "PIFuHD",
        "description": "Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization",
        "author": [
            [
                "Shunsuke Saito",
                "https://github.com/shunsukesaito"
            ],
            [
                "Tomas Simon",
                "http://www.cs.cmu.edu/~tsimon/"
            ],
            [
                "Jason Saragih",
                "https://scholar.google.com/citations?user=ss-IvjMAAAAJ"
            ],
            [
                "Hanbyul Joo",
                "https://jhugestar.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.00452"
            ],
            [
                "git",
                "https://github.com/facebookresearch/pifuhd"
            ],
            [
                "youtube",
                "https://youtu.be/uEDqCxvF5yc"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=8qnwbbDS8xk"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/11z58bl3meSzo6kFqkahMa35G5jmh2Wgt",
        "update": 1609866428.455
    },
    {
        "name": "CartoonGAN",
        "description": "The implementation of the cartoon GAN model with PyTorch",
        "author": [
            [
                "Tobias Sunderdiek",
                "https://github.com/TobiasSunderdiek"
            ]
        ],
        "links": [
            [
                "cvpr",
                "http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"
            ],
            [
                "project",
                "https://tobiassunderdiek.github.io/cartoon-gan/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alamson/safebooru"
            ]
        ],
        "colab": "https://colab.research.google.com/github/TobiasSunderdiek/cartoon-gan/blob/master/CartoonGAN.ipynb",
        "update": 1637760742.0
    },
    {
        "name": "HoF",
        "description": "This notebook will walk you step by step through the process of using a pre-trained model to detect faces in an image",
        "author": [
            [
                "Lucas Persona",
                "http://www.lucaspersona.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/the-house-of-black-and-white/hall-of-faces"
            ],
            [
                "data",
                "http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/"
            ],
            [
                "yolo",
                "https://pjreddie.com/darknet/yolo/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1lJWquGmKoMm68qNuwjSnfMjjIi-UTzI1",
        "update": 1524486647.85
    },
    {
        "name": "Background Matting",
        "description": "The notebook is split into three parts: required setup, running the algorithm on photos, and running it on videos",
        "author": [
            [
                "Andrey Ryabtsev",
                "https://github.com/andreyryabtsev"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.00626"
            ],
            [
                "blog post",
                "https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635"
            ],
            [
                "git",
                "https://github.com/senguptaumd/Background-Matting"
            ],
            [
                "data",
                "https://drive.google.com/open?id=1j3BMrRFhFpfzJAe6P2WDtfanoeSCLPiq"
            ]
        ],
        "colab": "https://colab.research.google.com/gist/andreyryabtsev/243aa3eefa6e06891dda7b1583d1d08f/backmatting.ipynb",
        "update": 1589806735.0
    },
    {
        "name": "YOLOv3",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov3"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov3"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ultralytics/yolov3/blob/master/tutorial.ipynb",
        "update": 1636919318.0
    },
    {
        "name": "YOLOv5",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov5"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov5"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb",
        "update": 1650935148.0
    },
    {
        "name": "ByteTrack",
        "description": "Multi-Object Tracking by Associating Every Detection Box",
        "author": [
            [
                "Yifu Zhang",
                "https://github.com/ifzhang"
            ],
            [
                "Peize Sun",
                "https://peizesun.github.io/"
            ],
            [
                "Yi Jiang",
                "https://github.com/iFighting"
            ],
            [
                "Dongdong Yu",
                "https://miracle-fmh.github.io/"
            ],
            [
                "Ping Luo",
                "http://luoping.me/"
            ],
            [
                "Xinggang Wang",
                "https://xinggangw.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ifzhang/ByteTrack"
            ],
            [
                "git",
                "https://github.com/Megvii-BaseDetection/YOLOX"
            ],
            [
                "git",
                "https://github.com/ifzhang/FairMOT"
            ],
            [
                "git",
                "https://github.com/PeizeSun/TransTrack"
            ],
            [
                "git",
                "https://github.com/samylee/Towards-Realtime-MOT-Cpp"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2110.06864"
            ],
            [
                "data",
                "https://motchallenge.net/"
            ],
            [
                "data",
                "https://www.crowdhuman.org/"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/multi-object-tracking"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1bDilg4cmXFa8HCKHbsZ_p16p0vrhLyu0",
        "update": 1635566517.748
    },
    {
        "name": "3D Photo Inpainting",
        "description": "Method for converting a single RGB-D input image into a 3D photo, i.e., a multi-layer representation for novel view synthesis that contains hallucinated color and depth structures in regions occluded in the original view",
        "author": [
            [
                "Meng-Li Shih",
                "https://shihmengli.github.io/"
            ],
            [
                "Shih-Yang Su",
                "https://lemonatsu.github.io/"
            ],
            [
                "Johannes Kopf",
                "https://johanneskopf.de/"
            ],
            [
                "Jia-Bin Huang",
                "https://filebox.ece.vt.edu/~jbhuang/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.04727"
            ],
            [
                "git",
                "https://github.com/vt-vl-lab/3d-photo-inpainting"
            ],
            [
                "project",
                "https://shihmengli.github.io/3D-Photo-Inpainting/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1706ToQrkIZshRSJSHvZ1RuCiM__YX3Bz",
        "update": 1588579458.042
    },
    {
        "name": "Flow-edge Guided Video Completion",
        "description": "Method first extracts and completes motion edges, and then uses them to guide piecewise-smooth flow completion with sharp edges",
        "author": [
            [
                "Chen Gao",
                "http://chengao.vision/"
            ],
            [
                "Ayush Saraf",
                "https://github.com/ayush29feb"
            ],
            [
                "Johannes Kopf",
                "https://johanneskopf.de/"
            ],
            [
                "Jia-Bin Huang",
                "https://filebox.ece.vt.edu/~jbhuang/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2009.01835"
            ],
            [
                "git",
                "https://github.com/vt-vl-lab/FGVC"
            ],
            [
                "project",
                "http://chengao.vision/FGVC/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=CHHVPxHT7rc"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1pb6FjWdwq_q445rG2NP0dubw7LKNUkqc",
        "update": 1609361825.432
    },
    {
        "name": "Earth Engine Python API and Folium Interactive Mapping",
        "description": "This notebook demonstrates how to setup the Earth Engine and provides several examples for visualizing Earth Engine processed data interactively using the folium library",
        "author": [
            [
                "Qiusheng Wu",
                "https://wetlands.io/"
            ]
        ],
        "links": [
            [
                "api",
                "https://developers.google.com/earth-engine/python_install"
            ],
            [
                "git",
                "https://github.com/python-visualization/folium"
            ]
        ],
        "colab": "https://colab.research.google.com/github/giswqs/qgis-earthengine-examples/blob/master/Folium/ee-api-folium-setup.ipynb",
        "update": 1579526571.0
    },
    {
        "name": "Instance-aware Image Colorization",
        "description": "Novel deep learning framework to achieve instance-aware colorization",
        "author": [
            [
                "Jheng-Wei Su",
                "https://github.com/ericsujw"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2005.10825"
            ],
            [
                "git",
                "https://github.com/ericsujw/InstColorization"
            ],
            [
                "project",
                "https://ericsujw.github.io/InstColorization/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Zj1N4uE1ehk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ericsujw/InstColorization/blob/master/InstColorization.ipynb",
        "update": 1598771700.0
    },
    {
        "name": "Adversarial Patch",
        "description": "A method to create universal, robust, targeted adversarial image patches in the real world",
        "author": [
            [
                "Tom Brown",
                "https://github.com/nottombrown"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1712.09665"
            ]
        ],
        "colab": "https://colab.research.google.com/github/cleverhans-lab/cleverhans/blob/master/examples/adversarial_patch/AdversarialPatch.ipynb",
        "update": 1611749406.0
    },
    {
        "name": "RNN for Predictive Maintenance",
        "description": "LSTM network in order to predict remaining useful life of aircraft engines",
        "author": [
            [
                "Umberto Griffo",
                "https://github.com/umbertogriffo"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/umbertogriffo/Predictive-Maintenance-using-LSTM"
            ],
            [
                "git",
                "https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb"
            ],
            [
                "link",
                "https://gallery.azure.ai/Experiment/Predictive-Maintenance-Step-2A-of-3-train-and-evaluate-regression-models-2"
            ],
            [
                "data",
                "https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1tjIOud2Cc6smmvZsbl-QDBA6TLA2iEtd",
        "update": 1585901739.618
    },
    {
        "name": "MakeItTalk",
        "description": "A method that generates expressive talking-head videos from a single facial image with audio as the only input",
        "author": [
            [
                "Yang Zhou",
                "https://people.umass.edu/~yangzhou/"
            ],
            [
                "Xintong Han",
                "http://users.umiacs.umd.edu/~xintong/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Jose Echevarria",
                "http://www.jiechevarria.com/"
            ],
            [
                "Evangelos Kalogerakis",
                "https://people.cs.umass.edu/~kalo/"
            ],
            [
                "Dingzeyu Li",
                "https://dingzeyu.li/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.12992"
            ],
            [
                "project",
                "https://people.umass.edu/~yangzhou/MakeItTalk/"
            ],
            [
                "git",
                "https://github.com/yzhou359/MakeItTalk"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=vUMGKASgbf8"
            ],
            [
                "data",
                "https://drive.google.com/drive/folders/1EwuAy3j1b9Zc1MsidUfxG_pJGc_cV60O"
            ]
        ],
        "colab": "https://colab.research.google.com/github/yzhou359/MakeItTalk/blob/master/quick_demo.ipynb",
        "update": 1605028739.0
    },
    {
        "name": "Taming Transformers for High-Resolution Image Synthesis",
        "description": "We combine the efficiancy of convolutional approaches with the expressivity of transformers by introducing a convolutional VQGAN, which learns a codebook of context-rich visual parts, whose composition is modeled with an autoregressive transformer",
        "author": [
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Björn Ommer",
                "https://hci.iwr.uni-heidelberg.de/people/bommer"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "git",
                "https://github.com/CompVis/taming-transformers"
            ],
            [
                "project",
                "https://compvis.github.io/taming-transformers/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb",
        "update": 1642089007.0
    },
    {
        "name": "Geometry-Free View Synthesis",
        "description": "Is a geometric model required to synthesize novel views from a single image?",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Björn Ommer",
                "https://hci.iwr.uni-heidelberg.de/people/bommer"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.07652"
            ],
            [
                "data",
                "https://google.github.io/realestate10k/"
            ],
            [
                "git",
                "https://github.com/CompVis/geometry-free-view-synthesis"
            ],
            [
                "git",
                "https://github.com/colmap/colmap"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CompVis/geometry-free-view-synthesis/blob/master/scripts/braindance.ipynb",
        "update": 1619084473.0
    },
    {
        "name": "Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes",
        "description": "A method to stylize images by optimizing parameterized brushstrokes instead of pixels",
        "author": [
            [
                "Dmytro Kotovenko",
                "https://scholar.google.de/citations?user=T_U8yxwAAAAJ"
            ],
            [
                "Matthias Wright",
                "https://matthias-wright.github.io/"
            ],
            [
                "Arthur Heimbrecht",
                "https://github.com/arwehei"
            ],
            [
                "Björn Ommer",
                "https://hci.iwr.uni-heidelberg.de/people/bommer"
            ]
        ],
        "links": [
            [
                "project",
                "https://compvis.github.io/brushstroke-parameterized-style-transfer/"
            ],
            [
                "git",
                "https://github.com/CompVis/brushstroke-parameterized-style-transfer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17185"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CompVis/brushstroke-parameterized-style-transfer/blob/tensorflow_v2/notebooks/BrushstrokeStyleTransfer_TF2.ipynb",
        "update": 1622621701.0
    },
    {
        "name": "bsuite",
        "description": "A collection of carefully-designed experiments that investigate core capabilities of an RL agent with two main objectives",
        "author": [
            [
                "Ian Osband",
                "http://iosband.github.io/"
            ]
        ],
        "links": [
            [
                "paper",
                "https://openreview.net/forum?id=rygf-kSYwH"
            ],
            [
                "git",
                "https://github.com/deepmind/bsuite"
            ],
            [
                "git",
                "https://github.com/openai/gym"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1rU20zJ281sZuMD1DHbsODFr1DbASL0RH",
        "update": 1613174366.054
    },
    {
        "name": "NFNet",
        "description": "An adaptive gradient clipping technique, a significantly improved class of Normalizer-Free ResNets",
        "author": [
            [
                "Andrew Brock",
                "https://github.com/ajbrock"
            ],
            [
                "Soham De",
                "https://sohamde.github.io/"
            ],
            [
                "Samuel L. Smith",
                "https://scholar.google.co.uk/citations?user=fyEqU5oAAAAJ"
            ],
            [
                "Karen Simonyan",
                "https://scholar.google.com/citations?user=L7lMQkQAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2102.06171"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2101.08692"
            ],
            [
                "git",
                "https://github.com/deepmind/deepmind-research/tree/master/nfnets"
            ],
            [
                "git",
                "https://github.com/deepmind/jaxline"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/deepmind-research/blob/master/nfnets/nfnet_demo_colab.ipynb",
        "update": 1613576576.0
    },
    {
        "name": "Skillful Precipitation Nowcasting Using Deep Generative Models of Radar",
        "description": "Open-sourced dataset and model snapshot for precipitation nowcasting",
        "author": [
            [
                "Suman Ravuri",
                "https://www.linkedin.com/in/suman-ravuri-81928082"
            ],
            [
                "Karel Lenc",
                "https://www.robots.ox.ac.uk/~karel/"
            ],
            [
                "Matthew Willson",
                "https://www.linkedin.com/in/matthew-willson-6a1b422"
            ],
            [
                "Dmitry Kangin",
                "https://scholar.google.com/citations?user=vv-leaMAAAAJ"
            ],
            [
                "Rémi Lam",
                "https://scholar.google.com/citations?user=Sm7xCbEAAAAJ"
            ],
            [
                "Piotr Mirowski",
                "https://piotrmirowski.com/"
            ],
            [
                "Maria Athanassiadou",
                "https://scholar.google.com/citations?user=VtkgHP0AAAAJ"
            ],
            [
                "Sheleem Kashem",
                "https://www.linkedin.com/in/sheleemkashem/"
            ],
            [
                "Rachel Prudden",
                "https://scholar.google.com/citations?user=uf39AF8AAAAJ"
            ],
            [
                "Amol Mandhane",
                "https://github.com/amol-mandhane"
            ],
            [
                "Aidan Clark",
                "https://scholar.google.com/citations?user=uf39AF8AAAAJ"
            ],
            [
                "Andrew Brock",
                "https://github.com/ajbrock"
            ],
            [
                "Karen Simonyan",
                "https://scholar.google.com/citations?user=L7lMQkQAAAAJ"
            ],
            [
                "Raia Hadsell",
                "https://github.com/raiah"
            ],
            [
                "Niall Robinson",
                "https://github.com/niallrobinson"
            ],
            [
                "Ellen Clancy",
                "https://www.linkedin.com/in/ellen-clancy-815967124"
            ],
            [
                "Shakir Mohamed",
                "https://www.shakirm.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00954"
            ],
            [
                "git",
                "https://github.com/deepmind/deepmind-research/tree/master/nowcasting"
            ],
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "local kernel",
                "https://research.google.com/colaboratory/local-runtimes.html"
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/nowcasting"
            ],
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03854-z"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/deepmind-research/blob/master/nowcasting/Open_sourced_dataset_and_model_snapshot_for_precipitation_nowcasting.ipynb",
        "update": 1632916830.0
    },
    {
        "name": "AlphaFold",
        "description": "Highly accurate protein structure prediction",
        "author": [
            [
                "John Jumper",
                "https://scholar.google.com/citations?user=a5goOh8AAAAJ"
            ],
            [
                "Richard Evans",
                "http://www.doc.ic.ac.uk/~re14/"
            ],
            [
                "Alexander Pritzel",
                "https://scholar.google.com/citations?user=GPgAyU0AAAAJ"
            ],
            [
                "Tim Green",
                "http://tfgg.me/"
            ],
            [
                "Michael Figurnov",
                "https://figurnov.ru/"
            ],
            [
                "Olaf Ronneberger",
                "https://lmb.informatik.uni-freiburg.de/people/ronneber/"
            ],
            [
                "Kathryn Tunyasuvunakool",
                "https://scholar.google.com/citations?user=eEqNGagAAAAJ"
            ],
            [
                "Russ Bates",
                "https://scholar.google.com/citations?user=Koes5ewAAAAJ"
            ],
            [
                "Augustin Žídek",
                "https://augustin.zidek.eu/"
            ],
            [
                "Anna Potapenko",
                "http://apotapenko.com/"
            ],
            [
                "Alex Bridgland",
                "https://scholar.google.com/citations?user=VWmXKPMAAAAJ"
            ],
            [
                "Clemens Meyer",
                "https://scholar.google.com/citations?user=EWLZiM8AAAAJ"
            ],
            [
                "Simon Kohl",
                "https://www.simonkohl.com/"
            ],
            [
                "Andrew Ballard",
                "https://scholar.google.com/citations?user=syjQhAMAAAAJ"
            ],
            [
                "Bernardino Romera-Paredes",
                "https://scholar.google.com/citations?user=_LC9U6EAAAAJ"
            ],
            [
                "Stanislav Nikolov",
                "https://scholar.google.co.uk/citations?user=O-b7pBEAAAAJ"
            ],
            [
                "Rishub Jain",
                "http://rishub.me/"
            ]
        ],
        "links": [
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03819-2"
            ],
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03828-1"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/AlphaFold"
            ],
            [
                "git",
                "https://github.com/deepmind/alphafold/"
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/putting-the-power-of-alphafold-into-the-worlds-hands"
            ],
            [
                "git",
                "https://github.com/deepmind/tree"
            ],
            [
                "git",
                "https://github.com/deepmind/chex"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=gg7WjuFs8F4"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=B9PL__gVxLI"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/alphafold"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb",
        "update": 1647429868.0
    },
    {
        "name": "Arnheim",
        "description": "Generative Art Using Neural Visual Grammars and Dual Encoders",
        "author": [
            [
                "Chrisantha Fernando",
                "https://www.chrisantha.co.uk/"
            ],
            [
                "Ali Eslami",
                "http://arkitus.com/"
            ],
            [
                "Jean-Baptiste Alayrac",
                "https://www.jbalayrac.com/"
            ],
            [
                "Piotr Mirowski",
                "https://piotrmirowski.com/"
            ],
            [
                "Dylan Banarse",
                "https://www.2ne1.com/"
            ],
            [
                "Simon Osindero",
                "https://scholar.google.com/citations?user=Jq8ZS5kAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2105.00162"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.07729"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.02580"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.09106"
            ],
            [
                "git",
                "https://github.com/deepmind/arnheim"
            ],
            [
                "git",
                "https://github.com/openai/dall-e"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Compositional_pattern-producing_network"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=U7guaMdeF4g"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=zh0goLbS-l0"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=SYJGNt7yu6M"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=MxkYKa0x5AU"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/arnheim/blob/master/arnheim_2.ipynb",
        "update": 1636627816.0
    },
    {
        "name": "Neural Style Transfer",
        "description": "Implementation of Neural Style Transfer in Keras 2.0+",
        "author": [
            [
                "Somshubra Majumdar",
                "http://titu1994.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "http://arxiv.org/abs/1508.06576"
            ],
            [
                "git",
                "https://github.com/titu1994/Neural-Style-Transfer"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1605.04603"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.05897"
            ]
        ],
        "colab": "https://colab.research.google.com/github/titu1994/Neural-Style-Transfer/blob/master/NeuralStyleTransfer.ipynb",
        "update": 1611301206.0
    },
    {
        "name": "Mask R-CNN",
        "description": "Code and visualizations to test, debug, and evaluate the Mask R-CNN model",
        "author": [
            [
                "Jirka Borovec",
                "https://github.com/Borda"
            ],
            [
                "Waleed Abdulla",
                "https://waleedka.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/matterport/Mask_RCNN"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06870"
            ],
            [
                "blog post",
                "https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46"
            ],
            [
                "data",
                "http://cocodataset.org/#home"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=OOT3UIXZztE"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/data-science-bowl-2018"
            ],
            [
                "medium",
                "https://medium.com/geoai/reconstructing-3d-buildings-from-aerial-lidar-with-ai-details-6a81cb3079c0"
            ],
            [
                "git",
                "https://github.com/jremillard/images-to-osm"
            ],
            [
                "git",
                "https://github.com/huuuuusy/Mask-RCNN-Shiny"
            ]
        ],
        "colab": "https://colab.research.google.com/github/matterport/Mask_RCNN/blob/master/samples/coco/inspect_model.ipynb",
        "update": 1548119467.0
    },
    {
        "name": "BERT score",
        "description": "An automatic evaluation metric for text generation",
        "author": [
            [
                "Tianyi Zhang",
                "https://tiiiger.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1904.09675"
            ],
            [
                "git",
                "https://github.com/Tiiiger/bert_score"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1kpL8Y_AnUUiCxFjhxSrxCsc6-sDMNb_Q",
        "update": 1595008645.686
    },
    {
        "name": "XLNet",
        "description": "Generalized Autoregressive Pretraining for Language Understanding",
        "author": [
            [
                "Zhilin Yang",
                "http://kimiyoung.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1906.08237"
            ],
            [
                "git",
                "https://github.com/zihangdai/xlnet"
            ],
            [
                "data",
                "https://ai.stanford.edu/~amaas/data/sentiment/"
            ],
            [
                "data",
                "https://rajpurkar.github.io/SQuAD-explorer/"
            ],
            [
                "data",
                "https://www.cs.cmu.edu/~glai1/data/race/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/zihangdai/xlnet/blob/master/notebooks/colab_imdb_gpu.ipynb",
        "update": 1561737505.0
    },
    {
        "name": "SIREN",
        "description": "Implicit Neural Representations with Periodic Activation Functions",
        "author": [
            [
                "Vincent Sitzmann",
                "https://vsitzmann.github.io/"
            ],
            [
                "Julien Martel",
                "http://web.stanford.edu/~jnmartel/"
            ]
        ],
        "links": [
            [
                "project",
                "https://vsitzmann.github.io/siren/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.09661"
            ],
            [
                "git",
                "https://github.com/vsitzmann/siren"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Q2fLWGBeaiI"
            ],
            [
                "data",
                "https://drive.google.com/drive/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb",
        "update": 1593027601.0
    },
    {
        "name": "GANSpace",
        "description": "A simple technique to analyze GANs and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day",
        "author": [
            [
                "Erik Härkönen",
                "https://github.com/harskish"
            ],
            [
                "Aaron Hertzmann",
                "http://www.dgp.toronto.edu/~hertzman/"
            ],
            [
                "Jaakko Lehtinen",
                "https://users.aalto.fi/~lehtinj7/"
            ],
            [
                "Sylvain Paris",
                "http://people.csail.mit.edu/sparis/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.02546"
            ],
            [
                "git",
                "https://github.com/harskish/ganspace"
            ],
            [
                "youtube",
                "https://youtu.be/jdTICDa_eAI"
            ],
            [
                "git",
                "https://github.com/justinpinkney/awesome-pretrained-stylegan"
            ],
            [
                "git",
                "https://github.com/CSAILVision/GANDissect"
            ]
        ],
        "colab": "https://colab.research.google.com/github/harskish/ganspace/blob/master/notebooks/Ganspace_colab.ipynb",
        "update": 1607271906.0
    },
    {
        "name": "Jukebox",
        "description": "A neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles",
        "author": [
            [
                "Christine Payne",
                "http://christinemcleavey.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://openai.com/blog/jukebox"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.00341"
            ],
            [
                "explorer",
                "http://jukebox.openai.com/"
            ],
            [
                "git",
                "https://github.com/openai/jukebox"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb",
        "update": 1588609010.0
    },
    {
        "name": "Open-Unmix",
        "description": "A deep neural network reference implementation for music source separation, applicable for researchers, audio engineers and artists",
        "author": [
            [
                "Fabian-Robert Stöter",
                "http://faroit.com/"
            ],
            [
                "Antoine Liutkus",
                "https://github.com/aliutkus"
            ]
        ],
        "links": [
            [
                "paper",
                "https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf"
            ],
            [
                "project",
                "https://sigsep.github.io/open-unmix/"
            ],
            [
                "git",
                "https://github.com/sigsep/open-unmix-pytorch"
            ],
            [
                "data",
                "https://sigsep.github.io/datasets/musdb.html#musdb18-compressed-stems"
            ],
            [
                "git",
                "https://github.com/sigsep/norbert"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1mijF0zGWxN-KaxTnd0q6hayAlrID5fEQ",
        "update": 1627030663.325
    },
    {
        "name": "LaSAFT",
        "description": "Latent Source Attentive Frequency Transformation for Conditioned Source Separation",
        "author": [
            [
                "Woosung Choi",
                "https://ws-choi.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://lasaft.github.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11631"
            ],
            [
                "git",
                "https://github.com/ws-choi/Conditioned-Source-Separation-LaSAFT"
            ],
            [
                "data",
                "https://sigsep.github.io/datasets/musdb.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ws-choi/Conditioned-Source-Separation-LaSAFT/blob/master/colab_demo/LaSAFT_with_GPoCM_Stella_Jang_Example.ipynb",
        "update": 1604240216.0
    },
    {
        "name": "CLIP",
        "description": "A neural network which efficiently learns visual concepts from natural language supervision",
        "author": [
            [
                "Jong Wook",
                "https://jongwook.kim/"
            ],
            [
                "Alec Radford",
                "http://newmu.github.io/"
            ],
            [
                "Ilya Sutskever",
                "http://www.cs.utoronto.ca/~ilya/"
            ]
        ],
        "links": [
            [
                "project",
                "https://openai.com/blog/clip/"
            ],
            [
                "git",
                "https://github.com/openai/CLIP"
            ],
            [
                "paper",
                "https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf"
            ],
            [
                "data",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb",
        "update": 1611926523.0
    },
    {
        "name": "CLIPDraw",
        "description": "Synthesize drawings to match a text prompt",
        "author": [
            [
                "Kevin Frans",
                "https://www.kvfrans.com/"
            ],
            [
                "Lisa Soros",
                "https://scholar.google.com/citations?user=iUkpvMUAAAAJ"
            ],
            [
                "Olaf Witkowski",
                "https://olafwitkowski.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.00162"
            ],
            [
                "blog post",
                "https://kvfrans.com/clipdraw-exploring-text-to-drawing-synthesis/"
            ],
            [
                "git",
                "https://github.com/kvfrans/clipdraw"
            ],
            [
                "git",
                "https://github.com/BachiLi/diffvg/blob/master/apps/painterly_rendering.py"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kvfrans/clipdraw/blob/main/clipdraw.ipynb",
        "update": 1651174599.0
    },
    {
        "name": "HiDT",
        "description": "A generative image-to-image model and a new upsampling scheme that allows to apply image translation at high resolution",
        "author": [
            [
                "Denis Korzhenkov",
                "https://github.com/denkorzh"
            ],
            [
                "Gleb Sterkin",
                "https://github.com/belkakari"
            ],
            [
                "Sergey Nikolenko",
                "https://logic.pdmi.ras.ru/~sergey/"
            ],
            [
                "Victor Lempitsky",
                "http://sites.skoltech.ru/compvision/members/vilem/"
            ]
        ],
        "links": [
            [
                "project",
                "https://saic-mdal.github.io/HiDT/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.08791"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLuvGzlEQXT1KQuKrfBBEWh2f3PToxyeM5"
            ],
            [
                "git",
                "https://github.com/saic-mdal/HiDT"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=EWKAgwgqXB4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/saic-mdal/hidt/blob/master/notebooks/HighResolutionDaytimeTranslation.ipynb",
        "update": 1594983798.0
    },
    {
        "name": "Wav2Lip",
        "description": "A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild",
        "author": [
            [
                "Prajwal Renukanand",
                "https://github.com/prajwalkr"
            ],
            [
                "Rudrabha Mukhopadhyay",
                "https://rudrabha.github.io/"
            ],
            [
                "Vinay Namboodiri",
                "https://vinaypn.github.io/"
            ],
            [
                "C. V. Jawahar",
                "https://faculty.iiit.ac.in/~jawahar/"
            ]
        ],
        "links": [
            [
                "project",
                "http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/"
            ],
            [
                "demo",
                "http://bhaasha.iiit.ac.in/lipsync/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.10010"
            ],
            [
                "git",
                "https://github.com/Rudrabha/Wav2Lip"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=0fXaDCZNOJc"
            ],
            [
                "data",
                "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eyaler/avatars4all/blob/master/melaflefon.ipynb",
        "update": 1613155107.0
    },
    {
        "name": "MSG-Net",
        "description": "Multi-style Generative Network with a novel Inspiration Layer, which retains the functionality of optimization-based approaches and has the fast speed of feed-forward networks",
        "author": [
            [
                "Hang Zhang",
                "https://hangzhang.org/"
            ],
            [
                "Kristin Dana",
                "https://www.ece.rutgers.edu/~kdana/dana.html"
            ]
        ],
        "links": [
            [
                "project",
                "http://computervisionrutgers.github.io/MSG-Net/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06953"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=oy6pWNWBt4Y"
            ]
        ],
        "colab": "https://colab.research.google.com/github/zhanghang1989/PyTorch-Multi-Style-Transfer/blob/master/msgnet.ipynb",
        "update": 1611599921.0
    },
    {
        "name": "GMCNN",
        "description": "Generative Multi-column Convolutional Neural Networks inpainting model in Keras",
        "author": [
            [
                "Tomasz Latkowski",
                "https://github.com/tlatkowski"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.08771"
            ],
            [
                "git",
                "https://github.com/tlatkowski/inpainting-gmcnn-keras"
            ],
            [
                "data",
                "http://places2.csail.mit.edu/download.html"
            ],
            [
                "data",
                "https://nv-adlr.github.io/publication/partialconv-inpainting"
            ],
            [
                "git",
                "https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tlatkowski/inpainting-gmcnn-keras/blob/master/colab/Image_Inpainting_with_GMCNN_model.ipynb",
        "update": 1565355440.0
    },
    {
        "name": "Siamese NN",
        "description": "Implementation of Siamese Neural Networks built upon multihead attention mechanism for text semantic similarity task",
        "author": [
            [
                "Tomasz Latkowski",
                "https://github.com/tlatkowski"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tlatkowski/multihead-siamese-nets"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/quora-question-pairs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.14599"
            ],
            [
                "git",
                "https://github.com/facebookresearch/anli/"
            ],
            [
                "data",
                "https://nlp.stanford.edu/projects/snli/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tlatkowski/multihead-siamese-nets/blob/master/colab/multihead_siamese_nets.ipynb",
        "update": 1576785905.0
    },
    {
        "name": "SkyAR",
        "description": "A vision-based method for video sky replacement and harmonization, which can automatically generate realistic and dramatic sky backgrounds in videos with controllable styles",
        "author": [
            [
                "Zhengxia Zou",
                "http://www-personal.umich.edu/~zzhengxi/"
            ]
        ],
        "links": [
            [
                "project",
                "https://jiupinjia.github.io/skyar/"
            ],
            [
                "git",
                "https://github.com/jiupinjia/SkyAR"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11800"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=zal9Ues0aOQ"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jiupinjia/SkyAR/blob/master/colab_demo.ipynb",
        "update": 1610970167.0
    },
    {
        "name": "Neural Magic Eye",
        "description": "Learning to See and Understand the Scene Behind an Autostereogram",
        "author": [
            [
                "Zhengxia Zou",
                "http://www-personal.umich.edu/~zzhengxi/"
            ],
            [
                "Tianyang Shi",
                "https://www.shitianyang.tech/"
            ],
            [
                "Yi Yuan",
                "https://yiyuan1991.github.io/"
            ],
            [
                "Zhenwei Shi",
                "http://levir.buaa.edu.cn/"
            ]
        ],
        "links": [
            [
                "project",
                "https://jiupinjia.github.io/neuralmagiceye/"
            ],
            [
                "git",
                "https://github.com/jiupinjia/neural-magic-eye"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.15692"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Fkh7DEblqJ8"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1f59dFLJ748i2TleE54RkbUZSMo9Hyx7l",
        "update": 1609465943.743
    },
    {
        "name": "Stylized Neural Painting",
        "description": "An image-to-painting translation method that generates vivid and realistic painting artworks with controllable styles",
        "author": [
            [
                "Zhengxia Zou",
                "http://www-personal.umich.edu/~zzhengxi/"
            ],
            [
                "Tianyang Shi",
                "https://www.shitianyang.tech/"
            ],
            [
                "Yi Yuan",
                "https://yiyuan1991.github.io/"
            ],
            [
                "Zhenwei Shi",
                "http://levir.buaa.edu.cn/"
            ]
        ],
        "links": [
            [
                "project",
                "https://jiupinjia.github.io/neuralpainter/"
            ],
            [
                "git",
                "https://github.com/jiupinjia/stylized-neural-painting"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.08114"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=oerb-nwrXhk"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1ch_41GtcQNQT1NLOA21vQJ_rQOjjv9D8",
        "update": 1606835403.466
    },
    {
        "name": "Classification of chest vs. adominal X-rays",
        "description": "The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "annotator",
                "https://public.md.ai/annotator/project/PVq9raBJ"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py"
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson1-xray-images-classification.ipynb",
        "update": 1583556420.0
    },
    {
        "name": "Lung X-Rays Semantic Segmentation",
        "description": "This lesson applies a U-Net for Semantic Segmentation of the lung fields on chest x-rays",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1505.04597"
            ],
            [
                "annotator",
                "https://public.md.ai/annotator/project/aGq4k6NW"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py"
            ],
            [
                "data",
                "https://ceb.nlm.nih.gov/repositories/tuberculosis-chest-x-ray-image-data-sets/"
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson2-lung-xrays-segmentation.ipynb",
        "update": 1583556420.0
    },
    {
        "name": "RSNA Pneumonia Detection Challenge (Kaggel API)",
        "description": "The basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06870"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/rsna-pneumonia-detection-challenge"
            ],
            [
                "annotator",
                "https://public.md.ai/annotator/project/LxR6zdR2/workspace"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py"
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-kaggle.ipynb",
        "update": 1535962706.0
    },
    {
        "name": "Generating Piano Music with Transformer",
        "description": "This Colab notebook lets you play with pretrained Transformer models for piano music generation, based on the Music Transformer",
        "author": [
            [
                "Ian Simon",
                "https://github.com/iansimon"
            ],
            [
                "Anna Huang",
                "https://github.com/czhuang"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1809.04281"
            ],
            [
                "blog post",
                "http://g.co/magenta/music-transformer"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb",
        "update": 1568581200.0
    },
    {
        "name": "GrooVAE",
        "description": "Some applications of machine learning for generating and manipulating beats and drum performances",
        "author": [
            [
                "Jon Gillick",
                "https://www.jongillick.com/"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1905.06118"
            ],
            [
                "blog post",
                "https://g.co/magenta/groovae"
            ],
            [
                "data",
                "https://g.co/magenta/groove-datasets"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=x2YLmXzovDo"
            ],
            [
                "git",
                "http://goo.gl/magenta/musicvae-py"
            ],
            [
                "web app",
                "https://groove-drums.glitch.me/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/magenta-demos/blob/master/colab-notebooks/GrooVAE.ipynb",
        "update": 1610114797.0
    },
    {
        "name": "Multitrack MusicVAE",
        "description": "The models in this notebook are capable of encoding and decoding single measures of up to 8 tracks, optionally conditioned on an underlying chord",
        "author": [
            [
                "Ian Simon",
                "https://github.com/iansimon"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Colin Raffel",
                "https://colinraffel.com/"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Douglas Eck",
                "https://github.com/douglaseck"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1806.00195"
            ],
            [
                "blog post",
                "http://g.co/magenta/multitrack"
            ]
        ],
        "colab": "https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb",
        "update": 1613580884.0
    },
    {
        "name": "MusicVAE",
        "description": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music",
        "author": [
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Colin Raffel",
                "https://colinraffel.com/"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Douglas Eck",
                "https://github.com/douglaseck"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1803.05428"
            ],
            [
                "blog post",
                "https://g.co/magenta/music-vae"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr"
            ],
            [
                "project",
                "https://magenta.tensorflow.org/music-vae"
            ]
        ],
        "colab": "https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb",
        "update": 1591121246.0
    },
    {
        "name": "MusicXML Documentation",
        "description": "The goal of this notebook is to explore one of the magenta libraries for music",
        "author": [
            [
                "Prakruti Joshi",
                "https://github.com/prakruti-joshi"
            ],
            [
                "Falak Shah",
                "https://falaktheoptimist.github.io/"
            ],
            [
                "Twisha Naik",
                "https://github.com/twisha96"
            ]
        ],
        "links": [
            [
                "musicXML",
                "https://www.musicxml.com/for-developers/"
            ],
            [
                "magenta",
                "https://magenta.tensorflow.org/"
            ],
            [
                "music theory",
                "http://musictheoryblog.blogspot.com/2008/02/learn-music-theory.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicXML_Document_Structure_Documentation.ipynb",
        "update": 1610114797.0
    },
    {
        "name": "SVG VAE",
        "description": "A colab demo for the SVG VAE model",
        "author": [
            [
                "Raphael Gontijo Lopes",
                "https://raphagl.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1904.02632"
            ],
            [
                "blog post",
                "https://magenta.tensorflow.org/svg-vae"
            ]
        ],
        "colab": "https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/vae_svg_decoding.ipynb",
        "update": 1610114797.0
    },
    {
        "name": "Latent Constraints",
        "description": "Conditional Generation from Unconditional Generative Models",
        "author": [
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Matthew Hoffman",
                "http://matthewdhoffman.com/"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1711.05772"
            ],
            [
                "data",
                "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/latent_constraints/latentconstraints.ipynb",
        "update": 1511733600.0
    },
    {
        "name": "Performance RNN",
        "description": "This notebook shows you how to generate new performed compositions from a trained model",
        "author": [
            [
                "Ian Simon",
                "https://github.com/iansimon"
            ],
            [
                "Sageev Oore",
                "https://github.com/osageev"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://magenta.tensorflow.org/performance-rnn"
            ],
            [
                "data",
                "http://www.piano-e-competition.com/"
            ],
            [
                "git",
                "https://github.com/magenta/magenta/tree/master/magenta/models/performance_rnn"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/magenta/performance_rnn/performance_rnn.ipynb",
        "update": 1499720400.0
    },
    {
        "name": "Onsets and Frames",
        "description": "Onsets and Frames is an automatic music transcription framework with piano and drums models",
        "author": [
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Erich Elsen",
                "https://github.com/ekelsen"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1710.11153"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.12247"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.00188"
            ],
            [
                "blog post",
                "http://g.co/magenta/onsets-frames"
            ],
            [
                "data",
                "https://g.co/magenta/maestro-wave2midi2wave"
            ],
            [
                "data",
                "https://magenta.tensorflow.org/datasets/e-gmd"
            ],
            [
                "git",
                "https://goo.gl/magenta/onsets-frames-code"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb",
        "update": 1585774800.0
    },
    {
        "name": "GANSynth",
        "description": "This notebook is a demo GANSynth, which generates audio with Generative Adversarial Networks",
        "author": [
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ],
            [
                "project",
                "https://storage.googleapis.com/magentadata/papers/gansynth/index.html"
            ],
            [
                "git",
                "http://goo.gl/magenta/gansynth-code"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/magenta/gansynth/gansynth_demo.ipynb",
        "update": 1551045600.0
    },
    {
        "name": "NSynth",
        "description": "This colab notebook has everything you need to upload your own sounds and use NSynth models to reconstruct and interpolate between them",
        "author": [
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Cinjon Resnick",
                "https://github.com/cinjon"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Sander Dieleman",
                "https://benanne.github.io/"
            ],
            [
                "Karen Simonyan",
                "https://scholar.google.co.uk/citations?user=L7lMQkQAAAAJ"
            ],
            [
                "Mohammad Norouzi",
                "https://norouzi.github.io/"
            ],
            [
                "Douglas Eck",
                "https://github.com/douglaseck"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1704.01279"
            ],
            [
                "blog post",
                "https://magenta.tensorflow.org/nsynth"
            ],
            [
                "git",
                "https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth"
            ],
            [
                "data",
                "https://magenta.tensorflow.org/datasets/nsynth"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=AaALLWQmCdI"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=BOoSy-Pg8is"
            ],
            [
                "tutorial",
                "https://magenta.tensorflow.org/nsynth-fastgen"
            ]
        ],
        "colab": "https://colab.research.google.com/notebooks/magenta/nsynth/nsynth.ipynb",
        "update": 1491426000.0
    },
    {
        "name": "Big GAN",
        "description": "Large Scale GAN Training for High Fidelity Natural Image Synthesis",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/hub"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb",
        "update": 1610429158.0
    },
    {
        "name": "BERT with TPU",
        "description": "Using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models and run predictions on tuned model",
        "author": [
            [
                "Sourabh Bajaj",
                "https://sourabhbajaj.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "TPU quickstart",
                "https://cloud.google.com/tpu/docs/quickstart"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb",
        "update": 1553812832.0
    },
    {
        "name": "Pixel2Style2Pixel",
        "description": "Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
        "author": [
            [
                "Elad Richardson",
                "https://github.com/eladrich"
            ],
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Yotam Nitzan",
                "https://yotamnitzan.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://www.cs.tau.ac.il/~dcor/"
            ]
        ],
        "links": [
            [
                "project",
                "https://eladrich.github.io/pixel2style2pixel/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00951"
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/HuangYG123/CurricularFace"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb",
        "update": 1622553884.0
    },
    {
        "name": "Talking Head Anime from a Single Image",
        "description": "The network takes as input an image of an anime character's face and a desired pose, and it outputs another image of the same character in the given pose",
        "author": [
            [
                "Pramook Khungurn",
                "https://pkhungurn.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://pkhungurn.github.io/talking-head-anime/"
            ],
            [
                "youtube",
                "https://youtu.be/kMQCERkTdO0"
            ],
            [
                "youtube",
                "https://youtu.be/T1Gp-RxFZwU"
            ],
            [
                "youtube",
                "https://youtu.be/FioRJ6x_RbI"
            ],
            [
                "git",
                "https://github.com/pkhungurn/talking-head-anime-demo"
            ],
            [
                "git",
                "https://github.com/lincolnhard/head-pose-estimation"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Virtual_YouTuber"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/MikuMikuDance"
            ]
        ],
        "colab": "https://colab.research.google.com/github/pkhungurn/talking-head-anime-demo/blob/master/tha_colab.ipynb",
        "update": 1614109107.0
    },
    {
        "name": "AnimeGANv2",
        "description": "An improved version of AnimeGAN - it prevents the generation of high-frequency artifacts by simply changing the normalization of features in the network",
        "author": [
            [
                "Xin Chen",
                "https://dl.acm.org/profile/99659508903"
            ],
            [
                "Gang Liu",
                "https://dl.acm.org/profile/81493643454"
            ],
            [
                "bryandlee",
                "https://github.com/bryandlee"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/bryandlee/animegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/TachibanaYoshino/AnimeGANv2"
            ],
            [
                "git",
                "https://github.com/TachibanaYoshino/AnimeGAN"
            ],
            [
                "project",
                "https://tachibanayoshino.github.io/AnimeGANv2/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bryandlee/animegan2-pytorch/blob/master/colab_demo.ipynb",
        "update": 1637107741.0
    },
    {
        "name": "NeRViS",
        "description": "An algorithm for full-frame video stabilization by first estimating dense warp fields",
        "author": [
            [
                "Yu-Lun Liu",
                "http://www.cmlab.csie.ntu.edu.tw/~yulunliu/"
            ],
            [
                "Wei-Sheng Lai",
                "https://www.wslai.net/"
            ],
            [
                "Ming-Hsuan Yang",
                "https://faculty.ucmerced.edu/mhyang/"
            ],
            [
                "Yung-Yu Chuang",
                "https://www.csie.ntu.edu.tw/~cyy/"
            ],
            [
                "Jia-Bin Huang",
                "https://filebox.ece.vt.edu/~jbhuang/"
            ]
        ],
        "links": [
            [
                "project",
                "https://alex04072000.github.io/NeRViS/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.06205"
            ],
            [
                "youtube",
                "https://youtu.be/KO3sULs4hso"
            ],
            [
                "git",
                "https://github.com/alex04072000/NeRViS"
            ],
            [
                "git",
                "https://github.com/cxjyxxme/deep-online-video-stabilization"
            ],
            [
                "git",
                "https://github.com/jinsc37/DIFRINT"
            ],
            [
                "data",
                "http://liushuaicheng.org/SIGGRAPH2013/database.html"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1l-fUzyM38KJMZyKMBWw_vu7ZUyDwgdYH",
        "update": 1618125726.731
    },
    {
        "name": "SkinDeep",
        "description": "Remove Body Tattoo Using Deep Learning",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/SkinDeep"
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/SkinDeep/blob/master/SkinDeep_good.ipynb",
        "update": 1619268323.0
    },
    {
        "name": "Toon-Me",
        "description": "A fun project to toon portrait images",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/Toon-Me"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Try_it_on_Colab).ipynb",
        "update": 1611303874.0
    },
    {
        "name": "ArtLine",
        "description": "A Deep Learning based project for creating line art portraits",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/ArtLine"
            ],
            [
                "git",
                "https://github.com/yiranran/APDrawingGAN"
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ],
            [
                "data",
                "https://cg.cs.tsinghua.edu.cn/people/~Yongjin/APDrawingDB.zip"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/ArtLine(AR).ipynb",
        "update": 1608800179.0
    },
    {
        "name": "ReStyle",
        "description": "A Residual-Based StyleGAN Encoder via Iterative Refinement",
        "author": [
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuval-alaluf.github.io/restyle-encoder/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.02699"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00951"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02766"
            ],
            [
                "git",
                "https://github.com/yuval-alaluf/restyle-encoder"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/TreB1eN/InsightFace_Pytorch"
            ]
        ],
        "colab": "https://colab.research.google.com/github/yuval-alaluf/restyle-encoder/blob/master/notebooks/inference_playground.ipynb",
        "update": 1621614207.0
    },
    {
        "name": "encoder4editing",
        "description": "Designing an Encoder for StyleGAN Image Manipulation",
        "author": [
            [
                "Omer Tov",
                "https://github.com/omertov"
            ],
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Yotam Nitzan",
                "https://yotamnitzan.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02766"
            ],
            [
                "git",
                "https://github.com/omertov/encoder4editing"
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel"
            ]
        ],
        "colab": "https://colab.research.google.com/github/omertov/encoder4editing/blob/master/notebooks/inference_playground.ipynb",
        "update": 1638454849.0
    },
    {
        "name": "SAM",
        "description": "Age Transformation Using a Style-Based Regression Model",
        "author": [
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuval-alaluf.github.io/SAM/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02754"
            ],
            [
                "youtube",
                "https://youtu.be/X_pYC_LtBFw"
            ],
            [
                "git",
                "https://github.com/yuval-alaluf/SAM"
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "colab": "http://colab.research.google.com/github/yuval-alaluf/SAM/blob/master/notebooks/animation_inference_playground.ipynb",
        "update": 1619410569.0
    },
    {
        "name": "StyleGAN-NADA",
        "description": "Zero-Shot non-adversarial domain adaptation of pre-trained generators",
        "author": [
            [
                "Rinon Gal",
                "https://rinongal.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Haggai Maron",
                "https://haggaim.github.io/"
            ],
            [
                "Gal Chechik",
                "https://research.nvidia.com/person/gal-chechik"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/rinongal/StyleGAN-nada"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch/"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17249"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.02699"
            ],
            [
                "project",
                "https://stylegan-nada.github.io/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/rinongal/stylegan-nada/blob/main/stylegan_nada.ipynb",
        "update": 1638620735.0
    },
    {
        "name": "Big Sleep",
        "description": "Text to image generation, using OpenAI's CLIP and a BigGAN",
        "author": [
            [
                "Phil Wang",
                "https://github.com/lucidrains"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/bigsleep/comments/lxawb4/how_to_use_some_of_the_newer_features_of/"
            ],
            [
                "git",
                "https://github.com/lucidrains/big-sleep"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/bigsleep/"
            ],
            [
                "git",
                "https://github.com/openai/CLIP"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb",
        "update": 1615949421.123
    },
    {
        "name": "Deep Daze",
        "description": "Text to image generation using OpenAI's CLIP and Siren",
        "author": [
            [
                "Phil Wang",
                "https://github.com/lucidrains"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.09661"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/deepdaze/"
            ],
            [
                "git",
                "https://github.com/lucidrains/deep-daze"
            ],
            [
                "git",
                "https://github.com/openai/CLIP"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1_YOHdORb0Fg1Q7vWZ_KlrtFe9Ur3pmVj",
        "update": 1615949380.476
    },
    {
        "name": "Parallel WaveGAN",
        "description": "State-of-the-art non-autoregressive models to build your own great vocoder",
        "author": [
            [
                "Tomoki Hayashi",
                "https://kan-bayashi.github.io/"
            ]
        ],
        "links": [
            [
                "demo",
                "https://kan-bayashi.github.io/ParallelWaveGAN/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.11480"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.06711"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05106"
            ],
            [
                "git",
                "https://github.com/kan-bayashi/ParallelWaveGAN"
            ],
            [
                "git",
                "https://github.com/NVIDIA/tacotron2"
            ],
            [
                "git",
                "https://github.com/espnet/espnet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb",
        "update": 1647483201.0
    },
    {
        "name": "VideoGPT",
        "description": "A conceptually simple architecture for scaling likelihood based generative modeling to natural videos",
        "author": [
            [
                "Wilson Yan",
                "https://wilson1yan.github.io/"
            ],
            [
                "Yunzhi Zhang",
                "https://zzyunzhi.github.io/"
            ],
            [
                "Pieter Abbeel",
                "https://people.eecs.berkeley.edu/~pabbeel/"
            ],
            [
                "Aravind Srinivas",
                "https://people.eecs.berkeley.edu/~aravind/"
            ]
        ],
        "links": [
            [
                "project",
                "https://wilson1yan.github.io/videogpt/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.10157"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.10509"
            ],
            [
                "data",
                "https://www.crcv.ucf.edu/data/UCF101.php"
            ],
            [
                "git",
                "https://github.com/wilson1yan/VideoGPT"
            ]
        ],
        "colab": "https://colab.research.google.com/github/wilson1yan/VideoGPT/blob/master/notebooks/Using_VideoGPT.ipynb",
        "update": 1646237327.0
    },
    {
        "name": "SimSwap",
        "description": "An efficient framework, called Simple Swap, aiming for generalized and high fidelity face swapping",
        "author": [
            [
                "Xuanhong Chen",
                "https://github.com/neuralchen"
            ],
            [
                "Bingbing Ni",
                "https://scholar.google.com.sg/citations?user=eUbmKwYAAAAJ"
            ],
            [
                "Yanhao Ge",
                "https://scholar.google.com/citations?user=h6tuBAcAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2106.06340"
            ],
            [
                "git",
                "https://github.com/neuralchen/SimSwap"
            ],
            [
                "git",
                "https://github.com/deepinsight/insightface"
            ]
        ],
        "colab": "https://colab.research.google.com/github/neuralchen/SimSwap/blob/master/SimSwap%20colab.ipynb",
        "update": 1637745544.0
    },
    {
        "name": "TediGAN",
        "description": "Framework for multi-modal image generation and manipulation with textual descriptions",
        "author": [
            [
                "Weihao Xia",
                "https://github.com/weihaox"
            ],
            [
                "Yujiu Yang",
                "http://www.fiesta.tsinghua.edu.cn/pi/3/24"
            ],
            [
                "Jing-Hao Xue",
                "http://www.homepages.ucl.ac.uk/~ucakjxu/"
            ],
            [
                "Baoyuan Wu",
                "https://sites.google.com/site/baoyuanwu2015/home"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2012.03308"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.08910"
            ],
            [
                "youtube",
                "https://youtu.be/L8Na2f5viAM"
            ],
            [
                "git",
                "https://github.com/IIGROUP/TediGAN"
            ],
            [
                "git",
                "https://github.com/weihaox/Multi-Modal-CelebA-HQ"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch/"
            ],
            [
                "git",
                "https://github.com/fyu/lsun"
            ]
        ],
        "colab": "http://colab.research.google.com/github/weihaox/TediGAN/blob/master/playground.ipynb",
        "update": 1625052505.0
    },
    {
        "name": "NeX",
        "description": "View synthesis based on enhancements of multiplane image that can reproduce NeXt-level view-dependent effects in real time",
        "author": [
            [
                "Suttisak Wizadwongsa",
                "https://www.linkedin.com/in/suttisak-wizadwongsa-763a931a5/"
            ],
            [
                "Pakkapon Phongthawee",
                "http://pureexe.github.io/"
            ],
            [
                "Jiraphon Yenphraphai",
                "https://www.linkedin.com/in/jiraphon-yenphraphai-990ba6175/"
            ],
            [
                "Supasorn Suwajanakorn",
                "https://www.supasorn.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://nex-mpi.github.io/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=HyfkF7Z-ddA"
            ],
            [
                "git",
                "https://github.com/nex-mpi/nex-code"
            ],
            [
                "git",
                "https://github.com/Fyusion/LLFF"
            ],
            [
                "data",
                "https://vistec-my.sharepoint.com/personal/pakkapon_p_s19_vistec_ac_th/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fpakkapon%5Fp%5Fs19%5Fvistec%5Fac%5Fth%2FDocuments%2Fpublic%2FVLL%2FNeX%2Fshiny%5Fdatasets&originalPath=aHR0cHM6Ly92aXN0ZWMtbXkuc2hhcmVwb2ludC5jb20vOmY6L2cvcGVyc29uYWwvcGFra2Fwb25fcF9zMTlfdmlzdGVjX2FjX3RoL0VuSVVoc1JWSk9kTnNaXzRzbWRoeWUwQjh6MFZseHFPUjM1SVIzYnAwdUd1cFE%5FcnRpbWU9WXRVQTQtQTcyVWc"
            ],
            [
                "data",
                "https://vistec-my.sharepoint.com/personal/pakkapon_p_s19_vistec_ac_th/_layouts/15/onedrive.aspx?originalPath=aHR0cHM6Ly92aXN0ZWMtbXkuc2hhcmVwb2ludC5jb20vOmY6L2cvcGVyc29uYWwvcGFra2Fwb25fcF9zMTlfdmlzdGVjX2FjX3RoL0VyalBSUkw5Sm5GSXA4TU42ZDFqRXVvQjNYVm94SmtmZlBqZm9QeWhIa2owZGc%5FcnRpbWU9bC0yYWctRTcyVWc&id=%2Fpersonal%2Fpakkapon%5Fp%5Fs19%5Fvistec%5Fac%5Fth%2FDocuments%2Fpublic%2FVLL%2FNeX%2Fmodified%5Fdataset"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.05606"
            ],
            [
                "vistec",
                "https://vistec.ist/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1hXVvYdAwLA0EFg2zrafJUE0bFgB_F7PU",
        "update": 1616692728.707
    },
    {
        "name": "Anycost GAN",
        "description": "Interactive natural image editing",
        "author": [
            [
                "Ji Lin",
                "http://linji.me/"
            ],
            [
                "Richard Zhang",
                "https://richzhang.github.io/"
            ],
            [
                "Frieder Ganz",
                "https://scholar.google.com/citations?user=u9ySZkUAAAAJ"
            ],
            [
                "Song Han",
                "https://songhan.mit.edu/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mit-han-lab/anycost-gan"
            ],
            [
                "project",
                "https://hanlab.mit.edu/projects/anycost-gan/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_yEziPl9AkM"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.03243"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/switchablenorms/CelebAMask-HQ"
            ],
            [
                "git",
                "https://github.com/fyu/lsun"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mit-han-lab/anycost-gan/blob/master/notebooks/intro_colab.ipynb",
        "update": 1625637518.0
    },
    {
        "name": "Rewriting a Deep Generative Model",
        "description": "We ask if a deep network can be reprogrammed to follow different rules, by enabling a user to directly change the weights, instead of training with a data set",
        "author": [
            [
                "David Bau",
                "https://people.csail.mit.edu/davidbau/home/"
            ],
            [
                "Steven Liu",
                "http://people.csail.mit.edu/stevenliu/"
            ],
            [
                "Tongzhou Wang",
                "https://ssnl.github.io/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2007.15646"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=i2_-zNqtEPk"
            ],
            [
                "youtube",
                "https://rewriting.csail.mit.edu/video/"
            ],
            [
                "project",
                "https://rewriting.csail.mit.edu/"
            ],
            [
                "git",
                "https://github.com/davidbau/rewriting"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "colab": "https://colab.research.google.com/github/davidbau/rewriting/blob/master/notebooks/rewriting-interface.ipynb",
        "update": 1596222132.0
    },
    {
        "name": "SeFa",
        "description": "A closed-form approach for unsupervised latent semantic factorization in GANs",
        "author": [
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Bolei Zhou",
                "http://bzhou.ie.cuhk.edu.hk/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/sefa/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.06600"
            ],
            [
                "git",
                "https://github.com/genforce/sefa"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=OFHW2WbXXIQ"
            ]
        ],
        "colab": "https://colab.research.google.com/github/genforce/sefa/blob/master/docs/SeFa.ipynb",
        "update": 1607213042.0
    },
    {
        "name": "HiGAN",
        "description": "Semantic Hierarchy Emerges in Deep Generative Representations for Scene Synthesis",
        "author": [
            [
                "Ceyuan Yang",
                "https://ceyuan.me/"
            ],
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Bolei Zhou",
                "http://bzhou.ie.cuhk.edu.hk/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/higan/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.09267"
            ],
            [
                "git",
                "https://github.com/genforce/higanc"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=X5yWu2Jwjpg"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6856"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1906.10112"
            ]
        ],
        "colab": "https://colab.research.google.com/github/genforce/higan/blob/master/docs/HiGAN_Bedroom.ipynb",
        "update": 1602641162.0
    },
    {
        "name": "InterFaceGAN",
        "description": "Interpreting the Latent Space of GANs for Semantic Face Editing",
        "author": [
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Jinjin Gu",
                "https://www.jasongt.com/"
            ],
            [
                "Xiaoou Tang",
                "https://www.ie.cuhk.edu.hk/people/xotang.shtml"
            ],
            [
                "Bolei Zhou",
                "http://bzhou.ie.cuhk.edu.hk/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/interfacegan/"
            ],
            [
                "git",
                "https://github.com/genforce/interfacegan"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=uoftpl3Bj6w"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10786"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.09635"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "git",
                "https://github.com/tkarras/progressive_growing_of_gans"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan"
            ]
        ],
        "colab": "https://colab.research.google.com/github/genforce/interfacegan/blob/master/docs/InterFaceGAN.ipynb",
        "update": 1602560296.0
    },
    {
        "name": "DALL·E Mini",
        "description": "Generate images from a text prompt",
        "author": [
            [
                "Boris Dayma",
                "https://github.com/borisdayma"
            ],
            [
                "Suraj Patil",
                "https://github.com/patil-suraj"
            ],
            [
                "Pedro Cuenca",
                "https://github.com/pcuenca"
            ],
            [
                "Khalid Saifullah",
                "https://khalidsaifullaah.github.io/"
            ],
            [
                "Tanishq Abraham",
                "https://github.com/tmabraham"
            ],
            [
                "Phúc H. Lê Khắc",
                "https://lkhphuc.com/"
            ],
            [
                "Luke Melas",
                "https://lukemelas.github.io/"
            ],
            [
                "Ritobrata Ghosh",
                "https://ghosh-r.github.io/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA"
            ],
            [
                "demo",
                "https://huggingface.co/spaces/flax-community/dalle-mini"
            ],
            [
                "git",
                "https://github.com/borisdayma/dalle-mini"
            ],
            [
                "git",
                "https://github.com/huggingface/transformers/tree/master/examples/research_projects/jax-projects"
            ],
            [
                "git",
                "https://github.com/openai/CLIP/blob/main/data/yfcc100m.md"
            ],
            [
                "data",
                "https://aclanthology.org/P18-1238/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.08981"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.13461"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.04015"
            ]
        ],
        "colab": "https://colab.research.google.com/github/borisdayma/dalle-mini/blob/main/tools/inference/inference_pipeline.ipynb",
        "update": 1638064306.0
    },
    {
        "name": "ruDALL-E",
        "description": "Generate images from texts in Russian",
        "author": [
            [
                "Alex Shonenkov",
                "https://github.com/shonenkov"
            ]
        ],
        "links": [
            [
                "project",
                "https://rudalle.ru/"
            ],
            [
                "git",
                "https://github.com/sberbank-ai/ru-dalle"
            ],
            [
                "git",
                "https://github.com/bes-dev/vqvae_dwt_distiller.pytorch"
            ],
            [
                "git",
                "https://github.com/boomb0om/Real-ESRGAN-colab"
            ]
        ],
        "colab": "https://colab.research.google.com/github/sberbank-ai/ru-dalle/blob/master/jupyters/ruDALLE-example-generation-A100.ipynb",
        "update": 1635950086.0
    },
    {
        "name": "Disentangled Lifespan Face Synthesis",
        "description": "LFS model is proposed to disentangle the key face characteristics including shape, texture and identity so that the unique shape and texture age transformations can be modeled effectively",
        "author": [
            [
                "Sen He",
                "https://senhe.github.io/"
            ],
            [
                "Wentong Liao",
                "https://www.tnt.uni-hannover.de/en/staff/liao/"
            ],
            [
                "Michael Yang",
                "https://sites.google.com/site/michaelyingyang/"
            ],
            [
                "Yi-Zhe Song",
                "http://personal.ee.surrey.ac.uk/Personal/Y.Song/"
            ],
            [
                "Bodo Rosenhahn",
                "https://scholar.google.com/citations?user=qq3TxtcAAAAJ"
            ],
            [
                "Tao Xiang",
                "http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html"
            ]
        ],
        "links": [
            [
                "project",
                "https://senhe.github.io/projects/iccv_2021_lifespan_face/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.02874"
            ],
            [
                "git",
                "https://github.com/SenHe/DLFS"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=uklX03ns0m0"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1fgVAoxCSaqPkj0rUK4RmBh7GTQRqLNpE",
        "update": 1645544461.162
    },
    {
        "name": "Lifespan Age Transformation Synthesis",
        "description": "Multi-domain image-to-image generative adversarial network architecture, whose learned latent space models a continuous bi-directional aging process",
        "author": [
            [
                "Roy Or-El",
                "https://homes.cs.washington.edu/~royorel/"
            ],
            [
                "Soumyadip Sengupta",
                "https://homes.cs.washington.edu/~soumya91/"
            ],
            [
                "Ohad Fried",
                "https://www.ohadf.com/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Ira Kemelmacher-Shlizerman",
                "https://www.irakemelmacher.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://grail.cs.washington.edu/projects/lifespan_age_transformation_synthesis/"
            ],
            [
                "youtube",
                "https://youtu.be/_jTFcjN2hBk"
            ],
            [
                "youtube",
                "https://youtu.be/9fulnt2_q_Y"
            ],
            [
                "git",
                "https://github.com/royorel/Lifespan_Age_Transformation_Synthesis"
            ],
            [
                "git",
                "https://github.com/royorel/FFHQ-Aging-Dataset"
            ],
            [
                "git",
                "https://github.com/NVIDIA/pix2pixHD"
            ],
            [
                "git",
                "https://github.com/rosinality/style-based-gan-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.09764"
            ]
        ],
        "colab": "https://colab.research.google.com/github/royorel/Lifespan_Age_Transformation_Synthesis/blob/master/LATS_demo.ipynb",
        "update": 1604164828.0
    },
    {
        "name": "Real-ESRGAN",
        "description": "Extend the powerful ESRGAN to a practical restoration application, which is trained with pure synthetic data",
        "author": [
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Liangbin Xie",
                "https://github.com/LiangbinXie"
            ],
            [
                "Chao Dong",
                "https://scholar.google.com/citations?user=OSDCB0UAAAAJ"
            ],
            [
                "Ying Shan",
                "https://scholar.google.com/citations?user=4oXBp9UAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2107.10833"
            ],
            [
                "git",
                "https://github.com/xinntao/Real-ESRGAN"
            ],
            [
                "git",
                "https://github.com/xinntao/ESRGAN"
            ],
            [
                "git",
                "https://github.com/xinntao/facexlib"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyView"
            ],
            [
                "git",
                "https://github.com/Tencent/ncnn"
            ],
            [
                "git",
                "https://github.com/nihui/waifu2x-ncnn-vulkan"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1k2Zod6kSHEvraybHl50Lys0LerhyTMCo",
        "update": 1650802718.426
    },
    {
        "name": "GFPGAN",
        "description": "Towards Real-World Blind Face Restoration with Generative Facial Prior",
        "author": [
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Yu Li",
                "https://yu-li.github.io/"
            ],
            [
                "Honglun Zhang",
                "https://scholar.google.com/citations?user=KjQLROoAAAAJ"
            ],
            [
                "Ying Shan",
                "https://scholar.google.com/citations?user=4oXBp9UAAAAJ"
            ]
        ],
        "links": [
            [
                "project",
                "https://xinntao.github.io/projects/gfpgan"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2101.04061"
            ],
            [
                "git",
                "https://github.com/TencentARC/GFPGAN"
            ],
            [
                "git",
                "https://github.com/xinntao/facexlib"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyView"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo",
        "update": 1644820685.65
    },
    {
        "name": "Live Speech Portraits",
        "description": "Real-Time Photorealistic Talking-Head Animation",
        "author": [
            [
                "Yuanxun Lu",
                "https://github.com/YuanxunLu"
            ],
            [
                "Jinxiang Chai",
                "https://scholar.google.com/citations?user=OcN1_gwAAAAJ"
            ],
            [
                "Xun Cao",
                "https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuanxunlu.github.io/projects/LiveSpeechPortraits/"
            ],
            [
                "git",
                "https://github.com/YuanxunLu/LiveSpeechPortraits"
            ],
            [
                "git",
                "https://github.com/lelechen63/ATVGnet"
            ],
            [
                "git",
                "https://github.com/lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion"
            ],
            [
                "git",
                "https://github.com/DinoMan/speech-driven-animation"
            ],
            [
                "git",
                "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.10595"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1tKvi-9kY3GkEK8lgtfTSM70rMFo_TY50",
        "update": 1632685360.817
    },
    {
        "name": "Text2Animation",
        "description": "Generate images from text phrases with VQGAN and CLIP with animation and keyframes",
        "author": [
            [
                "Katherine Crowson",
                "https://kath.io/"
            ],
            [
                "Ryan Murdock",
                "https://twitter.com/advadnoun"
            ],
            [
                "Chigozie Nri",
                "https://github.com/chigozienri"
            ],
            [
                "Denis Malimonov",
                "https://github.com/tg-bomze"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/chigozienri/VQGAN-CLIP-animations"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCToztRy9FSTIhEen_1x4FAw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Animation.ipynb",
        "update": 1632908592.0
    },
    {
        "name": "StyleCariGAN",
        "description": "Caricature Generation via StyleGAN Feature Map Modulation",
        "author": [
            [
                "Wonjong Jang",
                "https://wonjongg.github.io/"
            ],
            [
                "Gwangjin Ju",
                "https://github.com/jugwangjin"
            ],
            [
                "Yucheol Jung",
                "https://ycjung.info/"
            ],
            [
                "Jiaolong Yang",
                "https://jlyang.org/"
            ],
            [
                "Xin Tong",
                "https://www.microsoft.com/en-us/research/people/xtong/"
            ],
            [
                "Seungyong Lee",
                "https://scholar.google.com/citations?user=yGPH-nAAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/wonjongg/StyleCariGAN"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.04331"
            ],
            [
                "project",
                "https://wonjongg.github.io/StyleCariGAN/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=kpHbGOlI-BU"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1HDRQGm7pvC9mAb6Lktoft_SmY9sCq_Qg",
        "update": 1638304604.158
    },
    {
        "name": "SpecVQGAN",
        "description": "Taming the visually guided sound generation by shrinking a training dataset to a set of representative vectors",
        "author": [
            [
                "Vladimir Iashin",
                "https://iashin.ai/"
            ],
            [
                "Esa Rahtu",
                "https://esa.rahtu.fi/"
            ]
        ],
        "links": [
            [
                "project",
                "https://iashin.ai/SpecVQGAN"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/2110.08791"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1711.00937"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00820"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1712.01393"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1512.08512"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Bucb3nAa398"
            ],
            [
                "git",
                "https://github.com/v-iashin/SpecVQGAN"
            ],
            [
                "git",
                "https://github.com/PeihaoChen/regnet"
            ],
            [
                "git",
                "https://github.com/toshas/torch-fidelity"
            ],
            [
                "git",
                "https://github.com/descriptinc/melgan-neurips"
            ],
            [
                "git",
                "https://github.com/google/lyra"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Foley_(filmmaking)"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Row-_and_column-major_order"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1pxTIMweAKApJZ3ZFqyBee3HtMqFpnwQ0",
        "update": 1643911942.079
    },
    {
        "name": "StyleGAN3",
        "description": "Alias-Free Generative Adversarial Networks",
        "author": [
            [
                "Tero Karras",
                "https://research.nvidia.com/person/tero-karras"
            ],
            [
                "Miika Aittala",
                "https://research.nvidia.com/person/Miika-Aittala"
            ],
            [
                "Samuli Laine",
                "https://research.nvidia.com/person/Samuli-Laine"
            ],
            [
                "Erik Härkönen",
                "https://github.com/harskish"
            ],
            [
                "Janne Hellsten",
                "https://research.nvidia.com/person/Janne-Hellsten"
            ],
            [
                "Jaakko Lehtinen",
                "https://github.com/jtlehtin"
            ],
            [
                "Timo Aila",
                "https://research.nvidia.com/person/timo-aila"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/NVlabs/stylegan3"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan3-detector"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/NVlabs/metfaces-dataset"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada-pytorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada"
            ],
            [
                "project",
                "https://nvlabs.github.io/stylegan3"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.12423"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08500"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.01401"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.06991"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.04948"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.03498"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1BXNHZBai-pXtP-ncliouXo_kUiG1Pq7M",
        "update": 1634627369.928
    },
    {
        "name": "Person Remover",
        "description": "Project that combines Pix2Pix and YOLO arhitectures in order to remove people or other objects from photos",
        "author": [
            [
                "Javier Gamazo",
                "https://www.javiergamazo.com/"
            ],
            [
                "Daryl Autar",
                "https://github.com/Daryl149"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/javirk/Person_remover"
            ],
            [
                "git",
                "https://github.com/javirk/Person-remover-partial-convolutions"
            ],
            [
                "git",
                "https://github.com/zzh8829/yolov3-tf2"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_dRjY9gMcxE"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JDpH8MAjaKoekQ_H9ZaxYJ9_axiDtDGm",
        "update": 1598098239.644
    },
    {
        "name": "LaMa",
        "description": "Resolution-robust Large Mask Inpainting with Fourier Convolutions",
        "author": [
            [
                "Roman Suvorov",
                "https://github.com/windj007"
            ],
            [
                "Elizaveta Logacheva",
                "https://github.com/elimohl"
            ],
            [
                "Anton Mashikhin",
                "https://www.linkedin.com/in/heyt0ny/"
            ],
            [
                "Anastasia Remizova",
                "https://github.com/feathernox"
            ],
            [
                "Arsenii Ashukha",
                "https://ashukha.com/"
            ],
            [
                "Aleksei Silvestrov",
                "https://www.linkedin.com/in/%D0%B0%D0%BB%D0%B5%D0%BA%D1%81%D0%B5%D0%B9-%D1%81%D0%B8%D0%BB%D1%8C%D0%B2%D0%B5%D1%81%D1%82%D1%80%D0%BE%D0%B2-141b99b6/"
            ],
            [
                "Naejin Kong",
                "https://github.com/naejin-kong"
            ],
            [
                "Harshith Goka",
                "https://github.com/h9399-goka"
            ],
            [
                "Kiwoong Park",
                "https://github.com/kyoong-park"
            ],
            [
                "Victor Lempitsky",
                "http://sites.skoltech.ru/compvision/members/vilem/"
            ]
        ],
        "links": [
            [
                "project",
                "https://saic-mdal.github.io/lama-project/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.07161"
            ],
            [
                "git",
                "https://github.com/saic-mdal/lama"
            ],
            [
                "git",
                "https://github.com/andy971022/auto-lama"
            ],
            [
                "git",
                "https://github.com/richzhang/PerceptualSimilarity"
            ],
            [
                "git",
                "https://github.com/Po-Hsun-Su/pytorch-ssim"
            ],
            [
                "git",
                "https://github.com/mseitzer/pytorch-fid"
            ]
        ],
        "colab": "https://colab.research.google.com/github/saic-mdal/lama/blob/master/colab/LaMa_inpainting.ipynb",
        "update": 1642360206.0
    },
    {
        "name": "HuggingArtists",
        "description": "Choose your favorite Artist and train a language model to write new lyrics based on their unique voice",
        "author": [
            [
                "Aleksey Korshuk",
                "https://github.com/AlekseyKorshuk"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/AlekseyKorshuk/huggingartists"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb",
        "update": 1640166667.0
    },
    {
        "name": "RVM",
        "description": "Robust High-Resolution Video Matting with Temporal Guidance",
        "author": [
            [
                "Peter Lin",
                "https://github.com/PeterL1n"
            ],
            [
                "Linjie Yang",
                "https://sites.google.com/site/linjieyang89/"
            ],
            [
                "Imran Saleemi",
                "http://www.cs.ucf.edu/~imran/"
            ],
            [
                "Soumyadip Sengupta",
                "https://homes.cs.washington.edu/~soumya91/"
            ]
        ],
        "links": [
            [
                "project",
                "https://peterl1n.github.io/RobustVideoMatting"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/2108.11515"
            ],
            [
                "youtube",
                "https://youtu.be/Jvzltozpbpk"
            ],
            [
                "youtube",
                "https://youtu.be/Ay-mGCEYEzM"
            ],
            [
                "git",
                "https://github.com/PeterL1n/RobustVideoMatting"
            ],
            [
                "git",
                "https://github.com/NVIDIA/VideoProcessingFramework"
            ],
            [
                "git",
                "https://github.com/FeiGeChuanShu/ncnn_Android_RobustVideoMatting"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/10z-pNKRnVNsp0Lq9tH1J_XPZ7CBC_uHm",
        "update": 1637742544.201
    },
    {
        "name": "IC-GAN",
        "description": "Instance-Conditioned GAN",
        "author": [
            [
                "Arantxa Casanova",
                "https://github.com/ArantxaCasanova"
            ],
            [
                "Marlène Careil",
                "https://www.linkedin.com/in/marl%C3%A8ne-careil-901804155"
            ],
            [
                "Jakob Verbeek",
                "http://thoth.inrialpes.fr/~verbeek/"
            ],
            [
                "Michał Drożdżal",
                "https://scholar.google.com/citations?user=XK_ktwQAAAAJ"
            ],
            [
                "Adriana Romero-Soriano",
                "https://sites.google.com/site/adriromsor"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/ic_gan"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.05070"
            ],
            [
                "git",
                "https://github.com/facebookresearch/faiss"
            ],
            [
                "git",
                "https://github.com/ajbrock/BigGAN-PyTorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada-pytorch"
            ],
            [
                "git",
                "https://github.com/bioinf-jku/TTUR"
            ],
            [
                "git",
                "https://github.com/mit-han-lab/data-efficient-gans"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/instance-conditioned-gans/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/ic_gan/blob/master/inference/icgan_colab.ipynb",
        "update": 1633084350.0
    },
    {
        "name": "Music Composer",
        "description": "Synthesizing symbolic music in MIDI format using the Music Transformer model",
        "author": [
            [
                "bazanovvanya",
                "https://github.com/bazanovvanya"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/sberbank-ai/music-composer"
            ],
            [
                "git",
                "https://github.com/gwinndr/MusicTransformer-Pytorch"
            ],
            [
                "git",
                "https://github.com/bytedance/GiantMIDI-Piano"
            ],
            [
                "git",
                "https://github.com/mdeff/fma"
            ],
            [
                "data",
                "https://magenta.tensorflow.org/datasets/maestro"
            ],
            [
                "data",
                "https://colinraffel.com/projects/lmd/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.05858"
            ],
            [
                "blog post",
                "https://habr.com/ru/company/sberbank/blog/583592/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/sberbank-ai/music-composer/blob/master/src/Music_Composer_Demo_Colab_en.ipynb",
        "update": 1639987220.0
    },
    {
        "name": "T0",
        "description": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "author": [
            [
                "Victor Sanh",
                "https://github.com/VictorSanh"
            ],
            [
                "Albert Webson",
                "https://representation.ai/"
            ],
            [
                "Colin Raffel",
                "https://colinraffel.com/"
            ],
            [
                "Stephen Bach",
                "http://cs.brown.edu/people/sbach/"
            ],
            [
                "Lintang Sutawika",
                "https://github.com/lintangsutawika"
            ],
            [
                "Zaid Alyafeai",
                "https://github.com/zaidalyafeai"
            ],
            [
                "Antoine Chaffin",
                "https://antoine.chaffin.fr/"
            ],
            [
                "Arnaud Stiegler",
                "https://github.com/arnaudstiegler"
            ],
            [
                "Teven Le Scao",
                "https://scholar.google.com/citations?user=ik0_vxsAAAAJ"
            ],
            [
                "Arun Raja",
                "https://www.arunraja.dev/"
            ],
            [
                "Manan Dey",
                "https://github.com/manandey"
            ],
            [
                "M Saiful Bari",
                "https://sbmaruf.github.io/"
            ],
            [
                "Canwen Xu",
                "https://www.canwenxu.net/"
            ],
            [
                "Urmish Thakker",
                "https://github.com/Urmish"
            ],
            [
                "Shanya Sharma",
                "https://shanyas10.github.io/"
            ],
            [
                "Eliza Szczechla",
                "https://elsanns.github.io/"
            ],
            [
                "Taewoon Kim",
                "https://tae898.github.io/"
            ],
            [
                "Gunjan Chhablani",
                "https://gchhablani.github.io/"
            ],
            [
                "Nihal Nayak",
                "https://nihalnayak.github.io/"
            ],
            [
                "Debajyoti Datta",
                "http://debajyotidatta.github.io/"
            ],
            [
                "Jonathan Chang",
                "https://github.com/cccntu/"
            ],
            [
                "Mike Tian-Jian Jiang",
                "https://github.com/tianjianjiang"
            ],
            [
                "Matteo Manica",
                "https://github.com/drugilsberg"
            ],
            [
                "Sheng Shen",
                "https://sincerass.github.io/"
            ],
            [
                "Zheng Xin Yong",
                "https://yongzx.github.io/"
            ],
            [
                "Harshit Pandey",
                "https://scholar.google.com/citations?user=BPIs78gAAAAJ"
            ],
            [
                "Rachel Bawden",
                "https://rbawden.github.io/"
            ],
            [
                "Trishala Neeraj",
                "https://github.com/trishalaneeraj"
            ],
            [
                "Jos Rozen",
                "https://scholar.google.com/citations?user=OxEDKogAAAAJ"
            ],
            [
                "Abheesht Sharma",
                "https://github.com/abheesht-sharma"
            ],
            [
                "Andrea Santilli",
                "https://teelinsan.github.io/"
            ],
            [
                "Thibault Fevry",
                "http://thibaultfevry.com/"
            ],
            [
                "Jason Alan Fries",
                "https://web.stanford.edu/~jfries/"
            ],
            [
                "Ryan Teehan",
                "https://github.com/rteehas"
            ],
            [
                "Stella Biderman",
                "https://www.stellabiderman.com/"
            ],
            [
                "Leo Gao",
                "https://github.com/leogao2"
            ],
            [
                "Tali Bers",
                "https://github.com/tbers-coursera"
            ],
            [
                "Thomas Wolf",
                "https://thomwolf.io/"
            ],
            [
                "Alexander M. Rush",
                "https://scholar.google.com/citations?user=LIjnUGgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2110.08207"
            ],
            [
                "youtube",
                "https://youtu.be/iJ0IVZgGjTM"
            ],
            [
                "youtube",
                "https://youtu.be/YToXXfrIu6w"
            ],
            [
                "git",
                "https://github.com/bigscience-workshop/promptsource/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1xx7SgdLaAu23YFBirXmaQViDr8caowX_",
        "update": 1635243744.414
    },
    {
        "name": "ArcaneGAN",
        "description": "Process video in the style of the Arcane animated series",
        "author": [
            [
                "Alexander Spirin",
                "https://github.com/Sxela"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Sxela/ArcaneGAN"
            ],
            [
                "git",
                "https://github.com/Sxela/stylegan3_blending"
            ],
            [
                "youtube",
                "https://youtu.be/Fi199uFW6jE"
            ],
            [
                "youtube",
                "https://youtu.be/AJG4X7IokG8"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1r1hhciakk5wHaUn1eJk7TP58fV9mjy_W",
        "update": 1645095391.826
    },
    {
        "name": "SOAT",
        "description": "StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "Hsin-Ying Lee",
                "http://hsinyinglee.com/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/SOAT"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.01619"
            ],
            [
                "git",
                "https://github.com/justinpinkney/toonify"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mchong6/SOAT/blob/master/infinity.ipynb",
        "update": 1636810684.0
    },
    {
        "name": "JoJoGAN",
        "description": "One Shot Face Stylization",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/JoJoGAN"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.11641"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/replicate/cog"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mchong6/JoJoGAN/blob/master/stylize.ipynb",
        "update": 1643831380.0
    },
    {
        "name": "GANs N' Roses",
        "description": "Stable, Controllable, Diverse Image to Image Translation",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/GANsNRoses"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/znxlwm/UGATIT-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.06561"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.06600"
            ],
            [
                "youtube",
                "https://youtu.be/VNg0NyCGl_4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mchong6/GANsNRoses/blob/master/inference_colab.ipynb",
        "update": 1624108882.0
    },
    {
        "name": "SwinIR",
        "description": "Image Restoration Using Swin Transformer",
        "author": [
            [
                "Jingyun Liang",
                "https://jingyunliang.github.io/"
            ],
            [
                "Jiezhang Cao",
                "https://github.com/caojiezhang"
            ],
            [
                "Guolei Sun",
                "https://github.com/GuoleiSun"
            ],
            [
                "Kai Zhang",
                "https://cszn.github.io/"
            ],
            [
                "Luc Van Gool",
                "https://scholar.google.com/citations?user=TwMib_QAAAAJ"
            ],
            [
                "Radu Timofte",
                "http://people.ee.ethz.ch/~timofter/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2108.10257"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.10833"
            ],
            [
                "git",
                "https://github.com/JingyunLiang/SwinIR"
            ],
            [
                "git",
                "https://github.com/cszn/BSRGAN"
            ],
            [
                "git",
                "https://github.com/microsoft/Swin-Transformer"
            ],
            [
                "git",
                "https://github.com/cszn/KAIR"
            ]
        ],
        "colab": "https://colab.research.google.com/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb",
        "update": 1633711003.0
    },
    {
        "name": "VRT",
        "description": "A Video Restoration Transformer",
        "author": [
            [
                "Jingyun Liang",
                "https://jingyunliang.github.io/"
            ],
            [
                "Jiezhang Cao",
                "https://github.com/caojiezhang"
            ],
            [
                "Yuchen Fan",
                "https://ychfan.github.io/"
            ],
            [
                "Kai Zhang",
                "https://cszn.github.io/"
            ],
            [
                "Yawei Li",
                "https://ofsoundof.github.io/"
            ],
            [
                "Radu Timofte",
                "http://people.ee.ethz.ch/~timofter/"
            ],
            [
                "Luc Van Gool",
                "https://scholar.google.com/citations?user=TwMib_QAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/JingyunLiang/VRT"
            ],
            [
                "git",
                "https://github.com/cszn/KAIR"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Video-Swin-Transformer"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmediting"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12288"
            ]
        ],
        "colab": "https://colab.research.google.com/gist/JingyunLiang/deb335792768ad9eb73854a8efca4fe0/vrt-demo-on-video-restoration.ipynb",
        "update": 1645791495.0
    },
    {
        "name": "XLS-R",
        "description": "Self-supervised Cross-lingual Speech Representation Learning at Scale",
        "author": [
            [
                "Arun Babu",
                "https://github.com/arbabu123"
            ],
            [
                "Changhan Wang",
                "https://www.changhan.me/"
            ],
            [
                "Andros Tjandra",
                "https://github.com/androstj"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Qiantong Xu",
                "https://github.com/xuqiantong"
            ],
            [
                "Naman Goyal",
                "https://scholar.google.com/citations?user=CRbM_P4AAAAJ"
            ],
            [
                "Kritika Singh",
                "https://scholar.google.com/citations?user=Ltk3SykAAAAJ"
            ],
            [
                "Patrick von Platen",
                "https://github.com/patrickvonplaten"
            ],
            [
                "Yatharth Saraf",
                "https://scholar.google.com/citations?user=KJTtNJwAAAAJ"
            ],
            [
                "Juan Pino",
                "https://scholar.google.com/citations?user=weU_-4IAAAAJ"
            ],
            [
                "Alexei Baevski",
                "https://github.com/alexeib"
            ],
            [
                "Alexis Conneau",
                "https://github.com/aconneau"
            ],
            [
                "Michael Auli",
                "https://github.com/michaelauli"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2111.09296"
            ],
            [
                "blog post",
                "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2"
            ],
            [
                "git",
                "https://github.com/pytorch/fairseq/blob/main/examples/wav2vec/xlsr/README.md"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ]
        ],
        "colab": "https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLS_R_on_Common_Voice.ipynb",
        "update": 1643813558.0
    },
    {
        "name": "MTTR",
        "description": "End-to-End Referring Video Object Segmentation with Multimodal Transformers",
        "author": [
            [
                "Adam Botach",
                "https://www.linkedin.com/in/adam-botach"
            ],
            [
                "Evgenii Zheltonozhskii",
                "https://evgeniizh.com/"
            ],
            [
                "Chaim Baskin",
                "https://github.com/chaimbaskin"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2111.14821"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.11692"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13230"
            ],
            [
                "git",
                "https://github.com/mttr2021/MTTR"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Video-Swin-Transformer"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12p0jpSx3pJNfZk-y_L44yeHZlhsKVra-",
        "update": 1646010187.78
    },
    {
        "name": "FuseDream",
        "description": "Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization",
        "author": [
            [
                "Xingchao Liu",
                "https://scholar.google.com/citations?user=VOTVE0UAAAAJ"
            ],
            [
                "Chengyue Gong",
                "https://github.com/ChengyueGongR"
            ],
            [
                "Lemeng Wu",
                "https://github.com/klightz"
            ],
            [
                "Hao Su",
                "https://cseweb.ucsd.edu//~haosu/"
            ],
            [
                "Qiang Liu",
                "https://www.cs.utexas.edu/~lqiang/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2112.01573"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/190tKQf0aFj-Hi8STUrLc2m4DeOviv7NO",
        "update": 1641149798.191
    },
    {
        "name": "Demucs",
        "description": "Hybrid Spectrogram and Waveform Source Separation",
        "author": [
            [
                "Alexandre Défossez",
                "https://ai.honu.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2111.03600"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.01733"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.05418"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1805.02410"
            ],
            [
                "git",
                "https://github.com/facebookresearch/demucs/"
            ],
            [
                "git",
                "https://github.com/adefossez/mdx21_demucs"
            ],
            [
                "git",
                "https://github.com/CarlGao4/Demucs-Gui"
            ],
            [
                "git",
                "https://github.com/kuielab/mdx-net-submission"
            ],
            [
                "git",
                "https://github.com/f90/Wave-U-Net"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH",
        "update": 1648049819.06
    }
]
