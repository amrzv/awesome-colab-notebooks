[
    {
        "name": "RSNA Pneumonia Detection Challenge (MD.ai API)",
        "description": "The basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06870"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/rsna-pneumonia-detection-challenge"
            ],
            [
                "annotator",
                "https://public.md.ai/annotator/project/LxR6zdR2/workspace"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py",
                24
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-mdai-client-lib.ipynb",
        "update": 1535550003.0
    },
    {
        "name": "Classification of chest vs. adominal X-rays",
        "description": "The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "annotator",
                "https://public.md.ai/annotator/project/PVq9raBJ"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py",
                24
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson1-xray-images-classification.ipynb",
        "update": 1583560020.0
    },
    {
        "name": "Lung X-Rays Semantic Segmentation",
        "description": "This lesson applies a U-Net for Semantic Segmentation of the lung fields on chest x-rays",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1505.04597"
            ],
            [
                "annotator",
                "https://public.md.ai/annotator/project/aGq4k6NW"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py",
                24
            ],
            [
                "data",
                "https://ceb.nlm.nih.gov/repositories/tuberculosis-chest-x-ray-image-data-sets/"
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson2-lung-xrays-segmentation.ipynb",
        "update": 1583560020.0
    },
    {
        "name": "RSNA Pneumonia Detection Challenge (Kaggel API)",
        "description": "The basics of parsing the competition dataset, training using a detector basd on the Mask-RCNN algorithm for object detection and instance segmentation",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06870"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/rsna-pneumonia-detection-challenge"
            ],
            [
                "annotator",
                "https://public.md.ai/annotator/project/LxR6zdR2/workspace"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py",
                24
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson3-rsna-pneumonia-detection-kaggle.ipynb",
        "update": 1535966306.0
    },
    {
        "name": "Transfer learning and fine-tuning",
        "description": "You will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network",
        "author": [
            [
                "Fran√ßois Chollet",
                "https://fchollet.com/"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Transfer_learning"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/transfer-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb",
        "update": 1654639112.0
    },
    {
        "name": "DeepDream",
        "description": "This tutorial contains a minimal implementation of DeepDream: an experiment that visualizes the patterns learned by a neural network",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1409.4842"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Inception"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb",
        "update": 1642030618.0
    },
    {
        "name": "Neural style transfer",
        "description": "This tutorial uses deep learning to compose one image in the style of another image",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/style_transfer.ipynb",
        "update": 1664206365.0
    },
    {
        "name": "Adversarial FGSM",
        "description": "This tutorial creates an adversarial example using the Fast Gradient Signed Method attack. This was one of the first and most popular attacks to fool a neural network.",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6572"
            ],
            [
                "tf",
                "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications/MobileNetV2"
            ],
            [
                "imagenet",
                "http://www.image-net.org/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb",
        "update": 1615572917.0
    },
    {
        "name": "Autoencoders",
        "description": "This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "book",
                "https://www.deeplearningbook.org/contents/autoencoders.html"
            ],
            [
                "data",
                "http://www.timeseriesclassification.com/description.php?Dataset=ECG5000"
            ],
            [
                "blog post",
                "https://blog.keras.io/building-autoencoders-in-keras.html"
            ],
            [
                "examples",
                "https://anomagram.fastforwardlabs.com/#/"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/autoencoder"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/autoencoder.ipynb",
        "update": 1649152958.0
    },
    {
        "name": "CVAE",
        "description": "This notebook demonstrates how train a Variational Autoencoder on the MNIST dataset",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1312.6114"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1401.4082"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb",
        "update": 1616431523.0
    },
    {
        "name": "CycleGAN",
        "description": "This notebook demonstrates unpaired image to image translation using conditional GAN's",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.10593"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/cycle_gan"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb",
        "update": 1659465693.0
    },
    {
        "name": "DCGAN",
        "description": "This tutorial demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1511.06434"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/jessicali9530/celeba-dataset"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1701.00160"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb",
        "update": 1615573399.0
    },
    {
        "name": "Pix2Pix",
        "description": "This notebook demonstrates image to image translation using conditional GAN's",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1611.07004"
            ],
            [
                "data",
                "https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb",
        "update": 1678324111.0
    },
    {
        "name": "Simple audio recognition",
        "description": "This tutorial will show you how to build a basic speech recognition network that recognizes ten different words",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/speech_commands"
            ],
            [
                "coursera",
                "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe"
            ],
            [
                "tf.js",
                "https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab/index.html#0"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/speech-recognition"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb",
        "update": 1677331499.0
    },
    {
        "name": "Image classification",
        "description": "This tutorial shows how to classify images of flowers",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "paperswithcode",
                "https://paperswithcode.com/task/image-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb",
        "update": 1678050799.0
    },
    {
        "name": "CNN",
        "description": "This tutorial demonstrates training a simple Convolutional Neural Network to classify CIFAR images",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "link",
                "https://developers.google.com/machine-learning/glossary/#convolutional_neural_network"
            ],
            [
                "cifar",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb",
        "update": 1621628508.0
    },
    {
        "name": "Data augmentation",
        "description": "This tutorial demonstrates data augmentation: a technique to increase the diversity of your training set by applying random transformations such as image rotation",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Data_augmentation"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/tf_flowers"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/data-augmentation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb",
        "update": 1677722037.0
    },
    {
        "name": "Image segmentation",
        "description": "This tutorial focuses on the task of image segmentation, using a modified U-Net",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "u-net",
                "https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/"
            ],
            [
                "data",
                "https://www.robots.ox.ac.uk/~vgg/data/pets/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/carvana-image-masking-challenge/overview"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb",
        "update": 1679037942.0
    },
    {
        "name": "Integrated gradients",
        "description": "This tutorial demonstrates how to implement Integrated Gradients, an Explainable AI technique",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.01365"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Linear_interpolation"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Riemann_sum"
            ],
            [
                "git",
                "https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/integrated_gradients",
                6807
            ],
            [
                "visualizing",
                "https://distill.pub/2020/attribution-baselines/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb",
        "update": 1656549976.0
    },
    {
        "name": "Actor-Critic",
        "description": "This tutorial demonstrates how to implement the Actor-Critic method using TensorFlow to train an agent on the Open AI Gym CartPole-V0 environment",
        "author": [
            [
                "Mark Daoust",
                "https://github.com/MarkDaoust"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf"
            ],
            [
                "gym",
                "https://gym.openai.com/"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Temporal_difference_learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb",
        "update": 1671097510.0
    },
    {
        "name": "Classify text with BERT",
        "description": "This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "data",
                "https://ai.stanford.edu/~amaas/data/sentiment/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1711.05101"
            ],
            [
                "tf",
                "https://tfhub.dev/google/collections/bert/1"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/text-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb",
        "update": 1676496556.0
    },
    {
        "name": "Image captioning",
        "description": "Given an image our goal is to generate a caption",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1502.03044"
            ],
            [
                "data",
                "https://cocodataset.org/#home"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb",
        "update": 1666811466.0
    },
    {
        "name": "NMT with attention",
        "description": "This notebook trains a seq2seq model for Spanish to English translation",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1409.0473"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Neural_machine_translation"
            ],
            [
                "data",
                "http://www.manythings.org/anki/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.04025v5"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb",
        "update": 1676496556.0
    },
    {
        "name": "GLUE using BERT on TPU",
        "description": "This tutorial contains complete end-to-end code to train models on a TPU",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "GLUE",
                "https://gluebenchmark.com/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/tpu"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/bert_glue.ipynb",
        "update": 1676496556.0
    },
    {
        "name": "Text classification with RNN",
        "description": "This text classification tutorial trains a recurrent neural network on the IMDB large movie review dataset for sentiment analysis",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "link",
                "https://developers.google.com/machine-learning/glossary/#recurrent_neural_network"
            ],
            [
                "data",
                "http://ai.stanford.edu/~amaas/data/sentiment/"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/text-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb",
        "update": 1647511729.0
    },
    {
        "name": "Text generation with RNN",
        "description": "This tutorial demonstrates how to generate text using a character-based RNN",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "link",
                "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/text-generation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb",
        "update": 1651527963.0
    },
    {
        "name": "Transformer",
        "description": "This tutorial trains a Transformer model to translate Portuguese to English",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "link",
                "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1903.03878"
            ],
            [
                "git",
                "https://github.com/neulab/word-embeddings-for-nmt",
                110
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb",
        "update": 1680898869.0
    },
    {
        "name": "Word2Vec",
        "description": "Word2Vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1301.3781"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
            ],
            [
                "projector",
                "http://projector.tensorflow.org/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Zipf%27s_law"
            ],
            [
                "link",
                "https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/cbow-word2vec"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/skip-gram-word2vec"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb",
        "update": 1663904502.0
    },
    {
        "name": "Word embeddings",
        "description": "This tutorial contains an introduction to word embeddings",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "projector",
                "http://projector.tensorflow.org/"
            ],
            [
                "data",
                "http://ai.stanford.edu/~amaas/data/sentiment/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/guide/word_embeddings.ipynb",
        "update": 1642280780.0
    },
    {
        "name": "Building Your Own Federated Learning Algorithm",
        "description": "We discuss how to implement federated learning algorithms without deferring to the tff.learning API",
        "author": [
            [
                "Zachary Charles",
                "https://zachcharles.com/"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.08610"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "Federated Learning for Image Classification",
        "description": "We use the classic MNIST training example to introduce the Federated Learning API layer of TFF, tff.learning - a set of higher-level interfaces that can be used to perform common types of federated learning tasks, such as federated training, against user-supplied models implemented in TensorFlow",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "data",
                "https://www.nist.gov/srd/nist-special-database-19"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "medium",
                "https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/image-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "Federated Learning for Text Generation",
        "description": "We start with a RNN that generates ASCII characters, and refine it via federated learning",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "data",
                "http://www.ibiblio.org/pub/docs/books/gutenberg/9/98/98.txt"
            ],
            [
                "data",
                "http://www.ibiblio.org/pub/docs/books/gutenberg/4/46/46.txt"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.01097"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "Custom Federated Algorithms, Part 1: Introduction to the Federated Core",
        "description": "This tutorial is the first part of a two-part series that demonstrates how to implement custom types of federated algorithms in TensorFlow Federated using the Federated Core - a set of lower-level interfaces that serve as a foundation upon which we have implemented the Federated Learning layer",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_core"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_learning"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_1.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "Custom Federated Algorithms, Part 2: Implementing Federated Averaging",
        "description": "This tutorial is the second part of a two-part series that demonstrates how to implement custom types of federated algorithms in TFF using the Federated Core, which serves as a foundation for the Federated Learning layer",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_core"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_learning"
            ],
            [
                "git",
                "https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/learning/federated_averaging.py",
                2118
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_2.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "TFF for Federated Learning Research: Model and Update Compression",
        "description": "We use the EMNIST dataset to demonstrate how to enable lossy compression algorithms to reduce communication cost in the Federated Averaging algorithm",
        "author": [
            [
                "Weikang Song",
                "https://github.com/swkpku"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process"
            ],
            [
                "tensor encoding",
                "http://jakubkonecny.com/files/tensor_encoding.pdf"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/tff_for_federated_learning_research_compression.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "High-performance simulations with TFF",
        "description": "This tutorial will describe how to setup high-performance simulations with TFF in a variety of common scenarios",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/simulations.ipynb",
        "update": 1684429367.0
    },
    {
        "name": "High-performance Simulation with Kubernetes",
        "description": "This tutorial will describe how to set up high-performance simulation using a TFF runtime running on Kubernetes",
        "author": [
            [
                "Jason Roselander",
                "https://github.com/roselander"
            ]
        ],
        "links": [
            [
                "GKE",
                "https://cloud.google.com/kubernetes-engine/"
            ],
            [
                "shell",
                "https://cloud.google.com/shell/"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb",
        "update": 1675186266.0
    },
    {
        "name": "Introduction to the TensorFlow Models NLP library",
        "description": "You will learn how to build transformer-based models for common NLP tasks including pretraining, span labelling and classification using the building blocks from NLP modeling library",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/models/tree/master/official/nlp/modeling",
                75872
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/nlp/nlp_modeling_library_intro.ipynb",
        "update": 1655916395.0
    },
    {
        "name": "Context R-CNN Demo",
        "description": "This notebook will walk you step by step through the process of using a pre-trained model to build up a contextual memory bank for a set of images, and then detect objects in those images+context using Context R-CNN",
        "author": [
            [
                "pkulzc",
                "https://github.com/pkulzc"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1912.03538"
            ],
            [
                "data",
                "https://lila.science/datasets/snapshot-serengeti"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb",
        "update": 1592373557.0
    },
    {
        "name": "Eager Few Shot Object Detection",
        "description": "Fine tuning of a RetinaNet architecture on very few examples of a novel class after initializing from a pre-trained COCO checkpoint",
        "author": [
            [
                "kmindspark",
                "https://github.com/kmindspark"
            ]
        ],
        "links": [
            [
                "data",
                "https://cocodataset.org/#explore"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/few-shot-object-detection"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1708.02002"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb",
        "update": 1594424757.0
    },
    {
        "name": "Deep-MAC",
        "description": "Welcome to the Novel class segmentation demo",
        "author": [
            [
                "Vighnesh Birodkar",
                "http://vighneshbirodkar.github.io/"
            ]
        ],
        "links": [
            [
                "paperswithcode",
                "https://paperswithcode.com/method/deep-mac"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00613"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/deepmac_colab.ipynb",
        "update": 1660077013.0
    },
    {
        "name": "Train a GPT-2 Text-Generating Model",
        "description": "Retrain an advanced text generating neural network on any text dataset for free on a GPU using Colaboratory using aitextgen!",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/aitextgen",
                1769
            ],
            [
                "docs",
                "https://docs.aitextgen.io/"
            ],
            [
                "data",
                "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/task/text-generation"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD",
        "update": 1621222440.007
    },
    {
        "name": "Custom GPT-2 + Tokenizer",
        "description": "Train a custom GPT-2 model for free on a GPU using aitextgen!",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/aitextgen",
                1769
            ],
            [
                "docs",
                "https://docs.aitextgen.io/"
            ],
            [
                "data",
                "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/144MdX5aLqrQ3-YW-po81CQMrD6kpgpYh",
        "update": 1621222464.69
    },
    {
        "name": "Train a GPT-2 Model on Tweets",
        "description": "Train the model on your downloaded tweets, and generate massive amounts of Tweets from it",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/download-tweets-ai-text-gen",
                215
            ],
            [
                "GPT-2",
                "https://openai.com/blog/better-language-models/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1qxcQ2A1nNjFudAGN_mcMOnvV9sF_PkEb",
        "update": 1579148034.702
    },
    {
        "name": "automl-gs on a TPU",
        "description": "Give an input CSV file and a target field you want to predict to automl-gs, and get a trained high-performing machine learning or deep learning model plus native Python code pipelines allowing you to integrate that model into any prediction workflow",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/automl-gs",
                1813
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1sbF8cqnOsdzN9Bdt74eER5s_xXcdvatV",
        "update": 1553580859.738
    },
    {
        "name": "textgenrnn",
        "description": "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "http://minimaxir.com/2018/05/text-neural-networks/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=RW7mP6BfZuY"
            ],
            [
                "git",
                "https://github.com/minimaxir/textgenrnn",
                4901
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK",
        "update": 1626144610.804
    },
    {
        "name": "YOLOv4",
        "description": "This tutorial will help you build YOLOv4 easily in the cloud with GPU enabled so that you can run object detections in milliseconds!",
        "author": [
            [
                "Alexey Bochkovskiy",
                "http://www.alexeyab.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.10934"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.08036"
            ],
            [
                "git",
                "https://github.com/AlexeyAB/darknet",
                20633
            ],
            [
                "project",
                "https://pjreddie.com/darknet/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/gydxzd/p_yolov4_the_most_accurate_realtime_neural/"
            ],
            [
                "medium",
                "https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe"
            ],
            [
                "medium",
                "https://alexeyab84.medium.com/scaled-yolo-v4-is-the-best-neural-network-for-object-detection-on-ms-coco-dataset-39dfa22fa982"
            ],
            [
                "youtube",
                "https://youtu.be/1_SiUOYUoOI"
            ],
            [
                "youtube",
                "https://youtu.be/YDFf-TqJOFE"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1_GdoqCJWXsChrOiY8sZMr_zbr_fH-0Fg",
        "update": 1593048824.334
    },
    {
        "name": "YOLOv5 on Custom Objects",
        "description": "This notebook shows training on your own custom objects",
        "author": [
            [
                "Jacob Solawetz",
                "https://blog.roboflow.com/author/jacob/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov5",
                38987
            ],
            [
                "blog post",
                "https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/"
            ],
            [
                "data",
                "https://public.roboflow.ai/object-detection/bccd"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ",
        "update": 1658345581.74
    },
    {
        "name": "Python Data Science Handbook",
        "description": "Jupyter notebook version of the Python Data Science Handbook by Jake VanderPlas",
        "author": [
            [
                "Jake Vanderplas",
                "http://vanderplas.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jakevdp/PythonDataScienceHandbook",
                38545
            ],
            [
                "project",
                "https://jakevdp.github.io/PythonDataScienceHandbook/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb",
        "update": 1683321645.0
    },
    {
        "name": "TensorNetwork",
        "description": "A library for easy and efficient manipulation of tensor networks",
        "author": [
            [
                "Chase Roberts",
                "http://thenerdstation.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/TensorNetwork",
                1676
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=YN2YBB0viKo"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1708.00006"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1306.2164"
            ],
            [
                "docs",
                "https://tensornetwork.readthedocs.io/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/TensorNetwork/blob/master/colabs/Tensor_Networks_in_Neural_Networks.ipynb",
        "update": 1611188677.0
    },
    {
        "name": "BIG-bench",
        "description": "A collaborative benchmark intended to probe large language models and extrapolate their future capabilities",
        "author": [
            [
                "Jaehoon Lee",
                "https://jaehlee.github.io/"
            ],
            [
                "Jascha Sohl-Dickstein",
                "http://www.sohldickstein.com/"
            ],
            [
                "Vinay Ramasesh",
                "https://ramasesh.github.io/"
            ],
            [
                "Sajant Anand",
                "https://github.com/sajantanand"
            ],
            [
                "Alicia Parrish",
                "https://aliciaparrish.com/"
            ],
            [
                "Ethan Dyer",
                "https://github.com/ethansdyer"
            ],
            [
                "Liam Dugan",
                "http://liamdugan.com/"
            ],
            [
                "Dieuwke Hupkes",
                "https://github.com/dieuwkehupkes"
            ],
            [
                "Daniel Freeman",
                "https://github.com/cdfreeman-google"
            ],
            [
                "Guy Gur-Ari",
                "https://github.com/guygurari"
            ],
            [
                "Aitor Lewkowycz",
                "https://github.com/lewkowycz"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2206.04615"
            ],
            [
                "git",
                "https://github.com/google/BIG-bench",
                1951
            ],
            [
                "git",
                "https://github.com/google/seqio"
            ],
            [
                "API",
                "https://google.github.io/BIG-bench/docs/html/bigbench/index.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/BIG-bench/blob/master/notebooks/colab_examples.ipynb",
        "update": 1656360704.0
    },
    {
        "name": "The Autodiff Cookbook",
        "description": "You'll go through a whole bunch of neat autodiff ideas that you can cherry pick for your own work, starting with the basics",
        "author": [
            [
                "Alex Wiltschko",
                "https://github.com/alexbw"
            ],
            [
                "Matthew Johnson",
                "http://people.csail.mit.edu/mattjj/"
            ]
        ],
        "links": [
            [
                "book",
                "https://mitpress.mit.edu/sites/default/files/titles/content/sicm_edition_2/book.html"
            ],
            [
                "book",
                "https://mitpress.mit.edu/books/functional-differential-geometry"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Truncated_Newton_method"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pullback_(differential_geometry)"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Holomorphic_function"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1406.2572"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.04454"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.03451"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.07062"
            ],
            [
                "tutorial",
                "http://videolectures.net/deeplearning2017_johnson_automatic_differentiation/"
            ],
            [
                "git",
                "https://github.com/google/jax/issues/446#issuecomment-467105048",
                23365
            ],
            [
                "git",
                "https://github.com/google/jax#auto-vectorization-with-vmap"
            ],
            [
                "git",
                "https://github.com/hips/autograd"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/autodiff_cookbook.ipynb",
        "update": 1677690942.0
    },
    {
        "name": "EfficientNetV2",
        "description": "A family of image classification models, which achieve better parameter efficiency and faster training speed than prior arts",
        "author": [
            [
                "Mingxing Tan",
                "https://scholar.google.com/citations?user=6POeyBoAAAAJ"
            ],
            [
                "Quoc Le",
                "https://cs.stanford.edu/~quocle/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00298"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.11946"
            ],
            [
                "git",
                "https://github.com/google/automl/tree/master/efficientnetv2",
                5880
            ],
            [
                "git",
                "https://github.com/NVIDIA/TensorRT/tree/master/samples/python/efficientnet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/automl/blob/master/efficientnetv2/tutorial.ipynb",
        "update": 1632446690.0
    },
    {
        "name": "SentencePiece",
        "description": "An unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training",
        "author": [
            [
                "Taku Kudo",
                "http://chasen.org/~taku/"
            ],
            [
                "John Richardson",
                "https://scholar.google.com/citations?user=PEvmYfgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1808.06226"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.07909"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1804.10959"
            ],
            [
                "git",
                "https://github.com/google/sentencepiece",
                7494
            ],
            [
                "git",
                "https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl"
            ],
            [
                "git",
                "https://github.com/rsennrich/subword-nmt"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.13267"
            ],
            [
                "medium",
                "https://jacky2wong.medium.com/understanding-sentencepiece-under-standing-sentence-piece-ac8da59f6b08"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.08144"
            ],
            [
                "git",
                "https://github.com/gperftools/gperftools"
            ],
            [
                "git",
                "https://github.com/Microsoft/vcpkg"
            ],
            [
                "youtube",
                "https://youtu.be/U51ranzJBpY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb",
        "update": 1680956773.0
    },
    {
        "name": "Analyzing Tennis Serve",
        "description": "We'll use the Video Intelligence API to analyze a tennis serve, including the angle of the arms and legs during the serve",
        "author": [
            [
                "Dale Markowitz",
                "https://daleonai.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://daleonai.com/machine-learning-for-sports"
            ],
            [
                "git",
                "https://github.com/google/making_with_ml/tree/master/sports_ai",
                313
            ],
            [
                "medium",
                "https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=yLrOy2Xedgk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/making_with_ml/blob/master/sports_ai/Sports_AI_Analysis.ipynb",
        "update": 1594749219.0
    },
    {
        "name": "TF-Ranking",
        "description": "End-to-end walkthrough of training a TensorFlow Ranking neural network model which incorporates sparse textual features",
        "author": [
            [
                "Rama Kumar",
                "https://github.com/ramakumar1729"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1910.09676"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.00073"
            ],
            [
                "data",
                "http://hamedz.ir/resources/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.08957"
            ],
            [
                "git",
                "https://github.com/tensorflow/ranking",
                2633
            ],
            [
                "git",
                "https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/input.proto#L72"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Mean_reciprocal_rank"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Discounted_cumulative_gain"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.04415"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb",
        "update": 1612412908.0
    },
    {
        "name": "Detectron2",
        "description": "FAIR's next-generation platform for object detection and segmentation",
        "author": [
            [
                "Yuxin Wu",
                "http://ppwwyyxx.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/detectron2",
                25013
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/"
            ],
            [
                "docs",
                "https://detectron2.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5",
        "update": 1685069239.579
    },
    {
        "name": "Droidlet",
        "description": "A modular embodied agent architecture and platform for building embodied agents",
        "author": [
            [
                "Anurag Pratik",
                "https://github.com/anuragprat1k"
            ],
            [
                "Soumith Chintala",
                "https://soumith.ch/"
            ],
            [
                "Kavya Srinet",
                "https://github.com/kavyasrinet"
            ],
            [
                "Dhiraj Gandhi",
                "https://dhiraj100892.github.io/"
            ],
            [
                "Rebecca Qian",
                "https://github.com/Rebecca-Qian"
            ],
            [
                "Yuxuan Sun",
                "https://github.com/snyxan"
            ],
            [
                "Ryan Drew",
                "https://rdrew.dev/"
            ],
            [
                "Sara Elkafrawy",
                "https://github.com/saraEbrahim"
            ],
            [
                "Anoushka Tiwari",
                "https://www.linkedin.com/in/anoushka-tiwari"
            ],
            [
                "Tucker Hart",
                "https://www.linkedin.com/in/tucker-hart-05a638133"
            ],
            [
                "Mary Williamson",
                "https://scholar.google.com/citations?user=Ys4xB-QAAAAJ"
            ],
            [
                "Abhinav Gupta",
                "http://www.cs.cmu.edu/~abhinavg/"
            ],
            [
                "Arthur Szlam",
                "https://scholar.google.com/citations?user=u3-FxUgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2101.10384"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.08584"
            ],
            [
                "git",
                "https://github.com/facebookresearch/droidlet",
                800
            ],
            [
                "docs",
                "https://facebookresearch.github.io/droidlet/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/droidlet/blob/master/examples_and_tutorials/tutorials/droidlet_for_physical_robots.ipynb",
        "update": 1631724124.0
    },
    {
        "name": "CompilerGym",
        "description": "A reinforcement learning toolkit for compiler optimizations",
        "author": [
            [
                "Chris Cummins",
                "https://chriscummins.cc/"
            ],
            [
                "Bram Wasti",
                "https://github.com/bwasti"
            ],
            [
                "Jiadong Guo",
                "https://jd-eth.github.io/"
            ],
            [
                "Brandon Cui",
                "https://www.linkedin.com/in/bcui19/"
            ],
            [
                "Jason Ansel",
                "https://jasonansel.com/"
            ],
            [
                "Sahir Gomez",
                "https://github.com/sahirgomez1"
            ],
            [
                "Olivier Teytaud",
                "https://github.com/teytaud"
            ],
            [
                "Benoit Steiner",
                "http://bsteiner.info/"
            ],
            [
                "Yuandong Tian",
                "http://yuandong-tian.com/"
            ],
            [
                "Hugh Leather",
                "https://github.com/hughleat"
            ]
        ],
        "links": [
            [
                "docs",
                "https://facebookresearch.github.io/CompilerGym/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.08267"
            ],
            [
                "git",
                "https://github.com/facebookresearch/CompilerGym",
                776
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/CompilerGym/blob/development/examples/getting-started.ipynb",
        "update": 1637057384.0
    },
    {
        "name": "CoVoST",
        "description": "A Large-Scale Multilingual Speech-To-Text Translation Corpus",
        "author": [
            [
                "Changhan Wang",
                "https://www.changhan.me/"
            ],
            [
                "Juan Pino",
                "https://scholar.google.com/citations?user=weU_-4IAAAAJ"
            ],
            [
                "Jiatao Gu",
                "http://jiataogu.me/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/covost",
                282
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.01320"
            ],
            [
                "arxiv",
                "https://arxiv.org/pdf/2007.10310"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.06670"
            ],
            [
                "git",
                "https://www.changhan.me//SpeechTransProgress"
            ],
            [
                "git",
                "https://github.com/pytorch/fairseq/tree/main/examples/speech_to_text"
            ],
            [
                "git",
                "https://github.com/facebookresearch/vizseq"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/11GK7k7G1CG1qHbdA9Pz1RtQ3vlCkuohV",
        "update": 1596758022.342
    },
    {
        "name": "MyoSuite",
        "description": "A collection of musculoskeletal environments and tasks simulated with the MuJoCo physics engine and wrapped in the OpenAI gym API to enable the application of Machine Learning to bio-mechanic control problems",
        "author": [
            [
                "Vittorio Caggiano",
                "https://github.com/Vittorio-Caggiano"
            ],
            [
                "Huawei Wang",
                "https://huaweiwang.github.io/"
            ],
            [
                "Guillaume Durandau",
                "https://people.utwente.nl/g.v.durandau"
            ],
            [
                "Massimo Sartori",
                "https://people.utwente.nl/m.sartori"
            ],
            [
                "Vikash Kumar",
                "https://vikashplus.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2205.13600"
            ],
            [
                "git",
                "https://github.com/facebookresearch/myosuite",
                608
            ],
            [
                "docs",
                "https://myosuite.readthedocs.io/en/latest/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1U6vo6Q_rPhDaq6oUMV7EAZRm6s0fD1wn",
        "update": 1682753192.886
    },
    {
        "name": "BANMo",
        "description": "Given multiple casual videos capturing a deformable object, BANMo reconstructs an animatable 3D model, including an implicit canonical 3D shape, appearance, skinning weights, and time-varying articulations, without pre-defined shape templates or registered cameras",
        "author": [
            [
                "Gengshan Yang",
                "https://gengshan-y.github.io/"
            ],
            [
                "Minh Vo",
                "https://minhpvo.github.io/"
            ],
            [
                "Natalia Neverova",
                "https://nneverova.github.io/"
            ],
            [
                "Deva Ramanan",
                "http://www.cs.cmu.edu/~deva/"
            ],
            [
                "Andrea Vedaldi",
                "https://www.robots.ox.ac.uk/~vedaldi/"
            ],
            [
                "Hanbyul Joo",
                "https://jhugestar.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/banmo",
                453
            ],
            [
                "project",
                "https://banmo-www.github.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.12761"
            ],
            [
                "git",
                "https://github.com/kwea123/nerf_pl"
            ],
            [
                "git",
                "https://github.com/gengshan-y/rigidmask"
            ],
            [
                "git",
                "https://github.com/ShichenLiu/SoftRas"
            ],
            [
                "git",
                "https://github.com/ThibaultGROUEIX/ChamferDistancePytorch"
            ],
            [
                "youtube",
                "https://youtu.be/1NUa-yvFGA0"
            ],
            [
                "youtube",
                "https://youtu.be/jDTy-liFoCQ"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1dQJn1vsuz0DkyRZbOA1SulkVQ0V1kMUP",
        "update": 1672373422.19
    },
    {
        "name": "AV-HuBERT",
        "description": "Self-supervised representation learning framework for audio-visual speech",
        "author": [
            [
                "Bowen Shi",
                "https://home.ttic.edu/~bshi/"
            ],
            [
                "Wei-Ning Hsu",
                "http://people.csail.mit.edu/wnhsu/"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Abdelrahman Mohamed",
                "http://www.cs.toronto.edu/~asamir/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/av_hubert",
                552
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.02184"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.01763"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/ai-that-understands-speech-by-looking-as-well-as-hearing/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.04890"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1bNXkfpHiVHzXQH8WjGhzQ-fsDxolpUjD",
        "update": 1644689162.002
    },
    {
        "name": "textlesslib",
        "description": "A library aimed to facilitate research in Textless NLP",
        "author": [
            [
                "Eugene Kharitonov",
                "https://eugene-kharitonov.github.io/"
            ],
            [
                "Jade Copet",
                "https://scholar.google.com/citations?user=GRMLwjAAAAAJ"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Nguy·ªÖn T√∫ Anh",
                "https://tuanh208.github.io/"
            ],
            [
                "Paden Tomasello",
                "https://scholar.google.com/citations?user=sBtWMGYAAAAJ"
            ],
            [
                "Ann Lee",
                "https://ai.facebook.com/people/ann-lee"
            ],
            [
                "Ali Elkahky",
                "https://scholar.google.com/citations?user=KB3S8RoAAAAJ"
            ],
            [
                "Wei-Ning Hsu",
                "https://wnhsu.github.io/"
            ],
            [
                "Abdelrahman Mohamed",
                "https://ai.facebook.com/people/abdelrahman-mohamed/"
            ],
            [
                "Emmanuel Dupoux",
                "http://www.lscp.net/persons/dupoux/"
            ],
            [
                "Yossi Adi",
                "https://www.cs.huji.ac.il/~adiyoss/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/textlesslib",
                409
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.07359"
            ],
            [
                "git",
                "https://github.com/NVIDIA/waveglow"
            ],
            [
                "git",
                "https://github.com/keithito/tacotron"
            ],
            [
                "git",
                "https://github.com/NVIDIA/tacotron2"
            ],
            [
                "git",
                "https://github.com/pseeth/torch-stft"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/dataset/librispeech"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/textlesslib/blob/main/examples/resynthesis_and_continuation.ipynb",
        "update": 1644938869.0
    },
    {
        "name": "Home Robot",
        "description": "Low-level API for controlling various home robots",
        "author": [
            [
                "Chris Paxton",
                "https://cpaxton.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/home-robot",
                75
            ],
            [
                "git",
                "https://github.com/cpaxton/contact_graspnet/tree/cpaxton/devel"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairo"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_body"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_firmware"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_ros"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_ros2"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_web_interface"
            ],
            [
                "git",
                "https://github.com/RoboStack/ros-noetic"
            ],
            [
                "git",
                "https://github.com/codekansas/stretch-robot"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/home-robot/blob/master/src/home_robot_sim/notebooks/velocity_control_sim.ipynb",
        "update": 1674672189.0
    },
    {
        "name": "PyTorchVideo",
        "description": "Deeplearning library with a focus on video understanding work",
        "author": [
            [
                "Haoqi Fan",
                "https://haoqifan.github.io/"
            ],
            [
                "Tullie Murrell",
                "https://github.com/tullie"
            ],
            [
                "Heng Wang",
                "https://hengcv.github.io/"
            ],
            [
                "Kalyan Vasudev Alwala",
                "https://github.com/kalyanvasudev"
            ],
            [
                "Yanghao Li",
                "https://github.com/lyttonhao"
            ],
            [
                "Yilei Li",
                "https://liyilui.github.io/personal_page/"
            ],
            [
                "Bo Xiong",
                "https://github.com/bxiong1202"
            ],
            [
                "Nikhila Ravi",
                "https://nikhilaravi.com/"
            ],
            [
                "Meng Li",
                "https://mengli.me/"
            ],
            [
                "Haichuan Yang",
                "https://hyang1990.github.io/"
            ],
            [
                "Jitendra Malik",
                "https://scholar.google.com/citations?user=oY9R5YQAAAAJ"
            ],
            [
                "Ross Girshick",
                "https://github.com/rbgirshick"
            ],
            [
                "Matt Feiszli",
                "https://scholar.google.com/citations?user=A-wA73gAAAAJ"
            ],
            [
                "Aaron Adcock",
                "https://scholar.google.com/citations?&user=oa78zHUAAAAJ"
            ],
            [
                "Wan-Yen Lo",
                "https://github.com/wanyenlo"
            ],
            [
                "Christoph Feichtenhofer",
                "http://feichtenhofer.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/pytorchvideo",
                2886
            ],
            [
                "website",
                "https://github.com/facebookresearch/pytorchvideo"
            ],
            [
                "docs",
                "https://pytorchvideo.readthedocs.io/en/latest/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.09887"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.11227"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3474085.3478329"
            ],
            [
                "youtube",
                "https://youtu.be/b7-gnpqz9Qg"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/pytorchvideo-a-deep-learning-library-for-video-understanding/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/pytorchvideo/blob/main/tutorials/accelerator/Build_your_model_with_PytorchVideo_Accelerator.ipynb",
        "update": 1618329751.0
    },
    {
        "name": "Spleeter",
        "description": "Deezer source separation library including pretrained models",
        "author": [
            [
                "Romain Hennequin",
                "http://romain-hennequin.fr/"
            ],
            [
                "Anis Khlif",
                "https://github.com/alreadytaikeune"
            ],
            [
                "F√©lix Voituret",
                "https://github.com/Faylixe"
            ],
            [
                "Manuel Moussallam",
                "https://mmoussallam.github.io/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://deezer.io/releasing-spleeter-deezer-r-d-source-separation-engine-2b88985e797e"
            ],
            [
                "project",
                "https://research.deezer.com/projects/spleeter.html"
            ],
            [
                "git",
                "https://github.com/deezer/spleeter",
                22654
            ],
            [
                "data",
                "https://sigsep.github.io/datasets/musdb.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deezer/spleeter/blob/master/spleeter.ipynb",
        "update": 1610315062.0
    },
    {
        "name": "GPT Neo",
        "description": "An implementation of model & data parallel GPT2 & GPT3 -like models, with the ability to scale up to full GPT3 sizes (and possibly more!), using the mesh-tensorflow library",
        "author": [
            [
                "EleutherAI",
                "https://www.eleuther.ai/"
            ]
        ],
        "links": [
            [
                "GPT-2",
                "https://openai.com/blog/better-language-models/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.14165"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.05150"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1701.06538"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neo",
                7842
            ],
            [
                "git",
                "https://github.com/tensorflow/mesh"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neox/"
            ],
            [
                "pretrained",
                "https://the-eye.eu/public/AI/gptneo-release/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb",
        "update": 1616941156.0
    },
    {
        "name": "Lucid Sonic Dreams",
        "description": "Syncs GAN-generated visuals to music",
        "author": [
            [
                "Mikael Alafriz",
                "https://github.com/mikaelalafriz"
            ]
        ],
        "links": [
            [
                "youtube",
                "https://youtu.be/l-nGC-ve7sI"
            ],
            [
                "medium",
                "https://towardsdatascience.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1"
            ],
            [
                "git",
                "https://github.com/mikaelalafriz/lucid-sonic-dreams",
                750
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/justinpinkney/awesome-pretrained-stylegan2"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Y5i50xSFIuN3V4Md8TB30_GOAtts7RQD",
        "update": 1629785030.562
    },
    {
        "name": "ruGPT3",
        "description": "Example of inference of RuGPT3XL",
        "author": [
            [
                "Anton Emelyanov",
                "https://github.com/king-menin"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/ru-gpts",
                1870
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM"
            ],
            [
                "huggingface",
                "https://huggingface.co/transformers/main_classes/model.html#transformers.generation_utils.GenerationMixin.generate"
            ],
            [
                "sparse attention",
                "https://www.deepspeed.ai/tutorials/sparse-attention/"
            ],
            [
                "cristofari",
                "https://sbercloud.ru/ru/christofari"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/ru-gpts/blob/master/examples/ruGPT3XL_generation.ipynb",
        "update": 1670404185.0
    },
    {
        "name": "SberSwap",
        "description": "A new face swap method for image and video domains",
        "author": [
            [
                "Daniil Chesakov",
                "https://github.com/Danyache"
            ],
            [
                "Anastasia Maltseva",
                "https://github.com/NastyaMittseva"
            ],
            [
                "Alexander Groshev",
                "https://github.com/AlexanderGroshev"
            ],
            [
                "Andrey Kuznetsov",
                "https://www.linkedin.com/in/andrey-kuznetsov-70ab12127"
            ],
            [
                "Denis Dimitrov",
                "https://github.com/denndimitrov"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/sber-swap",
                660
            ],
            [
                "data",
                "https://www.robots.ox.ac.uk/~vgg/data/vgg_face/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.03046"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.13457"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1901.08971"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.06340"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05005"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.09965"
            ],
            [
                "blog post",
                "https://habr.com/ru/company/sberbank/blog/645919/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/14wnxMvD9zsiBQo2FtTpxn6w2cpXCcb-7",
        "update": 1656492993.669
    },
    {
        "name": "RuDOLPH",
        "description": "A fast and light text-image-text transformer designed for a quick and easy fine-tuning setup for the solution of various tasks: from generating images by text description and image classification to visual question answering and more",
        "author": [
            [
                "Alex Shonenkov",
                "https://github.com/shonenkov"
            ],
            [
                "Michael Konstantinov",
                "https://github.com/zeroshot-ai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/ru-dolph",
                251
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.14165"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.12092"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga",
        "update": 1642174476.466
    },
    {
        "name": "GPT-J-6B",
        "description": "A 6 billion parameter, autoregressive text generation model trained on The Pile",
        "author": [
            [
                "Ben Wang",
                "https://benwang.dev/"
            ],
            [
                "Aran Komatsuzaki",
                "https://arankomatsuzaki.wordpress.com/about-me/"
            ],
            [
                "Janko Prester",
                "https://www.jankoprester.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/kingoflolz/mesh-transformer-jax",
                5916
            ],
            [
                "blog post",
                "https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/"
            ],
            [
                "web demo",
                "https://6b.eleuther.ai/"
            ],
            [
                "The Pile",
                "https://pile.eleuther.ai/"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neox"
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeed"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb",
        "update": 1631670838.0
    },
    {
        "name": "highway-env",
        "description": "A collection of environments for autonomous driving and tactical decision-making tasks",
        "author": [
            [
                "Edouard Leurent",
                "https://edouardleurent.com/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://highway-env.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/eleurent/highway-env",
                1831
            ],
            [
                "git",
                "https://github.com/eleurent/rl-agents"
            ],
            [
                "git",
                "https://github.com/eleurent/finite-mdp"
            ],
            [
                "git",
                "https://github.com/openai/baselines/tree/master/baselines/her"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.03483"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.05701"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2101.07140"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eleurent/highway-env/blob/master/scripts/parking_model_based.ipynb",
        "update": 1682188326.0
    },
    {
        "name": "GAN steerability",
        "description": "We will navigate in GAN latent space to simulate various camera transformations",
        "author": [
            [
                "Ali Jahanian",
                "http://people.csail.mit.edu/jahanian/"
            ],
            [
                "Lucy Chai",
                "http://people.csail.mit.edu/lrchai/"
            ],
            [
                "Phillip Isola",
                "http://web.mit.edu/phillipi/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1907.07171"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ],
            [
                "git",
                "https://github.com/ali-design/gan_steerability",
                264
            ],
            [
                "youtube",
                "https://youtu.be/nS0V64sF7Cw"
            ],
            [
                "project",
                "https://ali-design.github.io/gan_steerability/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1kn6yG8PqD1U2bUcy32V1iAVjzlcQWcG3",
        "update": 1614894616.124
    },
    {
        "name": "GAN Dissection",
        "description": "Visualizing and Understanding Generative Adversarial Networks",
        "author": [
            [
                "David Bau",
                "https://people.csail.mit.edu/davidbau/home/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Hendrik Strobelt",
                "http://hendrik.strobelt.com/"
            ],
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ],
            [
                "Joshua Tenenbaum",
                "https://mitibmwatsonailab.mit.edu/people/joshua-tenenbaum/"
            ],
            [
                "William Freeman",
                "https://billf.mit.edu/"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "project",
                "https://gandissect.csail.mit.edu/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.10597"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1901.09887"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=yVCgUYe4JTM"
            ],
            [
                "demo",
                "http://gandissect.res.ibm.com/ganpaint.html"
            ],
            [
                "git",
                "https://github.com/CSAILVision/GANDissect",
                1749
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.10221"
            ],
            [
                "git",
                "https://github.com/CSAILVision/NetDissect"
            ],
            [
                "git",
                "https://github.com/junyanz/iGAN"
            ]
        ],
        "colab": "https://colab.research.google.com/github/SIDN-IAP/global-model-repr/blob/master/notebooks/gandissect_solutions.ipynb",
        "update": 1588609139.0
    },
    {
        "name": "EasyNMT",
        "description": "Easy to use, state-of-the-art machine translation for more than 100+ languages",
        "author": [
            [
                "Nils Reimers",
                "https://www.nils-reimers.de/"
            ]
        ],
        "links": [
            [
                "demo",
                "http://easynmt.net/demo/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00401"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11125"
            ],
            [
                "git",
                "https://github.com/UKPLab/EasyNMT",
                877
            ],
            [
                "git",
                "https://github.com/Helsinki-NLP/Opus-MT"
            ],
            [
                "git",
                "https://github.com/pytorch/fairseq/tree/master/examples/multilingual"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1X47vgSiOphpxS5w_LPtjQgJmiSTNfRNC",
        "update": 1619468765.741
    },
    {
        "name": "Sentence Transformers",
        "description": "Multilingual Sentence, Paragraph, and Image Embeddings using BERT & Co",
        "author": [
            [
                "Nils Reimers",
                "https://www.nils-reimers.de/"
            ],
            [
                "Iryna Gurevych",
                "https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/UKPLab/sentence-transformers",
                10753
            ],
            [
                "docs",
                "https://www.sbert.net/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1908.10084"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.09813"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.08240"
            ]
        ],
        "colab": "https://colab.research.google.com/github/UKPLab/sentence-transformers/blob/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.ipynb",
        "update": 1631551400.0
    },
    {
        "name": "FLAML",
        "description": "Lightweight Python library that finds accurate machine learning models automatically, efficiently and economically",
        "author": [
            [
                "Chi Wang",
                "https://github.com/sonichi"
            ],
            [
                "Qingyun Wu",
                "https://qingyun-wu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/microsoft/FLAML",
                2485
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.04815"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.01571"
            ],
            [
                "docs",
                "https://microsoft.github.io/FLAML/"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCfU0zfFXHXdAd5x-WvFBk5A"
            ],
            [
                "youtube",
                "https://youtu.be/euXpDYGgkGM"
            ],
            [
                "paper",
                "https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/FLAML/blob/master/notebook/flaml_automl.ipynb",
        "update": 1639699893.0
    },
    {
        "name": "TorchGeo",
        "description": "PyTorch domain library that provides datasets, transforms, samplers, and pre-trained models specific to geospatial data",
        "author": [
            [
                "Adam Stewart",
                "https://github.com/adamjstewart"
            ],
            [
                "Caleb Robinson",
                "https://calebrob.com/"
            ],
            [
                "Isaac Corley",
                "https://github.com/isaaccorley"
            ],
            [
                "Anthony Ortiz",
                "https://github.com/anthonymlortiz"
            ],
            [
                "Juan Lavista Ferres",
                "https://www.microsoft.com/en-us/research/people/jlavista/"
            ],
            [
                "Arindam Banerjee",
                "https://arindam.cs.illinois.edu/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/microsoft/torchgeo",
                1633
            ],
            [
                "git",
                "https://github.com/davemlz/awesome-spectral-indices"
            ],
            [
                "NDVI",
                "https://gisgeography.com/ndvi-normalized-difference-vegetation-index/"
            ],
            [
                "NDWI",
                "https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/ndwi/"
            ],
            [
                "NDBI",
                "https://www.linkedin.com/pulse/ndvi-ndbi-ndwi-calculation-using-landsat-7-8-tek-bahadur-kshetri/"
            ],
            [
                "data",
                "https://docs.sentinel-hub.com/api/latest/data/sentinel-2-l2a/"
            ],
            [
                "data",
                "https://www.cogeo.org/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.08872"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/torchgeo/blob/main/docs/tutorials/indices.ipynb",
        "update": 1680045971.0
    },
    {
        "name": "Imagededup",
        "description": "This package provides functionality to make use of hashing algorithms that are particularly good at finding exact duplicates as well as convolutional neural networks which are also adept at finding near duplicates",
        "author": [
            [
                "Tanuj Jain",
                "https://github.com/tanujjain"
            ],
            [
                "Christopher Lennan",
                "https://github.com/clennan"
            ],
            [
                "Dat Tran",
                "https://dat-tran.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://idealo.github.io/imagededup/"
            ],
            [
                "git",
                "https://github.com/idealo/imagededup",
                4546
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1704.04861"
            ],
            [
                "medium",
                "https://fullstackml.com/wavelet-image-hash-in-python-3504fdd282b5"
            ]
        ],
        "colab": "https://colab.research.google.com/github/idealo/imagededup/blob/master/examples/CIFAR10_duplicates.ipynb",
        "update": 1570109255.0
    },
    {
        "name": "MLP",
        "description": "The most basic neural network architectures, a multilayer perceptron, also known as a feedforward network",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Multilayer_perceptron"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1702.03118"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.12943"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.04020"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-only"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/transforms.html#transforms-on-torch-tensor-only"
            ],
            [
                "optimization",
                "https://ruder.io/optimizing-gradient-descent/"
            ],
            [
                "NN and DL",
                "http://neuralnetworksanddeeplearning.com/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb",
        "update": 1640516694.0
    },
    {
        "name": "LeNet",
        "description": "A neural network model that uses convolutional neural network layers and was designed for classifying handwritten characters",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "LeNet-5",
                "http://yann.lecun.com/exdb/lenet/"
            ],
            [
                "paper",
                "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Convolution"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Sobel_operator"
            ],
            [
                "guide",
                "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/"
            ],
            [
                "CNN",
                "https://cs231n.github.io/convolutional-networks/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Gaussian_blur"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/lenet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/2_lenet.ipynb",
        "update": 1640515550.0
    },
    {
        "name": "AlexNet",
        "description": "A neural network model that uses convolutional neural network layers and was designed for the ImageNet challenge",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html"
            ],
            [
                "ILSVRC",
                "https://image-net.org/challenges/LSVRC/"
            ],
            [
                "cifar-10",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Regularization_(mathematics)"
            ],
            [
                "dropout",
                "https://sebastianraschka.com/faq/docs/dropout-activation.html"
            ],
            [
                "PMLR",
                "https://proceedings.mlr.press/v9/glorot10a.html"
            ],
            [
                "git",
                "https://github.com/davidtvs/pytorch-lr-finder",
                819
            ],
            [
                "LR",
                "https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1409.0575"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/models.html"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/AlexNet"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/alexnet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/3_alexnet.ipynb",
        "update": 1640516694.0
    },
    {
        "name": "VGG",
        "description": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1409.1556"
            ],
            [
                "ILSVRC",
                "https://image-net.org/challenges/LSVRC/"
            ],
            [
                "cifar-10",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1506.01186"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.06146"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1502.03167"
            ],
            [
                "youtube",
                "https://youtu.be/HR0lt1hlR6U?t=5900"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1805.11604"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/models.html"
            ],
            [
                "git",
                "https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py#L47",
                14047
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/vgg"
            ],
            [
                "youtube",
                "https://youtu.be/j1jIoHN3m0s"
            ],
            [
                "youtube",
                "https://youtu.be/RNnKtNrsrmg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/4_vgg.ipynb",
        "update": 1640516694.0
    },
    {
        "name": "Semantic Segmentation",
        "description": "Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset",
        "author": [
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ],
            [
                "Hang Zhao",
                "https://hangzhaomit.github.io/"
            ],
            [
                "Xavier Puig",
                "https://people.csail.mit.edu/xavierpuig/"
            ],
            [
                "Sanja Fidler",
                "http://www.cs.toronto.edu/~fidler/index.html"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "project",
                "http://sceneparsing.csail.mit.edu/"
            ],
            [
                "git",
                "https://github.com/CSAILVision/semantic-segmentation-pytorch",
                4620
            ],
            [
                "git",
                "https://github.com/CSAILVision/sceneparsing"
            ],
            [
                "git",
                "https://github.com/vacancy/Synchronized-BatchNorm-PyTorch"
            ],
            [
                "git",
                "https://github.com/hszhao/semseg"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1608.05442"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1612.01105"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.10221"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.04514"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CSAILVision/semantic-segmentation-pytorch/blob/master/notebooks/DemoSegmenter.ipynb",
        "update": 1597992260.0
    },
    {
        "name": "Real-Time Voice Cloning",
        "description": "SV2TTS with a vocoder that works in real-time",
        "author": [
            [
                "Corentin Jemine",
                "https://github.com/CorentinJ"
            ],
            [
                "Erdene-Ochir Tuguldur",
                "https://github.com/tugstugi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/CorentinJ/Real-Time-Voice-Cloning",
                42095
            ],
            [
                "git",
                "https://github.com/fatchord/WaveRNN"
            ],
            [
                "git",
                "https://github.com/coqui-ai/tts"
            ],
            [
                "git",
                "https://github.com/resemble-ai/Resemblyzer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.04558"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.08435"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.10135"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10467"
            ],
            [
                "youtube",
                "https://youtu.be/-O_hYhToKoA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/RealTimeVoiceCloning.ipynb",
        "update": 1646690624.0
    },
    {
        "name": "NeMo",
        "description": "A conversational AI toolkit built for researchers working on automatic speech recognition, natural language processing, and text-to-speech synthesis",
        "author": [
            [
                "Oleksii Kuchaiev",
                "http://kuchaev.com/"
            ],
            [
                "Jason Li",
                "https://scholar.google.com/citations?user=V28bxDwAAAAJ"
            ],
            [
                "Chip Huyen",
                "https://huyenchip.com/"
            ],
            [
                "Oleksii Hrinchuk",
                "https://github.com/AlexGrinch"
            ],
            [
                "Ryan Leary",
                "https://github.com/ryanleary"
            ],
            [
                "Boris Ginsburg",
                "https://github.com/borisgin"
            ],
            [
                "Samuel Kriman",
                "https://github.com/sam1373"
            ],
            [
                "Stanislav Beliaev",
                "https://github.com/stasbel"
            ],
            [
                "Vitaly Lavrukhin",
                "https://github.com/vsl9"
            ],
            [
                "Jack Cook",
                "https://jackcook.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://docs.nvidia.com/deeplearning/nemo/"
            ],
            [
                "youtube",
                "https://youtu.be/wBgpMf_KQVw"
            ],
            [
                "git",
                "https://github.com/NVIDIA/NeMo",
                6824
            ]
        ],
        "colab": "https://colab.research.google.com/github/NVIDIA/NeMo/blob/master/tutorials/00_NeMo_Primer.ipynb",
        "update": 1672955472.0
    },
    {
        "name": "DeepStyle",
        "description": "The Neural Style algorithm synthesizes a pastiche by separating and combining the content of one image with the style of another image using convolutional neural networks",
        "author": [
            [
                "Cameron Smith",
                "https://github.com/cysmith"
            ],
            [
                "Alexander Spirin",
                "https://github.com/Sxela"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/cysmith/neural-style-tf",
                3072
            ],
            [
                "cvpr",
                "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1604.08610"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.05897"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pastiche"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/The_Starry_Night"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/YUV"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Lab_color_space"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/YCbCr"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/CIELUV"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pareidolia"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/14aJ7HQPbcP0sNRIY-FRO4u6lxtlyyxI_",
        "update": 1633120599.161
    },
    {
        "name": "Silero Models",
        "description": "Pre-trained speech-to-text, text-to-speech and text-enhancement models made embarrassingly simple",
        "author": [
            [
                "Silero team",
                "https://www.silero.ai/about/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/snakers4/silero-models",
                3695
            ],
            [
                "website",
                "https://www.silero.ai/"
            ],
            [
                "STT",
                "https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/"
            ],
            [
                "STT",
                "https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/"
            ],
            [
                "STT",
                "https://habr.com/ru/post/519562/"
            ],
            [
                "TTS",
                "https://habr.com/ru/post/660571/"
            ],
            [
                "TTS",
                "https://habr.com/ru/post/549482/"
            ],
            [
                "VAD",
                "https://thegradient.pub/one-voice-detector-to-rule-them-all/"
            ],
            [
                "VAD",
                "https://habr.com/ru/post/537276/"
            ],
            [
                "Text Enhancement",
                "https://habr.com/ru/post/581960/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/snakers4/silero-models/blob/master/examples.ipynb",
        "update": 1645986042.0
    },
    {
        "name": "Cirq",
        "description": "A python framework for creating, editing, and invoking Noisy Intermediate Scale Quantum circuits",
        "author": [
            [
                "Balint Pato",
                "https://refactorium.com/"
            ],
            [
                "Matthew Harrigan",
                "https://mpharrigan.com/"
            ],
            [
                "Animesh Sinha",
                "https://github.com/AnimeshSinha1309"
            ],
            [
                "Matthew Neeley",
                "https://github.com/maffoo"
            ],
            [
                "Dave Bacon",
                "https://dabacon.org/"
            ],
            [
                "Matteo Pompili",
                "https://github.com/matpompili"
            ],
            [
                "Michael Broughton",
                "https://github.com/MichaelBroughton"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/quantumlib/Cirq",
                3784
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Quantum_logic_gate#Hadamard_gate"
            ],
            [
                "youtube",
                "https://youtu.be/16ZfkPRVf2w"
            ]
        ],
        "colab": "https://colab.research.google.com/github/quantumlib/Cirq/blob/master/docs/tutorials/basics.ipynb",
        "update": 1655840319.0
    },
    {
        "name": "Hello, many worlds",
        "description": "This tutorial shows how a classical neural network can learn to correct qubit calibration errors",
        "author": [
            [
                "Michael Broughton",
                "https://github.com/MichaelBroughton"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/quantum/api_docs/python/tfq/layers"
            ],
            [
                "tf",
                "https://www.tensorflow.org/quantum/api_docs/python/tfq/get_expectation_op"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/keras/functional"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pauli_matrices"
            ],
            [
                "youtube",
                "https://youtu.be/-o9AhIz1uvo"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/hello_many_worlds.ipynb",
        "update": 1679338820.0
    },
    {
        "name": "dm_control",
        "description": "DeepMind Infrastructure for Physics-Based Simulation",
        "author": [
            [
                "Saran Tunyasuvunakool",
                "https://github.com/saran-t"
            ],
            [
                "Alistair Muldal",
                "https://github.com/alimuldal"
            ],
            [
                "Yotam Doron",
                "http://www.yotamdoron.com/"
            ],
            [
                "Siqi Liu",
                "http://siqi.fr/"
            ],
            [
                "Steven Bohez",
                "https://github.com/sbohez"
            ],
            [
                "Josh Merel",
                "https://sites.google.com/site/jsmerel/"
            ],
            [
                "Tom Erez",
                "https://github.com/erez-tom"
            ],
            [
                "Timothy Lillicrap",
                "https://contrastiveconvergence.net/~timothylillicrap/index.php"
            ],
            [
                "Nicolas Heess",
                "https://scholar.google.com/citations?user=79k7bGEAAAAJ"
            ],
            [
                "Yuval Tassa",
                "https://github.com/yuvaltassa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/dm_control",
                3190
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.12983"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Tippe_top"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.00690"
            ],
            [
                "youtube",
                "https://youtu.be/CMjoiU482Jk"
            ],
            [
                "youtube",
                "https://youtu.be/rAai4QzcYbs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.07151"
            ],
            [
                "blog post",
                "https://www.deepmind.com/publications/dm-control-software-and-tasks-for-continuous-control"
            ],
            [
                "youtube",
                "https://youtu.be/WhaRsrlaXLk"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02286"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.09564"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.10567"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb",
        "update": 1682003087.0
    },
    {
        "name": "MuJoCo",
        "description": "A general purpose physics engine that aims to facilitate research and development in robotics, biomechanics, graphics and animation, machine learning, and other areas which demand fast and accurate simulation of articulated structures interacting with their environment",
        "author": [
            [
                "Emo Todorov",
                "https://homes.cs.washington.edu/~todorov/"
            ],
            [
                "Tom Erez",
                "https://github.com/erez-tom"
            ],
            [
                "Yuval Tassa",
                "https://github.com/yuvaltassa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/mujoco",
                5810
            ],
            [
                "docs",
                "https://mujoco.readthedocs.io/en/latest/overview.html"
            ],
            [
                "website",
                "https://mujoco.org/"
            ],
            [
                "blog post",
                "https://www.deepmind.com/blog/opening-up-a-physics-simulator-for-robotics"
            ],
            [
                "blog post",
                "https://www.deepmind.com/blog/open-sourcing-mujoco"
            ],
            [
                "youtube",
                "https://youtu.be/0ORsj_E17B0"
            ],
            [
                "youtube",
                "https://youtu.be/yHZVVfsJ8mc"
            ],
            [
                "youtube",
                "https://youtu.be/eyzzsGJ1iic"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Tippe_top"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Chaos_theory"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/3D_projection#Mathematical_formula"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.12983"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm_control/blob/master/dm_control/mujoco/tutorial.ipynb",
        "update": 1682003087.0
    },
    {
        "name": "Haiku",
        "description": "A library built on top of JAX designed to provide simple, composable abstractions for machine learning research",
        "author": [
            [
                "Tom Hennigan",
                "https://github.com/tomhennigan"
            ],
            [
                "Trevor Cai",
                "https://github.com/trevorcai"
            ],
            [
                "Tamara Norman",
                "https://github.com/tamaranorman"
            ],
            [
                "Igor Babuschkin",
                "https://www.babushk.in/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/dm-haiku",
                2495
            ],
            [
                "docs",
                "https://dm-haiku.readthedocs.io/en/latest/"
            ],
            [
                "website",
                "https://www.haiku-os.org/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm-haiku/blob/main/examples/haiku_lstms.ipynb",
        "update": 1677759335.0
    },
    {
        "name": "Epistemic Neural Networks",
        "description": "A library for neural networks that know what they don't know",
        "author": [
            [
                "Ian Osband",
                "http://iosband.github.io/"
            ],
            [
                "Zheng Wen",
                "http://zheng-wen.com/"
            ],
            [
                "Seyed Mohammad Asghari",
                "https://github.com/mohammadasghari"
            ],
            [
                "Vikranth Dwaracherla",
                "https://github.com/dvikranth"
            ],
            [
                "Morteza Ibrahimi",
                "https://github.com/mibrahimi"
            ],
            [
                "Xiuyuan Lu",
                "https://scholar.google.com/citations?user=SPL_2lIAAAAJ"
            ],
            [
                "Benjamin Van Roy",
                "https://web.stanford.edu/~bvr/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2107.08924"
            ],
            [
                "git",
                "https://github.com/deepmind/enn",
                227
            ],
            [
                "youtube",
                "https://youtu.be/j8an0dKcX4A"
            ],
            [
                "medium",
                "https://medium.com/syncedreview/deepminds-epistemic-neural-networks-open-new-avenues-for-uncertainty-modelling-in-large-and-fa83ab00aba3"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/enn/blob/master/enn/colabs/enn_demo.ipynb",
        "update": 1657652575.0
    },
    {
        "name": "ACME",
        "description": "A library of reinforcement learning components and agents",
        "author": [
            [
                "Matt Hoffman",
                "https://www.mwhoffman.com/"
            ],
            [
                "Bobak Shahriari",
                "https://github.com/bshahr"
            ],
            [
                "John Aslanides",
                "https://www.aslanides.io/"
            ],
            [
                "Gabriel Barth-Maron",
                "https://github.com/fastturtle"
            ],
            [
                "Feryal Behbahani",
                "https://feryal.github.io/"
            ],
            [
                "Tamara Norman",
                "https://github.com/tamaranorman"
            ],
            [
                "Abbas Abdolmaleki",
                "https://scholar.google.com/citations?user=cCYTVWQAAAAJ"
            ],
            [
                "Albin Cassirer",
                "https://github.com/acassirer"
            ],
            [
                "Fan Yang",
                "https://github.com/ddmbr"
            ],
            [
                "Kate Baumli",
                "https://github.com/katebaumli"
            ],
            [
                "Sarah Henderson",
                "https://www.linkedin.com/in/sarah-henderson-agilecoach/"
            ],
            [
                "Alex Novikov",
                "https://scholar.google.ru/citations?user=jMUkLqwAAAAJ"
            ],
            [
                "Sergio G√≥mez Colmenarejo",
                "https://scholar.google.ru/citations?user=0Dkf68EAAAAJ"
            ],
            [
                "Serkan Cabi",
                "https://scholar.google.ru/citations?&user=l-HhJaUAAAAJ"
            ],
            [
                "Caglar Gulcehre",
                "https://www.caglarg.com/"
            ],
            [
                "Tom Le Paine",
                "http://tomlepaine.github.io/"
            ],
            [
                "Andrew Cowie",
                "https://scholar.google.ru/citations?&user=aTvi5mUAAAAJ"
            ],
            [
                "Ziyu Wang",
                "https://ziyuw.github.io/"
            ],
            [
                "Bilal Piot",
                "https://scholar.google.ru/citations?&user=fqxNUREAAAAJ"
            ],
            [
                "Nando de Freitas",
                "https://github.com/nandodf"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/acme",
                3109
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.00979"
            ],
            [
                "docs",
                "https://dm-acme.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/deepmind/dm_env"
            ],
            [
                "youtube",
                "https://youtu.be/NUwDr42bPOw"
            ],
            [
                "youtube",
                "https://youtu.be/J1XCWjuyRaI"
            ],
            [
                "youtube",
                "https://youtu.be/pFMuQWpHI5k"
            ],
            [
                "blog post",
                "https://www.deepmind.com/publications/acme-a-new-framework-for-distributed-reinforcement-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/acme/blob/master/examples/tutorial.ipynb",
        "update": 1664184977.0
    },
    {
        "name": "Sonnet",
        "description": "Library built on top of TensorFlow 2 designed to provide simple, composable abstractions for machine learning research",
        "author": [
            [
                "Malcolm Reynolds",
                "https://github.com/malcolmreynolds"
            ],
            [
                "Jack Rae",
                ""
            ],
            [
                "Andreas Fidjeland",
                "https://github.com/akfidjeland"
            ],
            [
                "Fabio Viola",
                "https://github.com/fabioviola"
            ],
            [
                "Adri√† Puigdom√®nech",
                "https://github.com/adria-p"
            ],
            [
                "Frederic Besse",
                "https://github.com/fbesse"
            ],
            [
                "Tim Green",
                "http://tfgg.me/"
            ],
            [
                "S√©bastien Racani√®re",
                "https://scholar.google.com/citations?user=o-h0vrQAAAAJ"
            ],
            [
                "Gabriel Barth-Maron",
                "https://github.com/fastturtle"
            ],
            [
                "Diego de Las Casas",
                "https://github.com/diegolascasas"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/sonnet",
                9570
            ],
            [
                "docs",
                "https://sonnet.readthedocs.io/en/latest/index.html"
            ],
            [
                "blog post",
                "https://www.deepmind.com/blog/open-sourcing-sonnet-a-new-library-for-constructing-neural-networks"
            ],
            [
                "youtube",
                "https://youtu.be/rlpQjnUvoKw"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/checkpoint"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/saved_model"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2016/hash/fb87582825f9d28a8d42c5e5e5e8b23d-Abstract.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/sonnet/blob/v2/examples/little_gan_on_mnist.ipynb",
        "update": 1587104381.0
    },
    {
        "name": "bsuite",
        "description": "A collection of carefully-designed experiments that investigate core capabilities of an RL agent with two main objectives",
        "author": [
            [
                "Ian Osband",
                "http://iosband.github.io/"
            ],
            [
                "Yotam Doron",
                "http://www.yotamdoron.com/"
            ],
            [
                "Matteo Hessel",
                "https://github.com/mtthss"
            ],
            [
                "John Aslanides",
                "https://www.aslanides.io/"
            ],
            [
                "Eren Sezener",
                "http://erensezener.com/"
            ],
            [
                "Andre Saraiva",
                "https://andresnds.wordpress.com/"
            ],
            [
                "Katrina McKinney",
                "https://medium.com/@katrinamckinney"
            ],
            [
                "Tor Lattimore",
                "http://tor-lattimore.com/"
            ],
            [
                "Csaba Szepesvari",
                "https://sites.ualberta.ca/~szepesva/"
            ],
            [
                "Satinder Singh",
                "http://web.eecs.umich.edu/~baveja/"
            ],
            [
                "Benjamin Van Roy",
                "https://web.stanford.edu/~bvr/"
            ],
            [
                "Richard Sutton",
                "http://www.incompleteideas.net/"
            ],
            [
                "David Silver",
                "https://www.davidsilver.uk/"
            ],
            [
                "Hado Van Hasselt",
                "https://hadovanhasselt.com/"
            ]
        ],
        "links": [
            [
                "paper",
                "https://openreview.net/forum?id=rygf-kSYwH"
            ],
            [
                "git",
                "https://github.com/deepmind/bsuite",
                1394
            ],
            [
                "git",
                "https://github.com/openai/gym"
            ],
            [
                "youtube",
                "https://youtu.be/Wcv4eU_qtZU"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1rU20zJ281sZuMD1DHbsODFr1DbASL0RH",
        "update": 1613174366.054
    },
    {
        "name": "PGMax",
        "description": "General factor graphs for discrete probabilistic graphical models, and hardware-accelerated differentiable loopy belief propagation in JAX",
        "author": [
            [
                "Guangyao Zhou",
                "https://stanniszhou.github.io/"
            ],
            [
                "Nishanth Kumar",
                "http://nishanthjkumar.com/"
            ],
            [
                "Antoine Dedieu",
                "https://github.com/antoine-dedieu"
            ],
            [
                "Miguel L√°zaro-Gredilla",
                "https://www.tsc.uc3m.es/~miguel/"
            ],
            [
                "Shrinu Kushagra",
                "https://cs.uwaterloo.ca/~skushagr/"
            ],
            [
                "Dileep George",
                "https://dileeplearning.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/PGMax",
                64
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.04110"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Belief_propagation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/PGMax/blob/main/examples/rcn.ipynb",
        "update": 1683297510.0
    },
    {
        "name": "Accelerate",
        "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision",
        "author": [
            [
                "Hugging Face",
                "https://huggingface.co/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://huggingface.co/docs/accelerate/index"
            ],
            [
                "git",
                "https://github.com/huggingface/accelerate",
                4659
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/accelerate/simple_nlp_example.ipynb",
        "update": 1658916297.0
    },
    {
        "name": "Diffusers",
        "description": "Provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models",
        "author": [
            [
                "Hugging Face",
                "https://huggingface.co/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/diffusers",
                15126
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11239"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11239"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.02502"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.13902"
            ],
            [
                "git",
                "https://github.com/hojonathanho/diffusion"
            ],
            [
                "git",
                "https://github.com/pesser/pytorch_diffusion"
            ],
            [
                "git",
                "https://github.com/ermongroup/ddim"
            ],
            [
                "git",
                "https://github.com/heejkoo/Awesome-Diffusion-Models"
            ],
            [
                "youtube",
                "https://youtu.be/UzkdOg7wWmI"
            ],
            [
                "medium",
                "https://towardsdatascience.com/hugging-face-just-released-the-diffusers-library-846f32845e65"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/CompVis/celeba-latent-diffusion"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/fusing/celeba-diffusion"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/huggingface/diffuse-the-rest"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Shuang59/Composable-Diffusion"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb",
        "update": 1673945811.0
    },
    {
        "name": "Deep RL Course",
        "description": "The Hugging Face Deep Reinforcement Learning Course",
        "author": [
            [
                "Thomas Simonini",
                "https://www.simoninithomas.com/"
            ],
            [
                "Omar Sanseviero",
                "https://osanseviero.github.io/hackerllama/"
            ],
            [
                "Sayak Paul",
                "https://sayak.dev/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/deep-rl-class",
                2973
            ],
            [
                "huggingface",
                "https://huggingface.co/deep-rl-course/unit0/introduction"
            ],
            [
                "syllabus",
                "https://simoninithomas.github.io/deep-rl-course"
            ],
            [
                "git",
                "https://github.com/alex-petrenko/sample-factory"
            ],
            [
                "pt",
                "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
            ],
            [
                "youtube",
                "https://youtu.be/2GwBez0D20A"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
            ],
            [
                "youtube",
                "https://youtu.be/CsuIANBnSq8"
            ],
            [
                "youtube",
                "https://youtu.be/AQKAOXJa6qg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit1/unit1.ipynb",
        "update": 1684232264.0
    },
    {
        "name": "Evidently",
        "description": "An open-source framework to evaluate, test and monitor ML models in production",
        "author": [
            [
                "Elena Samuylova",
                "https://github.com/elenasamuylova"
            ],
            [
                "Emeli Dral",
                "https://github.com/emeli-dral"
            ],
            [
                "Olga Filippova",
                "https://github.com/0lgaF"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/evidentlyai/evidently",
                3467
            ],
            [
                "docs",
                "https://docs.evidentlyai.com/"
            ],
            [
                "website",
                "https://evidentlyai.com/"
            ],
            [
                "git",
                "https://github.com/0lgaF/my_tab_with_evidently"
            ],
            [
                "youtube",
                "https://www.youtube.com/c/EvidentlyAI"
            ],
            [
                "youtube",
                "https://youtu.be/L4Pv6ExBQPM"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Dd6ZzIgeBYkD_4bqWZ0RAdUpCU0b6Y6H",
        "update": 1653945417.396
    },
    {
        "name": "NL-Augmenter",
        "description": "A collaborative effort intended to add transformations of datasets dealing with natural language",
        "author": [
            [
                "Aadesh Gupta",
                "https://github.com/aadesh11"
            ],
            [
                "Timothy Sum Hon Mun",
                "https://github.com/timothy22000"
            ],
            [
                "Aditya Srivatsa",
                "https://github.com/kvadityasrivatsa"
            ],
            [
                "Xudong Shen",
                "https://github.com/XudongOliverShen"
            ],
            [
                "Juan Diego Rodriguez",
                "https://github.com/juand-r"
            ],
            [
                "Ashish Shrivastava",
                "https://github.com/ashish3586"
            ],
            [
                "Nagender Aneja",
                "https://researchid.co/naneja"
            ],
            [
                "Zijie Wang",
                "https://zijie.wang/"
            ],
            [
                "Yiwen Shi",
                "https://github.com/Yiwen-Shi"
            ],
            [
                "Afnan Mir",
                "https://github.com/afnanmmir"
            ],
            [
                "William Soto",
                "https://github.com/sotwi"
            ],
            [
                "Chandan Singh",
                "https://csinva.io/"
            ],
            [
                "Claude Roux",
                "https://github.com/ClaudeRoux"
            ],
            [
                "Abinaya Mahendiran",
                "https://github.com/AbinayaM02"
            ],
            [
                "Anna Shvets",
                "https://github.com/asnota"
            ],
            [
                "Kaustubh Dhole",
                "https://github.com/kaustubhdhole"
            ],
            [
                "Bryan Wilie",
                "https://github.com/bryanwilie"
            ],
            [
                "Jamie Simon",
                "https://james-simon.github.io/"
            ],
            [
                "Mukund Varma",
                "https://github.com/MukundVarmaT"
            ],
            [
                "Sang Han",
                "https://github.com/jjangsangy"
            ],
            [
                "Denis Kleyko",
                "https://github.com/denkle"
            ],
            [
                "Samuel Cahyawijaya",
                "https://github.com/SamuelCahyawijaya"
            ],
            [
                "Filip Cornell",
                "https://github.com/Filco306"
            ],
            [
                "Tanay Dixit",
                "https://tanay2001.github.io/"
            ],
            [
                "Connor Boyle",
                "https://github.com/boyleconnor"
            ],
            [
                "Genta Indra Winata",
                "https://gentawinata.com/"
            ],
            [
                "Seungjae Ryan Lee",
                "https://github.com/seungjaeryanlee"
            ],
            [
                "Marcin Namysl",
                "https://github.com/mnamysl"
            ],
            [
                "Roman Sitelew",
                "https://github.com/RomanPlusPlus"
            ],
            [
                "Zhenhao Li",
                "https://zhenhaoli.net/"
            ],
            [
                "Fiona Tan",
                "https://tanfiona.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2112.02721"
            ],
            [
                "website",
                "https://gem-benchmark.com/nl_augmenter"
            ],
            [
                "git",
                "https://github.com/GEM-benchmark/NL-Augmenter",
                723
            ]
        ],
        "colab": "https://colab.research.google.com/github/GEM-benchmark/NL-Augmenter/blob/main/notebooks/Write_a_sample_transformation.ipynb",
        "update": 1659770490.0
    },
    {
        "name": "Person Remover",
        "description": "Project that combines Pix2Pix and YOLO arhitectures in order to remove people or other objects from photos",
        "author": [
            [
                "Javier Gamazo",
                "https://www.javiergamazo.com/"
            ],
            [
                "Daryl Autar",
                "https://github.com/Daryl149"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/javirk/Person_remover",
                135
            ],
            [
                "git",
                "https://github.com/javirk/Person-remover-partial-convolutions"
            ],
            [
                "git",
                "https://github.com/zzh8829/yolov3-tf2"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_dRjY9gMcxE"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JDpH8MAjaKoekQ_H9ZaxYJ9_axiDtDGm",
        "update": 1598098239.644
    },
    {
        "name": "Background Matting",
        "description": "The notebook is split into three parts: required setup, running the algorithm on photos, and running it on videos",
        "author": [
            [
                "Andrey Ryabtsev",
                "https://github.com/andreyryabtsev"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.00626"
            ],
            [
                "blog post",
                "https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635"
            ],
            [
                "git",
                "https://github.com/senguptaumd/Background-Matting",
                4679
            ],
            [
                "data",
                "https://drive.google.com/open?id=1j3BMrRFhFpfzJAe6P2WDtfanoeSCLPiq"
            ]
        ],
        "colab": "https://colab.research.google.com/gist/andreyryabtsev/243aa3eefa6e06891dda7b1583d1d08f/backmatting.ipynb",
        "update": 1589810335.0
    },
    {
        "name": "Earth Engine Python API and Folium Interactive Mapping",
        "description": "This notebook demonstrates how to setup the Earth Engine and provides several examples for visualizing Earth Engine processed data interactively using the folium library",
        "author": [
            [
                "Qiusheng Wu",
                "https://wetlands.io/"
            ]
        ],
        "links": [
            [
                "api",
                "https://developers.google.com/earth-engine/python_install"
            ],
            [
                "git",
                "https://github.com/python-visualization/folium",
                6261
            ]
        ],
        "colab": "https://colab.research.google.com/github/giswqs/qgis-earthengine-examples/blob/master/Folium/ee-api-folium-setup.ipynb",
        "update": 1579530171.0
    },
    {
        "name": "Traffic counting",
        "description": "Making Road Traffic Counting App based on Computer Vision and OpenCV",
        "author": [
            [
                "Andrey Nikishaev",
                "https://github.com/creotiv"
            ]
        ],
        "links": [
            [
                "medium",
                "https://medium.com/machine-learning-world/tutorial-making-road-traffic-counting-app-based-on-computer-vision-and-opencv-166937911660"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_o5iLbRHKao"
            ],
            [
                "git",
                "https://github.com/creotiv/object_detection_projects/tree/master/opencv_traffic_counting",
                341
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12N4m_RYKqrpozRzh9qe7nQE_sIqQH9U8",
        "update": 1578663579.317
    },
    {
        "name": "HoF",
        "description": "This notebook will walk you step by step through the process of using a pre-trained model to detect faces in an image",
        "author": [
            [
                "Lucas Persona",
                "http://www.lucaspersona.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/the-house-of-black-and-white/hall-of-faces",
                35
            ],
            [
                "data",
                "http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/"
            ],
            [
                "yolo",
                "https://pjreddie.com/darknet/yolo/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/the-house-of-black-and-white/hall-of-faces/blob/master/notebooks/Hall_of_Faces.ipynb",
        "update": 1521077715.0
    },
    {
        "name": "HuggingArtists",
        "description": "Choose your favorite Artist and train a language model to write new lyrics based on their unique voice",
        "author": [
            [
                "Aleksey Korshuk",
                "https://github.com/AlekseyKorshuk"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/AlekseyKorshuk/huggingartists",
                79
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/AlekseyKorshuk/huggingartists"
            ],
            [
                "huggingface",
                "https://huggingface.co/huggingartists"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb",
        "update": 1656161658.0
    },
    {
        "name": "CLIPDraw",
        "description": "Synthesize drawings to match a text prompt",
        "author": [
            [
                "Kevin Frans",
                "https://www.kvfrans.com/"
            ],
            [
                "Lisa Soros",
                "https://scholar.google.com/citations?user=iUkpvMUAAAAJ"
            ],
            [
                "Olaf Witkowski",
                "https://olafwitkowski.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.00162"
            ],
            [
                "blog post",
                "https://kvfrans.com/clipdraw-exploring-text-to-drawing-synthesis/"
            ],
            [
                "git",
                "https://github.com/kvfrans/clipdraw",
                107
            ],
            [
                "git",
                "https://github.com/BachiLi/diffvg/blob/master/apps/painterly_rendering.py"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kvfrans/clipdraw/blob/main/clipdraw.ipynb",
        "update": 1651178199.0
    },
    {
        "name": "OpenCLIP",
        "description": "An open source implementation of CLIP",
        "author": [
            [
                "Ross Wightman",
                "https://rwightman.com/"
            ],
            [
                "Cade Gordon",
                "https://cadegordon.io/"
            ],
            [
                "Vaishaal Shankar",
                "http://vaishaal.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mlfoundations/open_clip",
                5047
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.01903"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "data",
                "https://ai.google.com/research/ConceptualCaptions/download"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.02114"
            ],
            [
                "data",
                "https://laion.ai/blog/laion-5b/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.04649"
            ],
            [
                "git",
                "https://github.com/mlfoundations/wise-ft"
            ],
            [
                "git",
                "https://github.com/webdataset/webdataset"
            ],
            [
                "git",
                "https://github.com/webdataset/tarp"
            ],
            [
                "data",
                "https://laion.ai/blog/laion-400-open-dataset/"
            ],
            [
                "huggingface",
                "https://huggingface.co/datasets/laion/laion2B-en"
            ],
            [
                "huggingface",
                "https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
            ],
            [
                "huggingface",
                "https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K"
            ],
            [
                "huggingface",
                "https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K"
            ],
            [
                "huggingface",
                "https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K"
            ],
            [
                "git",
                "https://github.com/google-research-datasets/conceptual-12m"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.10811"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.04649"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mlfoundations/open_clip/blob/master/docs/Interacting_with_open_clip.ipynb",
        "update": 1681657982.0
    },
    {
        "name": "ArcaneGAN",
        "description": "Process video in the style of the Arcane animated series",
        "author": [
            [
                "Alexander Spirin",
                "https://github.com/Sxela"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Sxela/ArcaneGAN",
                634
            ],
            [
                "git",
                "https://github.com/Sxela/stylegan3_blending"
            ],
            [
                "youtube",
                "https://youtu.be/Fi199uFW6jE"
            ],
            [
                "youtube",
                "https://youtu.be/AJG4X7IokG8"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1r1hhciakk5wHaUn1eJk7TP58fV9mjy_W",
        "update": 1645095391.826
    },
    {
        "name": "Text2Animation",
        "description": "Generate images from text phrases with VQGAN and CLIP with animation and keyframes",
        "author": [
            [
                "Katherine Crowson",
                "https://kath.io/"
            ],
            [
                "Ryan Murdock",
                "https://twitter.com/advadnoun"
            ],
            [
                "Chigozie Nri",
                "https://github.com/chigozienri"
            ],
            [
                "Denis Malimonov",
                "https://github.com/tg-bomze"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/chigozienri/VQGAN-CLIP-animations",
                123
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCToztRy9FSTIhEen_1x4FAw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Animation.ipynb",
        "update": 1632912192.0
    },
    {
        "name": "Toon-Me",
        "description": "A fun project to toon portrait images",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/Toon-Me",
                393
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Try_it_on_Colab).ipynb",
        "update": 1611307474.0
    },
    {
        "name": "MindsEye",
        "description": "Graphical user interface built to run multimodal ai art models for free from a Google Colab, without needing edit a single line of code or know any programming",
        "author": [
            [
                "multimodal.art",
                "https://multimodal.art/"
            ],
            [
                "Jo√£o Paulo Apolin√°rio Passos",
                "http://www.apolinariopassos.com.br/portfolio/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/multimodalart/mindseye",
                78
            ],
            [
                "project",
                "https://multimodal.art/mindseye"
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1cg0LZ5OfN9LAIB37Xq49as0fSJxcKtC5",
        "update": 1657101595.331
    },
    {
        "name": "DALL¬∑E Flow",
        "description": "An interactive workflow for generating high-definition images from text prompt",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ],
            [
                "Delgermurun Purevkhuu",
                "https://delgermurun.com/"
            ],
            [
                "Alex Cureton-Griffiths",
                "http://blog.alexcg.net/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jina-ai/dalle-flow",
                2786
            ],
            [
                "git",
                "https://github.com/Jack000/glid-3-xl"
            ],
            [
                "git",
                "https://github.com/jina-ai/docarray"
            ],
            [
                "huggingface",
                "https://huggingface.co/CompVis/stable-diffusion-v-1-4-original"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "youtube",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/dalle-flow/blob/main/client.ipynb",
        "update": 1674720733.0
    },
    {
        "name": "CLIP-as-service",
        "description": "A low-latency high-scalability service for embedding images and text",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ]
        ],
        "links": [
            [
                "website",
                "https://clip-as-service.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/clip-as-service",
                11631
            ],
            [
                "git",
                "https://github.com/jina-ai/docarray"
            ],
            [
                "data",
                "https://sites.google.com/view/totally-looks-like-dataset"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "youtube",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/clip-as-service/blob/main/docs/hosting/cas-on-colab.ipynb",
        "update": 1655667769.0
    },
    {
        "name": "Jina",
        "description": "MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://docs.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/jina",
                18453
            ],
            [
                "hub",
                "https://hub.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/example-grafana-prometheus/blob/main/grafana-dashboards/flow.json"
            ],
            [
                "data",
                "https://sites.google.com/view/totally-looks-like-dataset"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "youtube",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/jina/blob/master/docs/Using_Jina_on_Colab.ipynb",
        "update": 1654974020.0
    },
    {
        "name": "Stable Diffusion",
        "description": "A latent text-to-image diffusion model",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Andreas Blattmann",
                "https://github.com/ablattmann"
            ],
            [
                "Dominik Lorenz",
                "https://github.com/qp-qp"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Bj√∂rn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/CompVis/stable-diffusion",
                55067
            ],
            [
                "git",
                "https://arxiv.org/abs/2112.10752"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2205.11487"
            ],
            [
                "huggingface",
                "https://huggingface.co/CompVis"
            ],
            [
                "huggingface",
                "https://huggingface.co/datasets/laion/laion2B-en"
            ],
            [
                "huggingface",
                "https://huggingface.co/datasets/laion/laion-high-resolution"
            ],
            [
                "git",
                "https://github.com/christophschuhmann/improved-aesthetic-predictor"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2207.12598"
            ],
            [
                "git",
                "https://github.com/ShieldMnt/invisible-watermark"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.01073"
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ],
            [
                "git",
                "https://github.com/lucidrains/denoising-diffusion-pytorch"
            ],
            [
                "git",
                "https://github.com/lucidrains/x-transformers"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CompVis/stable-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb",
        "update": 1660134649.0
    },
    {
        "name": "Stable Diffusion 2",
        "description": "New stable diffusion model at 768x768 resolution. Same number of parameters in the U-Net as 1.5, but uses OpenCLIP-ViT/H as the text encoder and is trained from scratch",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Andreas Blattmann",
                "https://github.com/ablattmann"
            ],
            [
                "Dominik Lorenz",
                "https://github.com/qp-qp"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Bj√∂rn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ],
            [
                "qunash",
                "https://github.com/qunash"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Stability-AI/stablediffusion",
                23670
            ],
            [
                "git",
                "https://github.com/qunash/stable-diffusion-2-gui"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10752"
            ],
            [
                "huggingface",
                "https://huggingface.co/stabilityai/stable-diffusion-2-1"
            ],
            [
                "huggingface",
                "https://huggingface.co/stabilityai/stable-diffusion-2-1-base"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.00512"
            ],
            [
                "git",
                "https://github.com/isl-org/MiDaS"
            ],
            [
                "youtube",
                "https://youtu.be/HytucGhwTRs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.02502"
            ],
            [
                "huggingface",
                "https://huggingface.co/stabilityai/stable-diffusion-2-depth"
            ],
            [
                "huggingface",
                "https://huggingface.co/stabilityai/stable-diffusion-2-inpainting"
            ],
            [
                "git",
                "https://github.com/lucidrains/denoising-diffusion-pytorch"
            ],
            [
                "git",
                "https://github.com/runwayml/stable-diffusion/blob/main/scripts/inpaint_st.py"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.01073"
            ],
            [
                "git",
                "https://github.com/crowsonkb/k-diffusion"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2206.00927"
            ]
        ],
        "colab": "https://colab.research.google.com/github/qunash/stable-diffusion-2-gui/blob/main/stable_diffusion_2_0.ipynb",
        "update": 1685129345.0
    },
    {
        "name": "Stable Diffusion Videos",
        "description": "Create videos with Stable Diffusion by exploring the latent space and morphing between text prompts",
        "author": [
            [
                "Nathan Raw",
                "https://github.com/nateraw"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nateraw/stable-diffusion-videos",
                2799
            ],
            [
                "git",
                "https://gist.github.com/karpathy/00103b0037c5aaea32fe1da1af553355"
            ],
            [
                "git",
                "https://gist.github.com/nateraw/c989468b74c616ebbc6474aa8cdd9e53"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb",
        "update": 1670276339.0
    },
    {
        "name": "Deforum Stable Diffusion",
        "description": "Open source project is designed to be free to use and easy to modify for custom needs and pipelines",
        "author": [
            [
                "EnzymeZoo",
                "https://linktr.ee/enzymezoo"
            ],
            [
                "–ê—Ä—Ç–µ–º –•—Ä–∞–ø–æ–≤",
                "https://github.com/kabachuha"
            ],
            [
                "Forest Star Walz",
                "https://github.com/reallybigname"
            ],
            [
                "pharmapsychotic",
                "https://github.com/pharmapsychotic"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deforum-art/deforum-stable-diffusion",
                1293
            ],
            [
                "project",
                "https://deforum.github.io/"
            ],
            [
                "docs",
                "https://docs.google.com/document/d/1RrQv7FntzOuLg4ohjRZPVL7iptIyBhwwbcEYEW2OfcI"
            ],
            [
                "discord",
                "https://discord.gg/deforum"
            ],
            [
                "youtube",
                "https://youtu.be/w_sxuDMt_V0"
            ],
            [
                "youtube",
                "https://youtu.be/bicPayZDI60"
            ],
            [
                "youtube",
                "https://youtu.be/dqkQo2alZvU"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deforum-art/deforum-stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb",
        "update": 1684436536.0
    },
    {
        "name": "Tortoise",
        "description": "A multi-voice TTS system trained with an emphasis on quality",
        "author": [
            [
                "James Betker",
                "https://nonint.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/neonbjb/tortoise-tts",
                6987
            ],
            [
                "examples",
                "https://nonint.com/static/tortoise_v2_examples.html"
            ],
            [
                "git",
                "https://github.com/neonbjb/DL-Art-School"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.12092"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.09672"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.07889"
            ],
            [
                "huggingface",
                "https://huggingface.co/patrickvonplaten"
            ],
            [
                "youtube",
                "https://youtu.be/J3-jfS29RF4"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/osanseviero/tortoisse-tts"
            ]
        ],
        "colab": "https://colab.research.google.com/github/neonbjb/tortoise-tts/blob/main/tortoise_tts.ipynb",
        "update": 1651543039.0
    },
    {
        "name": "TTS",
        "description": "A library for advanced Text-to-Speech generation, built on the latest research, was designed to achieve the best trade-off among ease-of-training, speed and quality",
        "author": [
            [
                "Eren G√∂lge",
                "https://github.com/erogol"
            ],
            [
                "Aya-AlJafari",
                "https://github.com/Aya-AlJafari"
            ],
            [
                "Edresson Casanova",
                "https://github.com/Edresson"
            ],
            [
                "Josh Meyer",
                "http://jrmeyer.github.io/"
            ],
            [
                "Kelly Davis",
                "https://github.com/kdavis-coqui"
            ],
            [
                "Reuben Morais",
                "https://github.com/reuben"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/coqui-ai/TTS",
                12062
            ],
            [
                "samples",
                "https://erogol.github.io/ddc-samples/"
            ],
            [
                "blog post",
                "https://coqui.ai/blog/tts/solving-attention-problems-of-tts-models-with-double-decoder-consistency"
            ],
            [
                "youtube",
                "https://youtu.be/ADnBCz0Wd1U"
            ],
            [
                "git",
                "https://github.com/coqui-ai/TTS-papers"
            ],
            [
                "docs",
                "https://tts.readthedocs.io/en/latest/"
            ],
            [
                "website",
                "https://coqui.ai/"
            ],
            [
                "youtube",
                "https://youtu.be/Yglxf2WbkLU"
            ],
            [
                "youtube",
                "https://youtu.be/alpI-DnVlO0"
            ]
        ],
        "colab": "https://colab.research.google.com/github/coqui-ai/TTS/blob/dev/notebooks/Tutorial_2_train_your_first_TTS_model.ipynb",
        "update": 1682508177.0
    },
    {
        "name": "MMAction2",
        "description": "An open-source toolbox for video understanding based on PyTorch",
        "author": [
            [
                "MMAction2 Contributors",
                "https://openmmlab.com/aboutus"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmaction2",
                3153
            ],
            [
                "docs",
                "https://mmaction2.readthedocs.io/"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Video-Swin-Transformer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13230"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.10161"
            ],
            [
                "git",
                "https://github.com/Cogito2012/DEAR"
            ],
            [
                "git",
                "https://github.com/xvjiarui/VFS"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17263"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.13586"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.05095"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.13042"
            ],
            [
                "git",
                "https://github.com/holistic-video-understanding/HVU-Dataset"
            ],
            [
                "data",
                "https://sdolivia.github.io/FineGym/"
            ],
            [
                "data",
                "http://www.svcl.ucsd.edu/projects/resound/dataset.html"
            ],
            [
                "data",
                "https://research.google.com/ava/index.html"
            ],
            [
                "data",
                "https://www.deepmind.com/open-source/kinetics"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmaction2/blob/master/demo/mmaction2_tutorial.ipynb",
        "update": 1684115382.0
    },
    {
        "name": "pymdp",
        "description": "Package for simulating Active Inference agents in Markov Decision Process environments",
        "author": [
            [
                "Conor Heins",
                "https://github.com/conorheins"
            ],
            [
                "Alec Tschantz",
                "https://github.com/alec-tschantz"
            ],
            [
                "Beren Millidge",
                "https://www.beren.io/"
            ],
            [
                "Brennan Klein",
                "https://github.com/jkbren"
            ],
            [
                "Arun Niranjan",
                "https://github.com/Arun-Niranjan"
            ],
            [
                "Daphne Demekas",
                "https://github.com/daphnedemekas"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/infer-actively/pymdp",
                262
            ],
            [
                "docs",
                "https://pymdp-rtd.readthedocs.io/en/stable/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.03904"
            ]
        ],
        "colab": "https://colab.research.google.com/github/infer-actively/pymdp/blob/master/docs/notebooks/active_inference_from_scratch.ipynb",
        "update": 1661366669.0
    },
    {
        "name": "AmpliGraph",
        "description": "A suite of neural machine learning models for relational Learning, a branch of machine learning that deals with supervised learning on knowledge graphs",
        "author": [
            [
                "Luca Costabello",
                "https://luca.costabello.info/"
            ],
            [
                "Adrianna Janik",
                "https://github.com/adrijanik"
            ],
            [
                "Chan Le Van",
                "https://github.com/chanlevan"
            ],
            [
                "Nicholas McCarthy",
                "https://github.com/NicholasMcCarthy"
            ],
            [
                "Rory McGrath",
                "http://www.rorymcgrath.ie/"
            ],
            [
                "Sumit Pai",
                "https://github.com/sumitpai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Accenture/AmpliGraph",
                1943
            ],
            [
                "docs",
                "https://docs.ampligraph.org"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1702.05563"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1705.10744"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.08683"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1612.03975"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.10000"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2013/hash/b337e84de8752b27eda3a12363109e80-Abstract.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6575"
            ],
            [
                "youtube",
                "https://youtu.be/gX_KHaU8ChI"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Accenture/AmpliGraph/blob/main/docs/tutorials/AmpliGraphBasicsTutorial.ipynb",
        "update": 1677165780.0
    },
    {
        "name": "BasicSR",
        "description": "Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring, etc.",
        "author": [
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Liangbin Xie",
                "https://liangbinxie.github.io/"
            ],
            [
                "Ke Yu",
                "https://github.com/yuke93"
            ],
            [
                "Kelvin Chan",
                "https://ckkelvinchan.github.io/"
            ],
            [
                "Chen Change Loy",
                "https://www.mmlab-ntu.com/person/ccloy/"
            ],
            [
                "Chao Dong",
                "https://scholar.google.com/citations?user=OSDCB0UAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/XPixelGroup/BasicSR",
                4872
            ],
            [
                "docs",
                "https://basicsr.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/xinntao/ESRGAN"
            ],
            [
                "git",
                "https://github.com/xindongzhang/ECBSR"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.02181"
            ],
            [
                "git",
                "https://github.com/Lotayou/Face-Renovation"
            ],
            [
                "git",
                "https://github.com/csxmli2016/DFDNet"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/xinntao/facexlib"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyView"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyFigure"
            ],
            [
                "git",
                "https://github.com/xinntao/SFTGAN"
            ],
            [
                "git",
                "https://github.com/xinntao/DNI"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyCrawler"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyWriting"
            ],
            [
                "youtube",
                "https://youtu.be/KaMYsxWkmww"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JQScYICvEC3VqaabLu-lxvq9h7kSV1ML",
        "update": 1623075800.789
    },
    {
        "name": "Petals",
        "description": "Run 100B+ language models at home, BitTorrent-style",
        "author": [
            [
                "BigScience",
                "https://bigscience.huggingface.co/"
            ]
        ],
        "links": [
            [
                "project",
                "https://petals.ml/"
            ],
            [
                "git",
                "https://github.com/bigscience-workshop/petals",
                4763
            ],
            [
                "huggingface",
                "https://huggingface.co/bigscience/bloom"
            ],
            [
                "git",
                "https://github.com/borzunov/chat.petals.ml"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.01188"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/BitTorrent"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.07258"
            ],
            [
                "git",
                "https://github.com/timDettmers/bitsandbytes"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ",
        "update": 1681329492.161
    },
    {
        "name": "py-irt",
        "description": "Fitting Item Response Theory models using variational inference",
        "author": [
            [
                "John Lalor",
                "https://jplalor.github.io/"
            ],
            [
                "Hong Yu",
                "https://scholar.google.com/citations?user=TyXe64wAAAAJ"
            ],
            [
                "Pedro Rodriguez",
                "https://www.pedro.ai/"
            ],
            [
                "Joe Barrow",
                "https://jbarrow.ai/"
            ],
            [
                "Alexander Hoyle",
                "https://alexanderhoyle.com/"
            ],
            [
                "Robin Jia",
                "https://robinjia.github.io/"
            ],
            [
                "Jordan Boyd-Graber",
                "https://github.com/ezubaric"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nd-ball/py-irt",
                84
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1908.11421"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/2021.acl-long.346"
            ],
            [
                "paper",
                "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.01422/full"
            ],
            [
                "youtube",
                "https://youtu.be/akUxtt21Mlc"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nd-ball/py-irt/blob/master/examples/py-irt_example.ipynb",
        "update": 1656584930.0
    },
    {
        "name": "Mubert",
        "description": "Prompt-based music generation via Mubert API",
        "author": [
            [
                "Ilya Belikov",
                "https://github.com/ferluht"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/MubertAI/Mubert-Text-to-Music",
                2620
            ],
            [
                "docs",
                "https://mubert2.docs.apiary.io/"
            ],
            [
                "project",
                "https://mubert.com/"
            ],
            [
                "youtube",
                "https://youtu.be/YJu0iXn-T_U"
            ],
            [
                "youtube",
                "https://youtu.be/5UsaxJsFvAI"
            ],
            [
                "youtube",
                "https://youtu.be/B0kkIpWifG4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ferluht/Mubert-Text-to-Music/blob/main/Mubert_Text_to_Music.ipynb",
        "update": 1666064989.0
    },
    {
        "name": "Tzer",
        "description": "Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation",
        "author": [
            [
                "Jiawei Liu",
                "https://jiawei-site.github.io/"
            ],
            [
                "Yuxiang Wei",
                "https://yuxiang.cs.illinois.edu/"
            ],
            [
                "Sen Yang",
                "https://github.com/syang-ng"
            ],
            [
                "Yinlin Deng",
                "https://dengyinlin.github.io/"
            ],
            [
                "Lingming Zhang",
                "http://lingming.cs.illinois.edu/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ise-uiuc/tzer",
                58
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09947"
            ],
            [
                "git",
                "https://github.com/ganler/memcov"
            ],
            [
                "docker",
                "https://hub.docker.com/repository/docker/tzerbot/oopsla"
            ],
            [
                "docs",
                "https://tzer.readthedocs.io/en/latest/index.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ise-uiuc/tzer/blob/main/bug-report.ipynb",
        "update": 1678395597.0
    },
    {
        "name": "Anomalib",
        "description": "Deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets",
        "author": [
            [
                "Samet Akcay",
                "https://github.com/samet-akcay"
            ],
            [
                "Dick Ameln",
                "https://github.com/djdameln"
            ],
            [
                "Ashwin Vaidya",
                "https://ashwinvaidya.com/"
            ],
            [
                "Barath Lakshmanan",
                "https://github.com/blakshma"
            ],
            [
                "Nilesh Ahuja",
                "https://github.com/nahuja-intel"
            ],
            [
                "Utku Genc",
                "https://github.com/ugenc-intel"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openvinotoolkit/anomalib",
                1951
            ],
            [
                "docs",
                "https://openvinotoolkit.github.io/anomalib/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.08785"
            ],
            [
                "data",
                "https://www.mvtec.com/company/research/datasets/mvtec-ad"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models"
            ],
            [
                "medium",
                "https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/lib/timm"
            ],
            [
                "git",
                "https://github.com/vnk8071/anomaly-detection-in-industry-manufacturing/tree/master/anomalib_contribute"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openvinotoolkit/anomalib/blob/main/notebooks/000_getting_started/001_getting_started.ipynb",
        "update": 1684929427.0
    },
    {
        "name": "OCTIS",
        "description": "Framework for training, analyzing, and comparing Topic Models, whose optimal hyper-parameters are estimated using a Bayesian Optimization approach",
        "author": [
            [
                "Silvia Terragni",
                "https://silviatti.github.io/"
            ],
            [
                "Elisabetta Fersini",
                "https://www.unimib.it/elisabetta-fersini"
            ],
            [
                "Antonio Candelieri",
                "https://www.unimib.it/antonio-candelieri"
            ],
            [
                "Pietro Tropeano",
                "https://github.com/pietrotrope"
            ],
            [
                "Bruno Galuzzi",
                "https://github.com/brunoG89"
            ],
            [
                "Lorenzo Famiglini",
                "https://github.com/lorenzofamiglini"
            ],
            [
                "Davide Pietrasanta",
                "https://github.com/davidepietrasanta"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mind-Lab/octis",
                549
            ],
            [
                "paper",
                "https://aclanthology.org/2021.eacl-demos.31/"
            ],
            [
                "medium",
                "https://towardsdatascience.com/a-beginners-guide-to-octis-optimizing-and-comparing-topic-models-is-simple-590554ec9ba6"
            ],
            [
                "medium",
                "https://towardsdatascience.com/a-beginners-guide-to-octis-vol-2-optimizing-topic-models-1214e58be1e5"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/dataset/20-newsgroups"
            ],
            [
                "data",
                "https://www.dbpedia.org/resources/ontology/"
            ],
            [
                "data",
                "https://www.statmt.org/europarl/"
            ],
            [
                "git",
                "https://github.com/estebandito22/PyTorchAVITM"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.01488"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2000/hash/f9d1152547c0bde01830b7e8bd60024c-Abstract.html"
            ],
            [
                "youtube",
                "https://youtu.be/nPmiWBFFJ8E"
            ]
        ],
        "colab": "https://colab.research.google.com/github/MIND-Lab/OCTIS/blob/master/examples/OCTIS_Optimizing_CTM.ipynb",
        "update": 1618831965.0
    },
    {
        "name": "SAHI",
        "description": "A lightweight vision library for performing large scale object detection & instance segmentation",
        "author": [
            [
                "Fatih Cagatay Akyon",
                "https://github.com/fcakyon"
            ],
            [
                "Sinan Onur ALTINU√á",
                "https://github.com/sinanonur"
            ],
            [
                "Alptekin Temizel",
                "https://blog.metu.edu.tr/atemizel/"
            ],
            [
                "Cemil Cengiz",
                "https://scholar.google.com/citations?user=1Ull07EAAAAJ"
            ],
            [
                "Devrim √áavu≈üoƒülu",
                "https://github.com/devrimcavusoglu"
            ],
            [
                "Kadir ≈ûahin",
                "https://github.com/ssahinnkadir"
            ],
            [
                "Oƒüulcan Ery√ºksel",
                "https://github.com/oulcan"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/obss/sahi",
                2663
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.06934"
            ],
            [
                "doi",
                "https://doi.org/10.1109/ICIP46576.2022.9897990"
            ],
            [
                "huggingface",
                "https://huggingface.co/models?pipeline_tag=object-detection&sort=downloads"
            ],
            [
                "medium",
                "https://medium.com/codable/sahi-a-vision-library-for-performing-sliced-inference-on-large-images-small-objects-c8b086af3b80"
            ],
            [
                "git",
                "https://github.com/fcakyon/small-object-detection-benchmark"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/remekkinas/sahi-slicing-aided-hyper-inference-yv5-and-yx"
            ],
            [
                "medium",
                "https://medium.com/codable/convert-any-dataset-to-coco-object-detection-format-with-sahi-95349e1fe2b7"
            ]
        ],
        "colab": "https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_yolov5.ipynb",
        "update": 1677187601.0
    },
    {
        "name": "NetKet",
        "description": "Open-source project delivering cutting-edge methods for the study of many-body quantum systems with artificial neural networks and machine learning techniques",
        "author": [
            [
                "Filippo Vicentini",
                "https://filippovicentini.com/"
            ],
            [
                "Damian Hofmann",
                "https://github.com/femtobit"
            ],
            [
                "Attila Szab√≥",
                "https://github.com/attila-i-szabo"
            ],
            [
                "Dian Wu",
                "https://github.com/wdphy16"
            ],
            [
                "Christopher Roth",
                "https://github.com/chrisrothUT"
            ],
            [
                "Clemens Giuliani",
                "https://github.com/inailuig"
            ],
            [
                "Gabriel Pescia",
                "https://github.com/gpescia"
            ],
            [
                "Jannes Nys",
                "https://github.com/jwnys"
            ],
            [
                "Vladimir Vargas-Calder√≥n",
                "https://github.com/VolodyaCO"
            ],
            [
                "Nikita Astrakhantsev",
                "https://github.com/nikita-astronaut"
            ],
            [
                "Giuseppe Carleo",
                "https://github.com/gcarleo"
            ],
            [
                "Kenny Choo",
                "https://github.com/kchoo1118"
            ],
            [
                "James Smith",
                "https://jamesetsmith.github.io/"
            ],
            [
                "Tom Westerhout",
                "https://github.com/twesterhout"
            ],
            [
                "Fabien Alet",
                "https://github.com/fabienalet"
            ],
            [
                "Emily Davis",
                "https://github.com/emilyjd"
            ],
            [
                "Stavros Efthymiou",
                "https://github.com/stavros11"
            ],
            [
                "Ivan Glasser",
                "https://www.researchgate.net/profile/Ivan-Glasser"
            ],
            [
                "Sheng-Hsuan Lin",
                "https://shhslin.github.io/"
            ],
            [
                "Marta Mauri",
                "https://github.com/martamau"
            ],
            [
                "Mazzola Guglielmo",
                "https://www.ics.uzh.ch/en/research/research-groups/Guglielmo-Mazzola0.html"
            ],
            [
                "Christian Mendl",
                "http://christian.mendl.net/"
            ],
            [
                "Evert Nieuwenburg",
                "https://evert.info/"
            ],
            [
                "Ossian O'Reilly",
                "https://github.com/ooreilly"
            ],
            [
                "Hugo Th√©veniaut",
                "https://github.com/theveniaut"
            ],
            [
                "Giacomo Torlai",
                "https://github.com/GTorlai"
            ],
            [
                "Alexander Wietek",
                "https://awietek.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/netket/netket",
                432
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10526"
            ],
            [
                "website",
                "https://www.netket.org/"
            ],
            [
                "docs",
                "https://netket.readthedocs.io/en/latest/index.html"
            ],
            [
                "git",
                "https://github.com/mpi4jax/mpi4jax"
            ],
            [
                "git",
                "https://github.com/cloudhan/jax-windows-builder"
            ],
            [
                "youtube",
                "https://youtu.be/Ryz-o71tuy8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/PhilipVinc/Lectures/blob/main/2202_NetKet/01_intro.ipynb",
        "update": 1663229972.0
    },
    {
        "name": "Stable Baselines3",
        "description": "Set of reliable implementations of reinforcement learning algorithms in PyTorch",
        "author": [
            [
                "Antonin Raffin",
                "https://araffin.github.io/"
            ],
            [
                "Ashley Hill",
                "https://hill-a.me/"
            ],
            [
                "Adam Gleave",
                "https://www.gleave.me/"
            ],
            [
                "Anssi Kanervisto",
                "https://github.com/Miffyli"
            ],
            [
                "Maximilian Ernestus",
                "https://github.com/ernestum"
            ],
            [
                "Noah Dormann",
                "https://github.com/ndormann"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/DLR-RM/stable-baselines3",
                5808
            ],
            [
                "docs",
                "https://stable-baselines3.readthedocs"
            ],
            [
                "git",
                "https://github.com/Stable-Baselines-Team/stable-baselines3-contrib"
            ],
            [
                "paper",
                "https://jmlr.org/papers/v22/20-1364.html"
            ],
            [
                "git",
                "https://github.com/hill-a/stable-baselines"
            ],
            [
                "git",
                "https://github.com/openai/gym/wiki/Environments"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/reinforcementlearning/"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLQVvvaa0QuDf0O2DWwLZBfJeYY-JOeZB1"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb",
        "update": 1681463238.0
    },
    {
        "name": "RL Baselines3 Zoo",
        "description": "Training Framework for Stable Baselines3 Reinforcement Learning Agents",
        "author": [
            [
                "Antonin Raffin",
                "https://araffin.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/DLR-RM/rl-baselines3-zoo",
                1302
            ],
            [
                "git",
                "https://github.com/DLR-RM/rl-baselines3-zoo"
            ],
            [
                "docs",
                "https://stable-baselines3.readthedocs.io/en/master/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05719"
            ],
            [
                "huggingface",
                "https://huggingface.co/sb3"
            ],
            [
                "git",
                "https://github.com/openai/roboschool"
            ],
            [
                "git",
                "https://github.com/Farama-Foundation/Minigrid"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb",
        "update": 1681463238.0
    },
    {
        "name": "CleanRL",
        "description": "Deep Reinforcement Learning library that provides high-quality single-file implementation with research-friendly features",
        "author": [
            [
                "Shengyi Huang",
                "https://costa.sh/"
            ],
            [
                "Rousslan Dossa",
                "https://dosssman.github.io/"
            ],
            [
                "Chang Ye",
                "https://github.com/yooceii"
            ],
            [
                "Jeff Braga",
                "https://github.com/bragajj"
            ],
            [
                "Dipam Chakraborty",
                "https://github.com/dipamc"
            ],
            [
                "Kinal Mehta",
                "https://kinalmehta.github.io/"
            ],
            [
                "Jo√£o Ara√∫jo",
                "https://github.com/joaogui1"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/vwxyzjn/cleanrl",
                2748
            ],
            [
                "paper",
                "https://www.jmlr.org/papers/v23/21-1342.html"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCDdC6BIFRI0jvcwuhi3aI6w"
            ],
            [
                "huggingface",
                "https://huggingface.co/cleanrl"
            ],
            [
                "docs",
                "https://docs.cleanrl.dev/"
            ],
            [
                "git",
                "https://github.com/tinkoff-ai/CORL"
            ],
            [
                "git",
                "https://github.com/Farama-Foundation/Gymnasium"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.06347"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.06887"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.05905"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1509.02971"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.09477"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2009.04416"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.12894"
            ],
            [
                "git",
                "https://github.com/openai/baselines"
            ],
            [
                "git",
                "https://github.com/ikostrikov/jaxrl"
            ],
            [
                "youtube",
                "https://youtu.be/dm4HdGujpPs"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vwxyzjn/cleanrl/blob/master/docs/get-started/CleanRL_Huggingface_Integration_Demo.ipynb",
        "update": 1673535797.0
    },
    {
        "name": "Sample Factory",
        "description": "One of the fastest RL libraries focused on very efficient synchronous and asynchronous implementations of policy gradients",
        "author": [
            [
                "Aleksei Petrenko",
                "https://alex-petrenko.github.io/"
            ],
            [
                "Zhehui Huang",
                "https://zhehui-huang.github.io/"
            ],
            [
                "Tushar Kumar",
                "https://github.com/tushartk"
            ],
            [
                "Gaurav Sukhatme",
                "http://robotics.usc.edu/~gaurav/"
            ],
            [
                "Vladlen Koltun",
                "http://vladlen.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/alex-petrenko/sample-factory",
                584
            ],
            [
                "docs",
                "https://www.samplefactory.dev/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11751"
            ],
            [
                "youtube",
                "https://youtu.be/lLG17LKKSZc"
            ],
            [
                "git",
                "https://github.com/alex-petrenko/faster-fifo"
            ],
            [
                "ICML",
                "http://proceedings.mlr.press/v119/petrenko20a.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/alex-petrenko/sample-factory/blob/master/sf_examples/notebooks/samplefactory_hub_example.ipynb",
        "update": 1673912124.0
    },
    {
        "name": "Ray",
        "description": "Unified framework for scaling AI and Python applications",
        "author": [
            [
                "Philipp Moritz",
                "https://github.com/pcmoritz"
            ],
            [
                "Robert Nishihara",
                "https://github.com/robertnishihara"
            ],
            [
                "Stephanie Wang",
                "https://stephanie-wang.github.io/"
            ],
            [
                "Alexey Tumanov",
                "https://faculty.cc.gatech.edu/~atumanov/"
            ],
            [
                "Richard Liaw",
                "https://github.com/richardliaw"
            ],
            [
                "Eric Liang",
                "https://github.com/ericl"
            ],
            [
                "Melih Elibol",
                "https://research.nvidia.com/person/melih-elibol"
            ],
            [
                "Zongheng Yang",
                "https://zongheng.me/"
            ],
            [
                "William Paul",
                "https://github.com/Wapaul1"
            ],
            [
                "Michael Jordan",
                "https://people.eecs.berkeley.edu/~jordan/"
            ],
            [
                "Ion Stoica",
                "https://people.eecs.berkeley.edu/~istoica/"
            ]
        ],
        "links": [
            [
                "website",
                "https://www.ray.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1712.05889"
            ],
            [
                "git",
                "https://github.com/ray-project/ray",
                25824
            ],
            [
                "docs",
                "https://docs.ray.io/en/latest/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.05072"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1712.09381"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.05118"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.03924"
            ],
            [
                "youtube",
                "https://youtu.be/LmROEotKhJA"
            ],
            [
                "youtube",
                "https://youtu.be/uzt-CwohQC8"
            ],
            [
                "youtube",
                "https://youtu.be/XME90SGL6Vs"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ray-project/ray/blob/master/doc/source/tune/examples/optuna_example.ipynb",
        "update": 1683581756.0
    },
    {
        "name": "Hyperopt",
        "description": "Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions",
        "author": [
            [
                "James Bergstra",
                "https://github.com/jaberg"
            ],
            [
                "Dan Yamins",
                "https://github.com/yamins81"
            ],
            [
                "David Cox",
                "https://scholar.google.com/citations?user=6S-WgLkAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/hyperopt/hyperopt",
                6747
            ],
            [
                "docs",
                "http://hyperopt.github.io/hyperopt/"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-sklearn"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-nnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-nnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-convnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-gpsmbo"
            ],
            [
                "ICML",
                "https://proceedings.mlr.press/v28/bergstra13.html"
            ],
            [
                "youtube",
                "https://youtu.be/Mp1xnPfE4PY"
            ],
            [
                "youtube",
                "https://youtu.be/tdwgR1AqQ8Y"
            ],
            [
                "youtube",
                "https://youtu.be/tteE_Vtmrv4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/hyperopt/hyperopt/blob/master/tutorial/01.BasicTutorial.ipynb",
        "update": 1622526481.0
    },
    {
        "name": "Feast",
        "description": "An open source feature store for machine learning",
        "author": [
            [
                "Willem Pienaar",
                "https://github.com/woop"
            ],
            [
                "Danny Chiao",
                "https://github.com/adchia"
            ],
            [
                "Achal Shah",
                "http://achals.com/"
            ],
            [
                "Terence Lim",
                "https://terryyylim.github.io/portfolio/"
            ],
            [
                "Ches Martin",
                "https://github.com/ches"
            ],
            [
                "Judah Rand",
                "https://github.com/judahrand"
            ],
            [
                "Matt Delacour",
                "https://github.com/MattDelac"
            ],
            [
                "Miguel Trejo Marrufo",
                "https://github.com/TremaMiguel"
            ],
            [
                "Francisco Javier Arceo",
                "https://franciscojavierarceo.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/feast-dev/feast",
                4340
            ],
            [
                "website",
                "https://feast.dev/"
            ],
            [
                "docs",
                "https://docs.feast.dev/"
            ],
            [
                "git",
                "https://github.com/baineng/feast-hive"
            ],
            [
                "git",
                "https://github.com/Shopify/feast-trino"
            ],
            [
                "git",
                "https://github.com/Azure/feast-azure"
            ],
            [
                "git",
                "https://github.com/amundsen-io/amundsen/blob/main/databuilder/databuilder/extractor/feast_extractor.py"
            ],
            [
                "youtube",
                "https://youtu.be/DaNv-Wf1MBA"
            ],
            [
                "youtube",
                "https://youtu.be/p2cuq4eJ2BY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/feast-dev/feast/blob/master/examples/quickstart/quickstart.ipynb",
        "update": 1675791196.0
    },
    {
        "name": "Optuna",
        "description": "An automatic hyperparameter optimization software framework, particularly designed for machine learning",
        "author": [
            [
                "Takuya Akiba",
                "https://iwiwi.github.io/"
            ],
            [
                "Shotaro Sano",
                "https://github.com/g-votte"
            ],
            [
                "Toshihiko Yanase",
                "https://github.com/toshihikoyanase"
            ],
            [
                "Takeru Ohta",
                "https://github.com/sile"
            ],
            [
                "Masanori Koyama",
                "https://scholar.google.com/citations?user=oY1gA10AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/optuna/optuna",
                8154
            ],
            [
                "website",
                "https://optuna.org/"
            ],
            [
                "docs",
                "https://optuna.readthedocs.io/en/stable/"
            ],
            [
                "git",
                "https://github.com/optuna/optuna-dashboard"
            ],
            [
                "docker",
                "https://hub.docker.com/r/optuna/optuna"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10902"
            ],
            [
                "youtube",
                "https://youtu.be/J_aymk4YXhg"
            ],
            [
                "youtube",
                "https://youtu.be/tcrcLRopTX0"
            ],
            [
                "youtube",
                "https://youtu.be/-UeC4MR3PHM"
            ],
            [
                "youtube",
                "https://youtu.be/oC8zFYcfYXU"
            ]
        ],
        "colab": "https://colab.research.google.com/github/optuna/optuna-examples/blob/main/quickstart.ipynb",
        "update": 1594160265.0
    },
    {
        "name": "Brax",
        "description": "A differentiable physics engine that simulates environments made up of rigid bodies, joints, and actuators",
        "author": [
            [
                "Daniel Freeman",
                "https://github.com/cdfreeman-google"
            ],
            [
                "Erik Frey",
                "https://fawx.com/"
            ],
            [
                "Anton Raichuk",
                "https://scholar.google.com/citations?user=fquIpvgAAAAJ"
            ],
            [
                "Sertan Girgin",
                "https://sites.google.com/site/girgint/home"
            ],
            [
                "Igor Mordatch",
                "https://scholar.google.com/citations?user=Vzr1RukAAAAJ"
            ],
            [
                "Olivier Bachem",
                "http://olivierbachem.ch/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/brax",
                1680
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13281"
            ],
            [
                "neurips",
                "https://neurips.cc/Conferences/2021/CallForDatasetsBenchmarks"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/brax/blob/main/notebooks/basics.ipynb",
        "update": 1680180863.0
    },
    {
        "name": "PyG",
        "description": "Library built upon PyTorch to easily write and train Graph Neural Networks for a wide range of applications related to structured data",
        "author": [
            [
                "Matthias Fey",
                "https://rusty1s.github.io/#/"
            ],
            [
                "Jan Eric Lenssen",
                "https://github.com/janericlenssen"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/pyg-team/pytorch_geometric",
                17741
            ],
            [
                "docs",
                "https://pytorch-geometric.readthedocs.io/en/latest/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1903.02428"
            ],
            [
                "git",
                "https://github.com/snap-stanford/ogb/tree/master/examples"
            ],
            [
                "pt",
                "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.07829"
            ],
            [
                "git",
                "https://github.com/pyg-team/pyg-lib"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_scatter"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_sparse"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_cluster"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.02907"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2018/hash/e77dbaf6759253c7c6d0efc5690369c7-Abstract.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.03123"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.05178"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08566"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10903"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html"
            ],
            [
                "neurips",
                "https://nips.cc/virtual/2020/public/poster_3fe230348e9a12c13120749e3f9fa4cd.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.07953"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLGMXrbDNfqTzqxB1IGgimuhtfAhGd8lHF"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLGMXrbDNfqTwPxitLVHEbT9Pd6-oR_cud"
            ],
            [
                "youtube",
                "https://youtu.be/-UjytpbqX4A"
            ],
            [
                "git",
                "https://github.com/AntonioLonga/PytorchGeometricTutorial"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8",
        "update": 1670482639.504
    },
    {
        "name": "Kornia",
        "description": "Library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low-level image processing such as filtering and edge detection that operate directly on tensors",
        "author": [
            [
                "Edgar Riba",
                "https://github.com/edgarriba"
            ],
            [
                "Dmytro Mishkin",
                "https://dmytro.ai/"
            ],
            [
                "Daniel Ponsa",
                "https://github.com/DanielPonsa"
            ],
            [
                "Ethan Rublee",
                "https://github.com/ethanrublee"
            ],
            [
                "Gary Bradski",
                "https://github.com/garybradski"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/kornia/kornia",
                8229
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.02190"
            ],
            [
                "doi",
                "https://doi.org/10.1109/WACV45572.2020.9093363"
            ],
            [
                "docs",
                "https://kornia.readthedocs.io/en/latest/"
            ],
            [
                "blog post",
                "https://opencv.org/kornia-an-open-source-differentiable-computer-vision-library-for-pytorch/"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCI1SE1Ij2Fast5BSKxoa7Ag"
            ],
            [
                "youtube",
                "https://youtu.be/3RmCYFhwclE"
            ],
            [
                "youtube",
                "https://youtu.be/AAZa-mXjYF0"
            ],
            [
                "slack",
                "https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA"
            ],
            [
                "website",
                "https://kornia.github.io/"
            ],
            [
                "twitter",
                "https://twitter.com/kornia_foss"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kornia/kornia/blob/master/examples/augmentation/kornia_augmentation.ipynb",
        "update": 1676123726.0
    },
    {
        "name": "Composer",
        "description": "PyTorch library that enables you to train neural networks faster, at lower cost, and to higher accuracy",
        "author": [
            [
                "The Mosaic ML Team",
                "https://www.mosaicml.com/team"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mosaicml/composer",
                3511
            ],
            [
                "docs",
                "http://docs.mosaicml.com/"
            ],
            [
                "website",
                "https://www.mosaicml.com/composer"
            ],
            [
                "blog post",
                "https://www.mosaicml.com/blog/5-best-practices-for-efficient-model-training"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Amdahl's_law"
            ],
            [
                "app",
                "https://app.mosaicml.com/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.05924"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.04688"
            ],
            [
                "youtube",
                "https://www.youtube.com/@mosaicml6047/videos"
            ],
            [
                "youtube",
                "https://youtu.be/n-1WV5QdIDc"
            ],
            [
                "youtube",
                "https://youtu.be/Xi_5wq2MpOw"
            ],
            [
                "slack",
                "https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg"
            ],
            [
                "twitter",
                "https://twitter.com/mosaicml"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/getting_started.ipynb",
        "update": 1681917307.0
    },
    {
        "name": "deep-significance",
        "description": "Easy-to-use package containing different significance tests and utility functions specifically tailored towards research needs and usability",
        "author": [
            [
                "Dennis Ulmer",
                "http://dennisulmer.eu/"
            ],
            [
                "Christian Hardmeier",
                "https://christianhardmeier.rax.ch/"
            ],
            [
                "Jes Frellsen",
                "https://frellsen.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Kaleidophon/deep-significance",
                290
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.06815"
            ],
            [
                "docs",
                "https://deep-significance.readthedocs.io/en/latest/"
            ],
            [
                "blog post",
                "https://machinelearningmastery.com/statistical-hypothesis-tests/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Multiple_comparisons_problem"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/p19-1266"
            ],
            [
                "git",
                "https://github.com/rtmdrr/replicability-analysis-NLP"
            ],
            [
                "git",
                "https://github.com/rtmdrr/testSignificanceNLP"
            ],
            [
                "git",
                "https://github.com/rtmdrr/DeepComparison"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Kaleidophon/deep-significance/blob/main/paper/deep-significance%20demo.ipynb",
        "update": 1649769869.0
    },
    {
        "name": "PyTerrier",
        "description": "A Python framework for performing information retrieval experiments",
        "author": [
            [
                "Craig Macdonald",
                "https://www.dcs.gla.ac.uk/~craigm/"
            ],
            [
                "Nicola Tonellotto",
                "https://github.com/tonellotto"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/terrier-org/pyterrier",
                321
            ],
            [
                "docs",
                "https://pyterrier.readthedocs.io"
            ],
            [
                "git",
                "https://github.com/terrier-org/ecir2021tutorial"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_ance"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_colbert"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_pisa"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_t5"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_doc2query"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_deepct"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.14271"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3459637.3482013"
            ]
        ],
        "colab": "https://colab.research.google.com/github/terrier-org/pyterrier/blob/master/examples/notebooks/non_en_retrieval.ipynb",
        "update": 1667409125.0
    },
    {
        "name": "StableLM",
        "description": "Stability AI Language Models",
        "author": [
            [
                "Stability AI",
                "https://stability.ai/careers"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Stability-AI/StableLM",
                14460
            ],
            [
                "huggingface",
                "https://huggingface.co/lmsys/vicuna-13b-delta-v0"
            ],
            [
                "git",
                "https://github.com/facebookresearch/llama"
            ],
            [
                "git",
                "https://github.com/tatsu-lab/stanford_alpaca"
            ],
            [
                "git",
                "https://github.com/nomic-ai/gpt4all"
            ],
            [
                "huggingface",
                "https://huggingface.co/datasets/RyokoAI/ShareGPT52K"
            ],
            [
                "git",
                "https://github.com/databrickslabs/dolly"
            ],
            [
                "git",
                "https://github.com/anthropics/hh-rlhf"
            ],
            [
                "huggingface",
                "https://huggingface.co/stabilityai"
            ],
            [
                "git",
                "https://github.com/ggerganov/llama.cpp"
            ],
            [
                "youtube",
                "https://youtu.be/dypPSs4t77g"
            ],
            [
                "youtube",
                "https://youtu.be/nWf1StvtoRw"
            ],
            [
                "youtube",
                "https://youtu.be/Hg-s2RTaTFE"
            ],
            [
                "youtube",
                "https://youtu.be/qXtJjoEfTnA"
            ],
            [
                "blog post",
                "https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stability-AI/StableLM/blob/main/notebooks/stablelm-alpha.ipynb",
        "update": 1682600742.0
    },
    {
        "name": "normflows",
        "description": "PyTorch implementation of discrete normalizing flows",
        "author": [
            [
                "Vincent Stimper",
                "https://is.mpg.de/person/vstimper"
            ],
            [
                "David Liu",
                "https://davindicode.github.io/"
            ],
            [
                "Andrew Campbell",
                "https://github.com/andrew-cr"
            ],
            [
                "Vincent Berenz",
                "http://vincentberenz.is.tuebingen.mpg.de/"
            ],
            [
                "Lukas Ryll",
                "https://github.com/lukasryll"
            ],
            [
                "Bernhard Sch√∂lkopf",
                "https://scholar.google.com/citations?user=DZ-fHPgAAAAJ"
            ],
            [
                "Jos√© Miguel Hern√°ndez-Lobato",
                "https://jmhl.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/VincentStimper/normalizing-flows",
                371
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.12014"
            ],
            [
                "docs",
                "https://vincentstimper.github.io/normalizing-flows/"
            ],
            [
                "git",
                "https://github.com/VincentStimper/resampled-base-flows"
            ],
            [
                "git",
                "https://github.com/VincentStimper/hmc-hyperparameter-tuning"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Von_Mises_distribution"
            ]
        ],
        "colab": "https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/paper_example_nsf_colab.ipynb",
        "update": 1677232602.0
    },
    {
        "name": "Open-Assistant",
        "description": "Chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so",
        "author": [
            [
                "Andreas K√∂pf",
                "https://github.com/andreaskoepf"
            ],
            [
                "Yannic Kilcher",
                "https://github.com/yk"
            ],
            [
                "Huu Nguyen",
                "https://github.com/ontocord"
            ],
            [
                "Christoph Schuhmann",
                "http://christoph-schuhmann.de/"
            ],
            [
                "Keith Stevens",
                "https://fozziethebeat.github.io/"
            ],
            [
                "Abdullah Barhoum",
                "https://github.com/AbdBarho"
            ],
            [
                "Nguyen Minh Duc",
                "https://github.com/notmd"
            ],
            [
                "Oliver Stanley",
                "https://olliestanley.github.io/"
            ],
            [
                "James Melvin Ebenezer",
                "https://github.com/melvinebenezer"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/LAION-AI/Open-Assistant",
                33429
            ],
            [
                "website",
                "https://open-assistant.io/"
            ],
            [
                "docs",
                "https://projects.laion.ai/Open-Assistant/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.02155"
            ],
            [
                "youtube",
                "https://youtu.be/64Izfm24FKA"
            ],
            [
                "youtube",
                "https://youtu.be/ddG2fM9i4Kk"
            ],
            [
                "youtube",
                "https://youtu.be/FQIHLFLrTw0"
            ],
            [
                "huggingface",
                "https://huggingface.co/OpenAssistant"
            ],
            [
                "medium",
                "https://generativeai.pub/open-assistant-a-free-and-open-source-alternative-to-chatgpt-67d15229813"
            ]
        ],
        "colab": "https://colab.research.google.com/github/LAION-AI/Open-Assistant/blob/main/notebooks/data-augmentation/stackexchange-builder/stackexchange-builder.ipynb",
        "update": 1673733069.0
    },
    {
        "name": "DeepFloyd IF",
        "description": "State-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding",
        "author": [
            [
                "Alex Shonenkov",
                "https://linktr.ee/shonenkovAI"
            ],
            [
                "Misha Konstantinov",
                "https://github.com/zeroshot-ai"
            ],
            [
                "Daria Bakshandaeva",
                "https://github.com/Gugutse"
            ],
            [
                "Christoph Schuhman",
                "http://christoph-schuhmann.de/"
            ],
            [
                "Ksenia Ivanova",
                "https://github.com/ivksu"
            ],
            [
                "Nadiia Klokova",
                "https://github.com/vauimpuls"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deep-floyd/IF",
                6484
            ],
            [
                "website",
                "https://deepfloyd.ai/deepfloyd-if"
            ],
            [
                "discord",
                "https://discord.gg/umz62Mgr"
            ],
            [
                "twitter",
                "https://twitter.com/deepfloydai"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2205.11487"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/shonenkov/deepfloyd-if-4-3b-generator-of-pictures"
            ],
            [
                "huggingface",
                "https://huggingface.co/DeepFloyd"
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/diffusers/optimization/fp16#model-offloading-for-fast-inference-and-memory-savings"
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-speed"
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-memory"
            ],
            [
                "huggingface",
                "https://huggingface.co/blog/if"
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/diffusers/main/en/api/pipelines/if"
            ],
            [
                "youtube",
                "https://youtu.be/4Zkipll5Rjc"
            ],
            [
                "youtube",
                "https://youtu.be/tq5ZXZWwTPA"
            ],
            [
                "youtube",
                "https://youtu.be/rLtfd1TvYJk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/deepfloyd_if_free_tier_google_colab.ipynb",
        "update": 1682594260.0
    },
    {
        "name": "Machine learning course",
        "description": "This course is broad and shallow, but author will provide additional links so that you can deepen your understanding of the ML method you need",
        "author": [
            [
                "–¢–∏–º—á–∏—à–∏–Ω –í—ñ—Ç–∞–ª—ñ–π",
                "https://github.com/fbeilstein"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/fbeilstein/machine_learning",
                118
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLkDeTjsoxDVgnb2lIYo9-1l4XYhrIyS6A"
            ],
            [
                "blog post",
                "https://vas3k.com/blog/machine_learning/"
            ],
            [
                "youtube",
                "https://youtu.be/-RdOwhmqP5s"
            ],
            [
                "youtube",
                "https://youtu.be/R13BD8qKeTg"
            ],
            [
                "youtube",
                "https://youtu.be/ZkjP5RJLQF4"
            ],
            [
                "youtube",
                "https://youtu.be/J4Wdy0Wc_xQ"
            ],
            [
                "youtube",
                "https://youtu.be/mBcLRGuAFUk"
            ],
            [
                "youtube",
                "https://youtu.be/YIGtalP1mv0"
            ],
            [
                "youtube",
                "https://youtu.be/Yz5pySyEtsU"
            ],
            [
                "youtube",
                "https://youtu.be/x5zLaWT5KPs"
            ],
            [
                "youtube",
                "https://youtu.be/yBwpo-L80Mc"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv"
            ]
        ],
        "colab": "https://colab.research.google.com/github/fbeilstein/machine_learning/blob/master/lecture_01_introduction.ipynb",
        "update": 1630588044.0
    },
    {
        "name": "DSP theory",
        "description": "Theory of digital signal processing: signals, filtration (IIR, FIR, CIC, MAF), transforms (FFT, DFT, Hilbert, Z-transform) etc",
        "author": [
            [
                "Alexander Kapitanov",
                "https://github.com/hukenovs"
            ],
            [
                "Vladimir Fadeev",
                "https://github.com/kirlf"
            ],
            [
                "Karina Kvanchiani",
                "https://github.com/karinakvanchiani"
            ],
            [
                "Elizaveta Petrova",
                "https://github.com/kleinsbotle"
            ],
            [
                "Andrei Makhliarchuk",
                "https://github.com/anotherhelloworld"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/hukenovs/dsp-theory",
                792
            ],
            [
                "blog post",
                "https://habr.com/ru/articles/460445/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/hukenovs/dsp-theory/blob/master/src/dsp_theory_1_signals.ipynb",
        "update": 1666082056.0
    },
    {
        "name": "Nerfstudio",
        "description": "API that allows for a simplified end-to-end process of creating, training, and testing NeRFs",
        "author": [
            [
                "Matthew Tancik",
                "https://github.com/tancik"
            ],
            [
                "Ethan Weber",
                "https://ethanweber.me/"
            ],
            [
                "Evonne Ng",
                "http://people.eecs.berkeley.edu/~evonne_ng/"
            ],
            [
                "Ruilong Li",
                "http://www.liruilong.cn/"
            ],
            [
                "Brent Yi",
                "https://github.com/brentyi"
            ],
            [
                "Justin Kerr",
                "https://kerrj.github.io/"
            ],
            [
                "Terrance Wang",
                "https://github.com/terrancewang"
            ],
            [
                "Alexander Kristoffersen",
                "https://akristoffersen.com/"
            ],
            [
                "Jake Austin",
                "https://github.com/jake-austin"
            ],
            [
                "Kamyar Salahi",
                "https://github.com/TheQuantumFractal"
            ],
            [
                "Abhik Ahuja",
                "https://abhikahuja.com/"
            ],
            [
                "David McAllister",
                "https://github.com/mcallisterdavid"
            ],
            [
                "Angjoo Kanazawa",
                "https://github.com/akanazawa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nerfstudio-project/nerfstudio",
                5240
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.04264"
            ],
            [
                "Viewer",
                "https://viewer.nerf.studio/"
            ],
            [
                "git",
                "https://github.com/NVlabs/tiny-cuda-nn"
            ],
            [
                "docs",
                "https://docs.nerf.studio/en/latest/"
            ],
            [
                "youtube",
                "https://youtu.be/XwKq7qDQCQk"
            ],
            [
                "discord",
                "https://discord.gg/uMbNqcraFc"
            ],
            [
                "twitter",
                "https://twitter.com/nerfstudioteam"
            ],
            [
                "youtube",
                "https://youtu.be/nSFsugarWzk"
            ],
            [
                "youtube",
                "https://youtu.be/h5EWiRRxYEQ"
            ],
            [
                "youtube",
                "https://youtu.be/8cv9G7izdPY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nerfstudio-project/nerfstudio/blob/main/colab/demo.ipynb",
        "update": 1685484198.0
    },
    {
        "name": "BLIP",
        "description": "VLP framework which transfers flexibly to both vision-language understanding and generation tasks",
        "author": [
            [
                "Junnan Li",
                "https://github.com/LiJunnan1992"
            ],
            [
                "Dongxu Li",
                "https://sites.google.com/view/dongxu-li/home"
            ],
            [
                "Caiming Xiong",
                "http://cmxiong.com/"
            ],
            [
                "Steven Hoi",
                "https://sites.google.com/view/stevenhoi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/salesforce/BLIP",
                2741
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12086"
            ],
            [
                "blog post",
                "https://blog.salesforceairesearch.com/blip-bootstrapping-language-image-pretraining/"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ],
            [
                "git",
                "https://github.com/salesforce/ALPRO"
            ],
            [
                "git",
                "https://github.com/dmlc/decord"
            ],
            [
                "git",
                "https://github.com/salesforce/ALBEF"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models/tree/main/timm"
            ],
            [
                "youtube",
                "https://youtu.be/X2k7n4FuI7c"
            ]
        ],
        "colab": "https://colab.research.google.com/github/salesforce/BLIP/blob/main/demo.ipynb",
        "update": 1646261949.0
    },
    {
        "name": "LAVIS",
        "description": "Python deep learning library for LAnguage-and-VISion intelligence research and applications",
        "author": [
            [
                "Dongxu Li",
                "https://github.com/dxli94"
            ],
            [
                "Junnan Li",
                "https://github.com/LiJunnan1992"
            ],
            [
                "Hung Le",
                "https://sites.google.com/view/henryle2018/home"
            ],
            [
                "Guangsen Wang",
                "https://github.com/guangsen-wang"
            ],
            [
                "Silvio Savarese",
                "https://scholar.google.com/citations?user=ImpbxLsAAAAJ"
            ],
            [
                "Steven Hoi",
                "https://sites.google.com/view/stevenhoi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/salesforce/LAVIS",
                5221
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.09019"
            ],
            [
                "docs",
                "https://opensource.salesforce.com/LAVIS//latest/index.html"
            ],
            [
                "blog post",
                "https://blog.salesforceairesearch.com/lavis-language-vision-library/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.06500"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.12597"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2212.10846"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.08773"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Merlion"
            ]
        ],
        "colab": "https://colab.research.google.com/github/salesforce/LAVIS/blob/main/projects/img2llm-vqa/img2llm_vqa.ipynb",
        "update": 1679636565.0
    },
    {
        "name": "SoftVC VITS",
        "description": "Singing Voice Conversion",
        "author": [
            [
                "svc develop team",
                "https://github.com/svc-develop-team"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/svc-develop-team/so-vits-svc",
                13819
            ],
            [
                "git",
                "https://github.com/NaruseMioShirakana/MoeVoiceStudio"
            ],
            [
                "git",
                "https://github.com/openvpi/DiffSinger/tree/refactor/modules/nsf_hifigan"
            ],
            [
                "git",
                "https://github.com/auspicious3000/contentvec"
            ],
            [
                "huggingface",
                "https://huggingface.co/NaruseMioShirakana/MoeSS-SUBModel/tree/main"
            ],
            [
                "git",
                "https://github.com/yxlllc/DDSP-SVC"
            ],
            [
                "git",
                "https://github.com/flutydeer/audio-slicer"
            ],
            [
                "git",
                "https://github.com/openvpi/audio-slicer"
            ]
        ],
        "colab": "https://colab.research.google.com/github/svc-develop-team/so-vits-svc/blob/4.1-Stable/sovits4_for_colab.ipynb",
        "update": 1685097198.0
    }
]